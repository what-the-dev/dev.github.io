{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>Data Scientist working at SEEK, specialising in Online and Tech. I work closely with product teams to identify opportunities to optimise product and provide value to candidates through data driven insights and modelling. I am a proactive, creative person with a passion for learning. I am constantly striving to improving my skill-set. I do this by immersing myself in new challenges. I am passionate about local music, python, data, the arts and travel.</p>"},{"location":"#skillset","title":"Skillset","text":"<ul> <li>Machine Learning</li> <li>Deep Learning</li> <li>Python</li> <li>SQL</li> <li>Adobe Analytics</li> <li>Power BI</li> <li>Web Analytics</li> <li>Data Visualisation</li> </ul>"},{"location":"computer%20vision/01_image_segmentation_floodnet/","title":"01 image segmentation floodnet","text":"<pre><code>from fastai.vision.all import *\nfrom fastai.data.all import *\n</code></pre> <pre><code>import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n</code></pre> <p>Segmentaion datasets usually consist of image files, mask files and codes which are the segmenttion pixel labels. </p> <pre><code>path = Path.cwd()/'floodnet_data'\npath\n</code></pre> <pre>\n<code>Path('/Users/ddearaujo/Desktop/dl/vision/image_segmentation/floodnet_data')</code>\n</pre> <pre><code># get loabels / codes\ncol_map = {'Class Index.1': 'class_id', 'Class Name.1':'label'}\n\ndf_codes = pd.read_csv(\n    path/'class_mapping.csv', \n    header=2\n).iloc[:, -2:].rename(columns=col_map)\n\ncodes = df_codes.label.values\n\ndf_codes.head()\n</code></pre> class_id label 0 0 Background 1 1 Building-flooded 2 2 Building-non-flooded 3 3 Road-flooded 4 4 Road-non-flooded <pre><code># Get all the files in path with optional extensions\n# mask files are PNG so we can exclude these by specifying the extensions\n\nfnames = get_files(path/\"train\", extensions='.jpg')\nfnames[0]\n</code></pre> <pre>\n<code>Path('/Users/ddearaujo/Desktop/dl/vision/image_segmentation/floodnet_data/train/not_flooded/image/7078.jpg')</code>\n</pre> <pre><code>def label_func(fn):\n    p = path/'train'/fn.parts[-3]/'mask'/f'{fn.stem}_lab.png'\n    return p\n</code></pre> <pre><code>dls = SegmentationDataLoaders.from_label_func(\n    path, \n    bs=8,\n    fnames=fnames, \n    label_func=label_func, \n    codes=codes,\n    item_tfms=Resize(128)\n)\n</code></pre> <pre><code>dls.show_batch(max_n=4)\n</code></pre> <pre><code>model = unet_learner(dls, resnet34)\nmodel.fine_tune(10)\n</code></pre> epoch train_loss valid_loss time 0 1.452725 1.594936 02:43 epoch train_loss valid_loss time 0 1.108694 1.171069 02:42 1 1.014180 1.138221 02:50 2 0.988032 1.126446 02:40 3 0.967991 1.056948 02:40 4 0.885660 0.986956 02:38 5 0.820628 0.929066 02:39 6 0.770862 0.848385 02:38 7 0.713452 0.886977 02:36 8 0.667192 0.956540 02:37 9 0.625676 0.927906 02:37 <pre><code>model.show_results(max_n=4, figsize=(7,10))\n</code></pre> <pre><code>interp = SegmentationInterpretation.from_learner(model)\n</code></pre> <pre><code>top_losses = interp.top_losses(4, largest=True)[1]\ninterp.show_results(top_losses.data)\n</code></pre> <p>The interpreter shows the model makes some reasonable predictions, but there is still room for improvement!</p>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#image-segmentation","title":"Image Segmentation","text":"<p>Image segmentation refers to the process of dividing an image into meaningful and distinct regions or objects at the pixel level. It involves assigning a label or class to each pixel in an image to identify different objects, boundaries, or areas of interest. The goal of image segmentation is to separate and distinguish different objects or regions within an image, enabling a computer or an algorithm to understand and analyze the image at a more detailed level.</p> <p>Segmentation has benefits to downstream tasks such as object recognition and tracking, scene understanding, medical image analysis and robotics to name a few.</p>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#u-net","title":"U-Net","text":"<p>The U-Net is a convolutional neural net (CNN) that was originally developed in 2015 at the Computer Science Department of the University of Freiburg for the task of biomedical image segmentation.</p> <p>U-Net introduced an encoder-decoder architecture with skip connections. The contracting path captured context and abstract features, while the expansive path recovered spatial resolution using skip connections. U-Net's design made it highly effective for biomedical image segmentation and subsequently gained popularity in other domains.</p>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#floodnet","title":"FloodNet","text":"<p>The below description is from the FloodNet GitHub</p> <p>FloodNet provides high-resolution UAV (Unmanned Aerial Vehicle) imageries with detailed semantic annotation regarding the damages. To advance the damage assessment process for post-disaster scenarios, we present a unique challenge considering classification, semantic segmentation, visual question answering highlighting the UAS imagery-based FloodNet dataset.</p>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#track-1","title":"Track 1","text":"<p>In this track, participants are required to complete two semi-supervised tasks. The first task is image classification, and the second task is semantic segmentation. 1. Semi-Supervised Classification: Classification for FloodNet dataset requires classifying the images into \u2018Flooded\u2019 and \u2018Non-Flooded\u2019 classes. Only a few of the training images have their labels available, while most of the training images are unlabeled.</p> <ol> <li>Semi-Supervised Semantic Segmentation: The semantic segmentation labels include: 1) Background, 2) Building Flooded, 3) Building Non-Flooded, 4) Road Flooded, 5) Road Non-Flooded, 6) Water, 7)Tree, 8) Vehicle, 9) Pool, 10) Grass. Only a small portion of the training images have their corresponding masks available.</li> </ol>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#links","title":"Links","text":"<ul> <li>FloodNet paper</li> <li>data download</li> </ul>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#segmentation","title":"segmentation","text":""},{"location":"computer%20vision/01_image_segmentation_floodnet/#model-u-net","title":"Model: U-Net","text":"<p>Traditional convolutional neural networks (CNNs) are effective for various computer vision tasks, such as image classification, object detection, and localization. However, they have limitations when it comes to image segmentation. Reasons for this include...</p> <ul> <li>Resolution Loss: CNNs typically downsample the input image as they progress through the network to capture higher-level features. This downsampling reduces the resolution of the feature maps, making it challenging to accurately localize and segment small objects or fine details in the image.</li> <li>Contextual Information: Segmentation tasks often require capturing contextual information to distinguish between objects with similar appearances or to handle complex object boundaries. Traditional CNNs, with their hierarchical feature extraction, may struggle to capture long-range dependencies and global context, which are crucial for accurate segmentation.</li> <li>Limited Localization Accuracy: CNNs designed for classification or localization tasks focus on identifying the presence of objects within an image but do not provide precise information about their boundaries. Segmenting an image requires pixel-level localization accuracy, which is not emphasized in traditional CNNs.</li> </ul> <p>The U-Net is specifically designed for semantic segmentation and addresses the above limitations. It employs a U-shaped architecture, consisting of a contracting path (encoder) and an expansive path (decoder), with skip connections between corresponding encoder and decoder layers. Advantages of using a UNet include... - U-shaped Architecture: U-Net's U-shaped design enables the preservation of high-resolution feature maps through skip connections, which helps in localizing objects accurately. - Context Aggregation: Skip connections in UNet allow the decoder to receive feature maps from different resolutions, incorporating both local and global contextual information. This aids in better segmentation by capturing fine details and understanding the overall context. - Dense Feature Propagation: U-Net uses upsampling and concatenation operations during the decoding phase, which helps in recovering the lost spatial resolution. This dense feature propagation aids in precise segmentation by retaining spatial information.</p>"},{"location":"computer%20vision/01_image_segmentation_floodnet/#bibliography","title":"Bibliography","text":"<p> <p></p> FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding Maryam Rahnemoonfar, Tashnim Chowdhury, Argho Sarkar, Debvrat Varshney, Masoud Yari, Robin Murphy arXiv preprint arXiv:2012.02951 2020 <p></p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/","title":"02 YOLO running biomechanics","text":"<pre><code>from itertools import cycle\nimport numpy as np\nimport pandas as pd\nfrom numpy.linalg import lstsq\n\nfrom ultralytics import YOLO\nfrom ultralytics.yolo.utils.plotting import *\nimport cv2\nfrom PIL import Image\nfrom IPython.display import Video\n\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\n</code></pre> <pre><code># use pretrained model\nVERSION = 'yolov8s-pose.pt'\n\n# load pretrained model\nyolo = YOLO('models/'+VERSION)\n</code></pre> <pre><code>save_path = '/Users/devindearaujo/Desktop/deep_learning/04_vision/'\n\nresults = yolo.predict(source_video, \n                    save=True, \n                    name=save_path,\n                    stream=True,\n                    boxes=False, \n                    verbose=False, # do not output to terminal\n                   )\n</code></pre> <pre><code># loop through results\n# get keypoint data\nstream_data = []\n\nfor i,frame in enumerate(results):\n    orig_img = frame.orig_img\n    kpts = frame.keypoints.data # Keypoints\n\n    data = {'frame':i, 'orig_img':orig_img, 'kpts':kpts}\n    stream_data.append(data)\n</code></pre> <pre>\n<code>Results saved to /Users/devindearaujo/Desktop/deep_learning/04_vision3\n</code>\n</pre> <pre><code>print(f'there are {len(stream_data)} frames in video')\n</code></pre> <pre>\n<code>there are 447 frames in video\n</code>\n</pre> <pre><code>def solve_line(x,y):\n\"\"\" \n    solve line equation by least squares\n    ref: https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html\n\n    arguments:\n        x,y: two sets of coordinates (x,y pairs)\n    \"\"\"\n    A = np.vstack([x, np.ones(len(x))]).T\n\n    m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n    return m,c\n</code></pre> <pre><code># fitting a line through \n# two sets of coordinates\n\nx = np.array([3.9210, 9.3849])\ny = np.array([4.1213, 5.2848])\n\nm,c, = solve_line(x,y)\n\nprint(\"Line Solution is y = {m}x + {c}\".format(m=m,c=c))\n</code></pre> <pre>\n<code>Line Solution is y = 0.2129431358553416x + 3.2863499643112064\n</code>\n</pre> <pre><code># plot line with random point to illustrate problem\n\n# random point\npoint = np.array([6.0, 4.8])\n\nplt.plot(x, y, 'o', label='Original data', markersize=10)\nplt.plot(x, m*x + c, 'r', label='Fitted line')\nplt.scatter(*point, c='purple')\nplt.legend()\n\nplt.show();\n</code></pre> <p>The plot above describes the problem visually, we have a line, and a point heading towards it. Where will that point intersect with the line? We need a function that will estimate this given the points current position and a function that will measure the error which will help us select the closest point in our frames.</p> <pre><code>def RMSE(x,y):\n\"\"\" root mean squared error\"\"\"\n    return np.sqrt(np.sum((x-y)**2))\n\ndef calc_intersection_point(m, c, point_coords:np.array):\n\"\"\"\n    calculates the expected point of contact\n    between a line given by y=mx+c and a point\n    given as a set of coordinates\n\n    arguments:\n        point_coords: x and y coords for point\n        m: slope of line\n        c: intercept of line\n    \"\"\"\n    point_x, point_y = point_coords\n\n    # x-coordinate of the intersection point\n    intersection_x = (point_y - c) / m\n\n    # y-coordinate of the intersection point\n    intersection_y = m * intersection_x + c\n\n    return intersection_x, intersection_y\n</code></pre> <p>mock example</p> <p>I've mocked up some data that describes the point (ie y coordinates are decreasing) as it moves closer and closer to the line. We want to find the point on the line where the distance or error is smallest.</p> <p>The line that they are approaching is the line plotted above.</p> <pre><code>descending_coords = np.array(\n    [[6.0, 5.0],\n    [6.0, 4.8 ],\n    [6.0, 4.58], # very close to line\n    [6.0, 4.2 ]  # passed through line\n    ]\n)\n\nfor points in descending_coords:\n    inter = calc_intersection_point(m,c,points)\n    print(RMSE(points, inter))\n</code></pre> <pre>\n<code>2.047453743016753\n1.1082358659217801\n0.0750962011173133\n1.7094177653631322\n</code>\n</pre> <p>as we can see, the coordinates <code>[6.0, 4.58]</code> are the ones that minimise the error between the line. </p> <pre><code># plot a frame with keypoints\ncolours = cycle(['#e02d86','#ff9d00','#01718e'])\n\nskeleton = np.array([\n            [16, 14], [14, 12], [15, 13], \n            [12, 13], [6, 12], \n            [6, 8], [7, 9], [8, 10], \n            [2, 3], [1, 2], [1, 3], [2, 4], \n            [3, 5], [4, 6], [5, 7]]\n            )\n\nlimb_labels = {\n    'left_shin':2,\n    'left_thigh':3,\n    'left_bicep':14,\n    'left_forearm':6,\n    'right_shin':0,\n    'right_thigh':1,\n    'right_bicep':5,\n    'right_forearm':6,\n}\n\n\ndef get_points(kpts):\n\"\"\"\n    return x,y coords from keypoints\n    \"\"\"\n    x = kpts[:,0]\n    y = kpts[:,1]\n    return x,y\n\ndef plot_keypoints(frame, plot_ticks=True):\n\"\"\"\n    frame: a dict containing keypoints and other data\n    \"\"\"\n    img = frame['orig_img']\n    img = cv2.cvtColor(img, code=cv2.COLOR_BGR2RGB)\n\n    fig, ax = plt.subplots()\n\n    ax.imshow(img)\n\n    # each object is a person!\n    for obj in frame['kpts']:\n        c = next(colours)\n        x,y = get_points(obj)\n\n        ax.scatter(x,y, s=2.5, c=c)\n\n    if plot_ticks == False:\n        plt.xticks([])\n        plt.yticks([])\n    plt.tight_layout();\n\nclass Limbs():\n    def __init__(self):\n        self.skeleton = skeleton\n        self.limb_labels = limb_labels\n\n    def get_limb_by_name(self, name:str):\n        \"return the indices of a limb\"\n        idx = self.limb_labels[name]\n        return self.skeleton[idx]\n</code></pre> <pre><code># Looks like RHS runner touches down on\n# frame 101\nframe = stream_data[101]\n\n# plot keyboints on base image\nplot_keypoints(frame)\n\n# plot the \"floor\"\n# get the line coords\nx = np.array([900, 625])\ny = np.array([650, 625])\n\nm,c, = solve_line(x,y)\n\n# plot floor points &amp; line\nplt.plot(x, y, 'o', c='r', label='Original data', markersize=5)\nplt.plot(x, m*x + c, 'r', label='Fitted line')\n\n# limb\nlimbs = Limbs()\nr_shin = frame['kpts'][1][limbs.get_limb_by_name('right_shin')]\nplt.plot(r_shin[:,0], r_shin[:,1], 'ro--', label='limb', markersize=5, linewidth=1.5);\n</code></pre> <p>Turns out there is a an issue with the model... While the YOLO is able to predict keypoints and bounding boxes, there doesn't seem to be anything that guarantees these keypoints will align with the same person across frames.. Below, in frame 106 the keypoints at index 0 align with the RHS runner, but in frame 107 the keypoints align with the LHS runner....</p> <pre><code>def plot_image_pairs(\n    fr1_id, fr2_id, stream_data, runner_id=1, figsize=(14,7), s=4.5, c='r'):\n\"\"\" \n    plot two images side by side with keypoints\n    for a single runner\n    \"\"\"\n    f1, f2 = stream_data[fr1_id], stream_data[fr2_id]\n\n    # get keypoint coords\n    x1, y1 = f1['kpts'][runner_id][:,0], f1['kpts'][runner_id][:,1]\n    x2, y2 = f2['kpts'][runner_id][:,0], f2['kpts'][runner_id][:,1]\n\n    # plot\n    fig, axs = plt.subplots(1,2, figsize=figsize)\n\n    axs[0].imshow(f1['orig_img']) # don't care about colour conversion\n    axs[1].imshow(f2['orig_img'])\n\n    axs[0].scatter(x1, y1, s=s, c=c)\n    axs[1].scatter(x2, y2, s=s, c=c)\n\n    axs[0].set_title(f'frame {fr1_id}')\n    axs[1].set_title(f'frame {fr2_id}');\n</code></pre> <pre><code>plot_image_pairs(106,107, stream_data, runner_id=0)\n</code></pre> <pre><code># dummy example\n\npoly = plt.Rectangle(\n    xy=(570,10), \n    width=1000-570, height=700, \n    fill=False\n)\n\npoints = np.array([[800,600], [800,400]])\n\npoly.contains_points(points)\n</code></pre> <pre>\n<code>array([ True,  True])</code>\n</pre> <pre><code># plot bounding box\nfig, ax = plt.subplots()\n\nbbox = plt.Rectangle(\n    xy=(570,10), \n    width=1000-570, height=700, \n    fill=False,\n    ec=\"#d91ec0\"\n)\n\nax.imshow(f_106['orig_img'], cmap='gray')\nax.scatter(x_106, y_106, s=5, c='r')\nax.add_patch(bbox)\nax.set_title('frame 106');\n</code></pre> <pre><code># check for a single frame\npoints_106 = f_106['kpts'][0][:,:2].numpy()\npoints_107 = f_107['kpts'][0][:,:2].numpy()\n\nbbox = plt.Rectangle(\n    xy=(570,10), \n    width=1000-570, height=700, \n    fill=False\n)\n# 106 is inside, 107 is outside.\nbbox.contains_points(points_106), bbox.contains_points(points_107)\n</code></pre> <pre>\n<code>(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True]),\n array([False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]))</code>\n</pre> <pre><code># box is empty!\nnp.sum(bbox.contains_points(points_107))\n</code></pre> <pre>\n<code>0</code>\n</pre> <pre><code># how often is this happening?\nres = []\n\nfor f in stream_data:\n    f_id = f['frame']\n\n    # get points from obj\n    points_0 = f['kpts'][0][:,:2].numpy()\n    points_1 = f['kpts'][1][:,:2].numpy()\n\n    contains_points_0 = np.where(np.sum(bbox.contains_points(points_0)) &gt; 0, True, False).item()\n    contains_points_1 = np.where(np.sum(bbox.contains_points(points_1)) &gt; 0, True, False).item()\n\n    res.append({\n        'frame':f_id,\n        'contains_points_0':contains_points_0,\n        'contains_points_1':contains_points_1\n    })\n\ndf = pd.DataFrame(res)\n</code></pre> <pre><code># only ~30% of the frames in \n# contains_points_0 column belong to runner on RHS\ndf.contains_points_0.mean(), df.contains_points_1.mean()\n</code></pre> <pre>\n<code>(0.32662192393736017, 0.6733780760626398)</code>\n</pre> <pre><code>df.head()\n</code></pre> frame contains_points_0 contains_points_1 0 0 False True 1 1 True False 2 2 True False 3 3 False True 4 4 False True <pre><code># put it all together\n# loop through stream data\n# if frame id is in the list \n# of problematic frames\n# swap data\n\nstream_data_fix = []\nframes_to_swap = df[df.contains_points_1 == False].frame.values\n\nfor f in stream_data:\n    # get id, image &amp; keypoints\n    f_id = f['frame']\n    orig_img = f['orig_img']\n    kpts = f['kpts']\n\n    # get object points (ie person 0 and 1)\n    points_0 = kpts[0]\n    points_1 = kpts[1]\n\n    if f_id in frames_to_swap:\n\n        # swap points\n        new_kpts = torch.tensor(np.array([points_1.numpy(),points_0.numpy()]))\n\n        # dims should match\n        assert new_kpts.shape == torch.Size([2, 17, 3])\n\n        data = {'frame':f_id, 'orig_img':orig_img, 'kpts':new_kpts}\n\n    else: \n        data = {'frame':f_id, 'orig_img':orig_img, 'kpts':kpts}\n\n    stream_data_fix.append(data)\n\n# sort so frame ids match\nstream_data_fix = sorted(stream_data_fix, key=lambda x: x['frame']) \n</code></pre> <pre><code>type(stream_data), len(stream_data), type(stream_data_fix), len(stream_data_fix)\n</code></pre> <pre>\n<code>(list, 447, list, 447)</code>\n</pre> <pre><code>plot_image_pairs(106,107, stream_data_fix, 1)\n</code></pre> <p>After the swap, all points belonging to the RHS runner are now indexed with <code>id=1</code></p> <pre><code>def calc_leg_floor_error(shin):\n\"\"\"\n    return the index and error\n    of the limb closest to the floor\n    \"\"\"\n    out = []\n    for i,points in enumerate(shin):\n        inter = calc_intersection_point(m,c,points)\n        e = RMSE(points, inter)\n        #out.append({i:e})\n        out.append({'idx':i, 'error':e})\n    return min(out, key=lambda x: list(x.values())[0])\n</code></pre> <pre><code>shin = stream_data_fix[0]['kpts'][0][limbs.get_limb_by_name('left_shin')][:,:2].numpy()\ncalc_leg_floor_error(shin)\n</code></pre> <pre>\n<code>{'idx': 0, 'error': 237.58837890625261}</code>\n</pre> <pre><code>RHS_runner_id = 1\nlimbs = Limbs()\n\nres = []\n\nfor f in stream_data_fix:\n\n    # data\n    f_id = f['frame']\n    orig_img = f['orig_img'][[RHS_runner_id]]\n    kpts = f['kpts'][RHS_runner_id]\n\n    # get leg coordinates\n    l_shin = kpts[\n        limbs.get_limb_by_name('left_shin')][:,:2].numpy()\n    r_shin = kpts[\n        limbs.get_limb_by_name('right_shin')][:,:2].numpy()\n\n    # get error for closest val\n    l_shin_err = calc_leg_floor_error(l_shin)\n    r_shin_err = calc_leg_floor_error(r_shin)\n\n    data = {\n        'frame':f_id, \n        'orig_img':orig_img, \n        'kpts':kpts,\n        'l_shin':l_shin,\n        'r_shin':r_shin,\n        'l_shin_err_id':l_shin_err['idx'],\n        'r_shin_err_id':r_shin_err['idx'],\n        'l_shin_err':l_shin_err['error'],\n        'r_shin_err':r_shin_err['error'],\n    }\n\n    res.append(data)\n</code></pre> <pre><code>df_legs = pd.DataFrame(res)\n\ndf_legs.head(2)\n</code></pre> frame orig_img kpts l_shin r_shin l_shin_err_id r_shin_err_id l_shin_err r_shin_err 0 0 [[[73, 45, 37], [73, 45, 37], [73, 45, 37], [7... [[tensor(721.7922), tensor(148.8591), tensor(0... [[940.49304, 509.91675], [804.28107, 435.70178]] [[736.6238, 616.66504], [762.37585, 461.6278]] 0 0 1581.408813 203.308350 1 1 [[[73, 45, 37], [73, 45, 37], [73, 45, 37], [7... [[tensor(726.7953), tensor(159.0453), tensor(0... [[933.1233, 482.19775], [783.6169, 438.49356]] [[743.5001, 630.4986], [760.86804, 479.3217]] 0 0 1878.947998 58.015564 <pre><code>fig, axs = plt.subplots(1,2, figsize=(10,4))\n\naxs[0].hist(df_legs['l_shin_err'], bins=40)\naxs[1].hist(df_legs['r_shin_err'], bins=40)\n\naxs[0].set_title(f\"error distribution (left), Q(25,50)\")\naxs[1].set_title(f\"error distribution (right), Q(25,50)\")\n\nquantiles = [.25, .50]\ncolors = ['orange', 'red', 'orange']\n\nfor q, c in zip(quantiles, colors):\n    lq = df_legs['l_shin_err'].quantile(q)\n    rq = df_legs['r_shin_err'].quantile(q)\n\n    axs[0].axvline(lq, 0, 1, color=c, ls='--')\n    axs[0].text(lq+30,40, f'{lq:.1f}', fontsize='x-small')\n    axs[1].axvline(rq, 0, 1, color=c, ls='--')\n    axs[1].text(rq+30, 40, f'{rq:.1f}', fontsize='x-small');\n</code></pre> <p>Manually counting the initial contact points for the RHS runner gives 23 for the right leg and 22 for the left. This is is a good enough guide for how many points to expect in this small dtaset. I have taken a wider percentile (10th) that includes more than 23 points, because it is likely that two points close together will have very similar errors.</p> <pre><code>lq = df_legs['l_shin_err'].quantile(.10)\nrq = df_legs['r_shin_err'].quantile(.10)\n\ndf_legs['l_initial_contact'] = np.where(df_legs['l_shin_err'] &lt; lq, True, False)\ndf_legs['r_initial_contact'] = np.where(df_legs['r_shin_err'] &lt; rq, True, False)\n\n# right leg initial contact 23 times\n# left leg initial contact 22 times\ndf_legs['l_initial_contact'].value_counts(), df_legs['r_initial_contact'].value_counts()\n</code></pre> <pre>\n<code>(l_initial_contact\n False    402\n True      45\n Name: count, dtype: int64,\n r_initial_contact\n False    402\n True      45\n Name: count, dtype: int64)</code>\n</pre> <pre><code># check a few frames \nplot_image_pairs(16, 34, stream_data_fix, 1)\n</code></pre> <pre><code>plot_image_pairs(359, 399, stream_data_fix, 1)\n</code></pre> <p>Not bad at all! As expected, if you look at the data you will see that there examples where two sequential frames have been flagged as initial contact - this is because these frames are close enough that both have low error.</p> <pre><code>plot_image_pairs(438, 437, stream_data_fix, 1)\n</code></pre> <p>The data was exported and some manual cleaning was done. Specifically, ensuring only a single point of contact was flagged for each leg as it hits the treadmill.</p> <pre><code>df_leg_adj = pd.read_csv('df_leg_adjusted.csv')\ndf_leg_adj = df_legs[['frame','orig_img','kpts','l_shin','r_shin','l_shin_err_id','r_shin_err_id']].merge(df_leg_adj, how='left', on='frame')\ndf_leg_adj.head(2)\n</code></pre> frame orig_img kpts l_shin r_shin l_shin_err_id r_shin_err_id l_initial_contact r_initial_contact l_shin_err r_shin_err 0 0 [[[73, 45, 37], [73, 45, 37], [73, 45, 37], [7... [[tensor(721.7922), tensor(148.8591), tensor(0... [[940.49304, 509.91675], [804.28107, 435.70178]] [[736.6238, 616.66504], [762.37585, 461.6278]] 0 0 False False 1581 203 1 1 [[[73, 45, 37], [73, 45, 37], [73, 45, 37], [7... [[tensor(726.7953), tensor(159.0453), tensor(0... [[933.1233, 482.19775], [783.6169, 438.49356]] [[743.5001, 630.4986], [760.86804, 479.3217]] 0 0 False False 1879 58 <pre><code>def get_shin_coords(x, col=0):\n    return x[0][col]\n</code></pre> <pre><code>X_df = df_leg_adj\n\nshins = ['l_shin', 'r_shin']\n\nX_data = []\n\nfor s in shins:\n    x_coord = X_df[s].apply(get_shin_coords, col=0)#.values\n    y_coord = X_df[s].apply(get_shin_coords, col=1)#.values\n    X_data.append(x_coord)\n    X_data.append(y_coord)\n</code></pre> <pre><code># X , y\nX = np.array(X_data).T\n#y_l = np.where(df_leg_adj['l_initial_contact'] == True, 1,0)\n#y_r = np.where(df_leg_adj['r_initial_contact'] == True, 1,0)\n\n# let's predict both left and right leg\n# to improve data sparsity and because\n# we know which leg is which based on skeleton\ny = np.sum(df_leg_adj[['l_initial_contact','r_initial_contact']], axis=1).values\n</code></pre> <pre><code>from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n</code></pre> <pre><code># training spit\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n</code></pre> <pre><code>param_grid = [\n    {\n        'n_estimators': [5, 10, 20], \n        'max_depth':[2,3,6], \n        'class_weight':['balanced', 'balanced_subsample']\n    }]\n\ngrid = GridSearchCV(\n    estimator=RandomForestClassifier(),\n    param_grid=param_grid,\n    refit=True,\n    n_jobs=-1,\n    verbose=1,\n)\n\ngrid.fit(X_train, y_train)\n\n# print best parameter after tuning \nprint(grid.best_params_,'\\n') \n\n# TEST\ntest_accuracy = grid.score(X_test, y_test)\nprint('Accuracy of the best parameters using the inner CV of')\nprint(f'the random search: {grid.best_score_:.3f}')\nprint(f'Accuracy on test set: {test_accuracy:.3f}')\n</code></pre> <pre>\n<code>Fitting 5 folds for each of 18 candidates, totalling 90 fits\n{'class_weight': 'balanced', 'max_depth': 6, 'n_estimators': 5} \n\nAccuracy of the best parameters using the inner CV of\nthe random search: 0.916\nAccuracy on test set: 0.900\n</code>\n</pre> <p>fit the model using the best params</p> <pre><code>#take best params\nclf = RandomForestClassifier(\n    **grid.best_params_,\n    random_state=123\n)\n\nclf.fit(X_train, y_train)\n\nclf.score(X_train, y_train), clf.score(X_test, y_test)\n</code></pre> <pre>\n<code>(0.9607843137254902, 0.9)</code>\n</pre> <pre><code>clf.predict(X_test)\n</code></pre> <pre>\n<code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])</code>\n</pre> <pre><code>y_test\n</code></pre> <pre>\n<code>array([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])</code>\n</pre> <pre><code>import torch\nimport torch.nn as nn\n</code></pre> <pre><code># convert to tensors\nX_train = torch.from_numpy(X_train)\nX_test = torch.from_numpy(X_test)\ny_train = torch.from_numpy(y_train)\ny_test = torch.from_numpy(y_test)\n</code></pre> <pre><code>def train_mlp_classifier(model, optim, criterion, X_train, y_train, X_test, y_test, num_epochs=100):\n    for epoch in range(num_epochs):\n\n        # zero grad\n        model.train()\n        optim.zero_grad()\n\n        # forward, loss\n        # -------------\n        # preds -&gt; (n examples, n classes) (357, 2)\n        preds = model(X_train)\n        loss = criterion(preds, y_train)\n\n        # backprop, step\n        loss.backward()\n        optim.step()\n\n        # validate\n        acc = eval_mlp_classifier(model, X_test, y_test)\n\n        log = f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val Acc: {acc:.3f}'\n\n        if epoch % 100 == 0:\n            print(log)\n\ndef eval_mlp_classifier(model, X_test, y_test):\n    model.eval()\n    out = model(X_test).argmax(dim=1) # get preds\n    correct = (out == y_test).sum()\n    acc = int(correct) / len(y_test)\n    return acc\n</code></pre> <pre><code>class MLP(nn.Module):\n\"\"\" \n    MLP classifier \n    --------------\n\n    n_input: number input features\n    n_output: number of classes\n    n_hidden: number of hidden layers\n    \"\"\"\n    def __init__(self, n_input=4, n_output=2, n_hidden=64):\n        super().__init__()\n\n        self.model = nn.Sequential(\n\n            nn.Linear(n_input, n_hidden*8),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n\n            nn.Linear(n_hidden*8, n_hidden*4),\n            nn.ReLU(),\n            #nn.Dropout(0.2),\n\n            nn.Linear(n_hidden*4, n_output),\n        )\n\n    def forward(self, x):\n        return self.model(x)\n</code></pre> <pre><code>DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# init\nmlp = MLP().to(DEVICE)\n\n# optimiser and loss\noptim = torch.optim.Adam(mlp.parameters(), lr=0.001, weight_decay=.05)\n\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor([.2, 1.]))\n</code></pre> <pre><code>train_mlp_classifier(mlp, optim, criterion, X_train, y_train, X_test, y_test, num_epochs=300)\n</code></pre> <pre>\n<code>Epoch: 000, Train Loss: 21.817, Val Acc: 0.133\nEpoch: 100, Train Loss: 1.545, Val Acc: 0.878\nEpoch: 200, Train Loss: 0.540, Val Acc: 0.889\n</code>\n</pre> <pre><code>mlp(X_test).argmax(1)\n</code></pre> <pre>\n<code>tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])</code>\n</pre> <pre><code>y_test\n</code></pre> <pre>\n<code>tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])</code>\n</pre> <p>Not bad, maybe more consistent that the random forrest but still misses a few points of contact.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#human-pose-estimation-yolov8","title":"Human Pose Estimation: YoloV8","text":""},{"location":"computer%20vision/02_YOLO_running_biomechanics/#classifying-running-biomechanics","title":"Classifying Running Biomechanics","text":"<p>In this notebook I aim to explore using YOLOv8 pose data to estimate running biomechanics. Specifically, I am going to limit the scope of the task to classifying what is called the \"initial contact\".</p> <p>The moment the gait cycle begins is when one foot comes in contact with the ground. The cycle lasts until the same foot again comes in contact with the ground. These moments of impact are referred to as intial contact.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#goal","title":"Goal","text":"<p>The goal then is to use yolov8 pose estimation data to build and train a classifier that will detect the point of initial contact.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#method","title":"Method","text":"<ol> <li>Extract pose data for runners using YOLOv8</li> <li>Using a single runner, clean data and identify initial contact</li> <li>Train a classifier on the data</li> </ol>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#pose-detection-with-yolov8","title":"Pose Detection with YOLOv8","text":""},{"location":"computer%20vision/02_YOLO_running_biomechanics/#identifying-initial-contact","title":"Identifying Initial Contact","text":"<p>I could go through the video frame by frame and flag the frames where a runner's foot has touched thr ground, but this seems tedious and if the dataset was any bigger it would quickly become infeasible to do this by hand.</p> <p>Instead, I'm going to build some tooling to assist with this. The idea is simple, using a single runner (maybe the chap on the right hand side: RHS), draw a line across the frame where the treadmill serface is located. Then find or estimate the point where the feet coordinates intersect or collide with this line. </p> <p>The distance between the line and the point of intersection can be measured by calculating the error between the two. Where the error is small, the foot is likely close to the line, we can assume the minima is the point of contact.</p> <p>To do this, we will need to get the coordinates of each runner and store them separately. </p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#sidebar-the-point-of-intersection-between-a-point-and-a-line","title":"Sidebar: the point of intersection between a point and a line","text":"<p>If I can identify where foot hits the ground, then I can then calssify the onset or initial contact. Once I have this I could probably identify other statistics like the stride or gait! But for now, the initial contact will do.</p> <p>Below is a simple example, building the mechanics that we will use in our real problem.</p> <p>Basically, I have a line, given by two sets of coordinates (x,y pairs) and I have a point that approaches that line. I need to find the point on the line where the distance between the line and points is the smallest (ie lowest error).</p> <p>There are plenty of libraries that can help solve this as well as more rigorous mathematics but the below is good enough for a rough POC.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#back-to-the-main-problem","title":"Back to the main problem","text":"<p>Now that we have a method for estimating where on a line a point will collide, we can establish a baseline (e.g. the \"floor\") in the frame. Since the camera here is stationary, it is simple to do this visually using the axis tick marks as a guide.</p> <p>To make this work, we willl need to identify at minimum the x,y coords of the left and right feet. We might want to identify the shin and even thigh. My thinking here is that we can use these coordinates in our classification model down the line. </p> <p>How will we identify these data points? If you look inside the <code>Annotator</code> class in the yolov8 codebase you will see a <code>skeleton</code> attribute, these are the indices of the coordinates that connect the various coordinates together. We can use these to find limbs.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#to-do","title":"to do","text":"<ul> <li>plot a frame, identify the \"floor\" using a frame where a leg is at it's the lowest.<ul> <li>we are using the runner on the RHS for this.</li> </ul> </li> <li>draw a baseline along these coordinates and check that the foot intersects with it.<ul> <li>we won't need all coords for this, only the feet and maybe shins.</li> </ul> </li> <li>plot the \"limb\" ie left or right shin to help visually inspect the data.<ul> <li>we can use the skeleton coordinates for this.</li> </ul> </li> </ul>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#sidebar-points-inside-polygon","title":"Sidebar: points inside polygon...","text":"<p>One way to solve this problem would be to... - check each frame, assert whether the keypoints are inside a bounding box that covers the runner of interest - identify the frames where this is not true - for these frames, simply switch the arrays containing the keypoints</p> <p>The nature of the video makes this task somewhat easier than it would be if the camera were not fixed!</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#swapping-problematic-points","title":"swapping problematic points","text":""},{"location":"computer%20vision/02_YOLO_running_biomechanics/#back-to-the-main-problem_1","title":"Back to the main problem","text":"<ul> <li>Extracting leg data. Specifically the foot and shin coordinatses.</li> <li>Calculating error between foot and floor</li> <li>building a table with the data we care about</li> </ul>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#error-distribution","title":"Error distribution","text":"<p>looking at the below plots, we can see that the lowest error values occur below the 25% quartile. We can use this to filter the data and roughly categorise the initial contact. This is just a starting point. Some manual curation afterwards will be done to clean up the data properly. Given this is only a small dataset (&lt;500 rows) this is feasible, but for large production tables I would refine this method and implement something more robust!</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#building-a-classifer","title":"Building a classifer","text":""},{"location":"computer%20vision/02_YOLO_running_biomechanics/#randomforestclassifier-w-gridsearchcv","title":"RandomForestClassifier w GridSearchCV","text":"<p>GridSearch is a process of performing hyperparameter tuning in order to find optimal values for a machine learing model. Generally speaking, there is no way to know in advance the best parameters for a model in a given problem setting. GridSearch helps by providing an automated way to search through a defined parameter space, and returns the optimal values. </p> <p>The problem I am facing with this data is that the event I are interested in, happens very infrequently. The majority class in this data would be every frame where the RHS runner's foot is not making contact with the treadmill. Basically, the class labels in this dataset are very imbalanced. </p> <p>There are many strategies to help deal with this. The method that improved model fit in this example was a balanced class weighting strategy. Here, the values of y are used to automatically adjust weights inversely proportional to the class frequencies. The <code>balanced_subsample</code> argument means this is performed for each bootstrap sample for every tree grown.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#mlp","title":"MLP","text":"<p>out of interest, see how an MLP does. The random forrest did a pretty good job. It certainly provides a much more efficient method for identifyign the inital contact points than the functional methods I built above to help create the data set in the first place. </p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#summary","title":"Summary","text":"<p>What a journey! This notebook was an exploration into using pose data from YOLOv8. Off the shelf, YOLO is a very impressive model but all you ever see online are videos of object detection on street scenes, people dancing, excersising or holding cups and pens up to their webcams. I wanted to understand how useable the data from YOLO actaully is and how it could use to estimate something specific. </p> <p>Classifying a runners gait is nothing new, but the idea here was to illustrate how much thought, preparation and work there is in exploring, cleaning and preparing the pose data for a downstream task.</p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#where-to-next","title":"Where to next?","text":"<p>There are a few things that I would have liked to try but this notebook got a bit big to fit it all in!</p> <p>I would have liked to see how the model performs on the second runner in the frame, this would help in understanding whether the model is able to generalise. I suspect that the model wouldn't perform well on the LHS runner because the magnitude of the X coordinates would be smaller that for the RHS runner due to their position on screen. </p> <p>A potential workaround would be to perform some simple data augmentation on the RHS coordinates, this would hopefully help the model to learn to be invariant to the scale. Another idea could be to include all keypoints for the RHS runner during training or even represent the data as a graph and apply graph representation learning techniques to the data, specifically, this could mean that we can encode in the feet or leg data information propagated from the other keypoints in the body. Maybe this would encode more useful information and assist better in the task. </p> <p>I'd also like to try these models on some more dynamic video content, like someone running outside or around a track or being followed with a handheld camera. </p>"},{"location":"computer%20vision/02_YOLO_running_biomechanics/#references","title":"references","text":"<ul> <li>physio-pedia running biomechanics</li> <li>pexels woman and man on treadmill</li> </ul>"},{"location":"fastai%20deep%20learning%202020/","title":"About","text":""},{"location":"fastai%20deep%20learning%202020/#fastai-deep-learning-for-coders-2020-course","title":"fastai: Deep Learning for Coders 2020 course","text":"<p>Notes from the 2020 version of the course.</p> <p>Note, the lesson numbers do not correspond to the fastai lesson numbers. This is because multiple notebooks are sometimes covered in one lecture, where it makes sense, I have kept these as part of a single notebook rather than separate.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/","title":"Lesson 01","text":"<pre><code>from fastai.vision.all import *\nfrom pathlib import Path\n</code></pre> <p>download one of the standard datasets provided by fasta, the Oxford-IIIT Pet Dataset which is a 37 category pet dataset with roughly 200 images for each class. </p> <pre><code>path = untar_data(URLs.PETS)/'images'\npath\n</code></pre> <pre>\n<code>Path('/storage/data/oxford-iiit-pet/images')</code>\n</pre> <pre><code># check a few image names to confirm that \n# dog images start with lowercase filenames\n# cat images start with uppercase filenames\n\nfiles = get_image_files(path)\nfiles[0],files[6]\n</code></pre> <pre>\n<code>(Path('/storage/data/oxford-iiit-pet/images/american_bulldog_146.jpg'),\n Path('/storage/data/oxford-iiit-pet/images/Siamese_56.jpg'))</code>\n</pre> <pre><code>def is_cat(x): return x[0].isupper()\n\ndls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat, item_tfms=Resize(224))\n</code></pre> <pre><code># check our function works!\nis_cat(files[0].name), is_cat(files[6].name)\n</code></pre> <pre>\n<code>(False, True)</code>\n</pre> <pre><code># take a look at some of the data\ndls.show_batch(max_n=6)\n</code></pre> <pre><code># check number of items in training and test datasets\nlen(dls.train_ds), len(dls.valid_ds)\n</code></pre> <pre>\n<code>(5912, 1478)</code>\n</pre> <pre><code>learn = cnn_learner(dls, resnet34, metrics=error_rate)\n</code></pre> <pre><code>learn.fine_tune(1)\n</code></pre> epoch train_loss valid_loss error_rate time 0 0.158638 0.023677 0.008119 00:45 epoch train_loss valid_loss error_rate time 0 0.061309 0.013070 0.004736 01:01 <pre><code>learn.show_results()\n</code></pre> <pre><code>img_01 = Path.cwd()/'lesson1_assets/img_1.PNG'\nimg_02 = Path.cwd()/'lesson1_assets/img_2.PNG'\n</code></pre> <pre><code>im1 = PILImage.create(img_01)\nim2 = PILImage.create(img_02)\n\nim1.to_thumb(192)\n</code></pre> <pre><code>im2.to_thumb(192)\n</code></pre> <p><code>learn.predict()</code> returns 3 things, the label (<code>True</code>/<code>False</code> in our case), the class that scored highest (1 or 0) and then the probabilities of each class.</p> <p>As a reminder, let's use <code>learn.dls.vocab.o2i</code> to check how the classes are mapped to our labels</p> <pre><code># show how our labels map to our vocab\nlearn.dls.vocab.o2i\n</code></pre> <pre>\n<code>{False: 0, True: 1}</code>\n</pre> <pre><code>is_cat, clas, probs = learn.predict(im1)\n\nis_cat, clas, probs\n</code></pre> <pre>\n<code>('True', tensor(1), tensor([2.7169e-10, 1.0000e+00]))</code>\n</pre> <p>Let's check both images...</p> <pre><code>images = [im1, im2]\n\nfor i in images:\n    is_cat,_,probs = learn.predict(i)\n\n    print(f\"Is this a cat?: {is_cat}.\")\n    print(f\"Probability it's a cat: {probs[1].item():.5f}\")\n</code></pre> <pre>\n<code>Is this a cat?: True.\nProbability it's a cat: 1.00000\n</code>\n</pre> <pre>\n<code>Is this a cat?: False.\nProbability it's a cat: 0.00000\n</code>\n</pre> <pre><code>from fastai.tabular.all import *\npath = untar_data(URLs.ADULT_SAMPLE)\npath\n</code></pre> <pre>\n<code>Path('/storage/data/adult_sample')</code>\n</pre> <pre><code>df = pd.read_csv(path/'adult.csv')\n\ndf.head()\n</code></pre> age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary 0 49 Private 101320 Assoc-acdm 12.0 Married-civ-spouse NaN Wife White Female 0 1902 40 United-States &gt;=50k 1 44 Private 236746 Masters 14.0 Divorced Exec-managerial Not-in-family White Male 10520 0 45 United-States &gt;=50k 2 38 Private 96185 HS-grad NaN Divorced NaN Unmarried Black Female 0 0 32 United-States &lt;50k 3 38 Self-emp-inc 112847 Prof-school 15.0 Married-civ-spouse Prof-specialty Husband Asian-Pac-Islander Male 0 0 40 United-States &gt;=50k 4 42 Self-emp-not-inc 82297 7th-8th NaN Married-civ-spouse Other-service Wife Black Female 0 0 50 United-States &lt;50k <pre><code>len(df)\n</code></pre> <pre>\n<code>32561</code>\n</pre> <pre><code>dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n    cont_names = ['age', 'fnlwgt', 'education-num'],\n    procs = [Categorify, FillMissing, Normalize])\n</code></pre> <p>I'm going to keep some of the data at the end of the set aside for testing. <code>df[:32500]</code> will select from row 0 to 32500, the remaining rows will not be seen by the model</p> <pre><code>splits = RandomSplitter(valid_pct=0.2)(range_of(df[:32500]))\n\nto = TabularPandas(df, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n                   cont_names = ['age', 'fnlwgt', 'education-num'],\n                   y_names='salary',\n                   splits=splits)\n</code></pre> <pre><code>dls = to.dataloaders(bs=64)\n</code></pre> <pre><code>dls.show_batch()\n</code></pre> workclass education marital-status occupation relationship race education-num_na age fnlwgt education-num salary 0 Private HS-grad Married-spouse-absent Other-service Unmarried White False 32.000000 128016.002920 9.0 &lt;50k 1 Private 7th-8th Married-civ-spouse Exec-managerial Wife White False 52.000000 194259.000001 4.0 &lt;50k 2 Private Some-college Widowed Exec-managerial Unmarried White False 31.000000 73796.004491 10.0 &lt;50k 3 Private Some-college Separated Other-service Not-in-family White False 64.000001 114993.998143 10.0 &lt;50k 4 Self-emp-not-inc Assoc-voc Married-civ-spouse Prof-specialty Husband White False 68.000000 116902.996854 11.0 &lt;50k 5 Private Bachelors Married-civ-spouse Prof-specialty Husband White False 42.000000 190178.999991 13.0 &gt;=50k 6 Self-emp-not-inc Prof-school Married-civ-spouse Prof-specialty Husband White False 66.000000 291362.001320 15.0 &lt;50k 7 Self-emp-not-inc Bachelors Married-civ-spouse Sales Husband White False 63.000001 298249.000475 13.0 &gt;=50k 8 Private Masters Divorced Tech-support Not-in-family White False 47.000000 606752.001736 14.0 &lt;50k 9 State-gov Bachelors Married-civ-spouse Exec-managerial Husband White False 42.000000 345969.005416 13.0 &gt;=50k <p>We can see that our y values have been turned into the categories 0 and 1.</p> <pre><code>dls.y.value_counts()\n</code></pre> <pre>\n<code>0    19756\n1     6244\nName: salary, dtype: int64</code>\n</pre> <pre><code>learn = tabular_learner(dls, metrics=accuracy)\n</code></pre> <pre><code>learn.fit_one_cycle(3)\n</code></pre> epoch train_loss valid_loss accuracy time 0 0.366288 0.354235 0.834769 00:06 1 0.367247 0.348617 0.839538 00:05 2 0.358275 0.345206 0.839077 00:06 <pre><code>learn.show_results()\n</code></pre> workclass education marital-status occupation relationship race education-num_na age fnlwgt education-num salary salary_pred 0 5.0 11.0 3.0 11.0 1.0 5.0 1.0 1.494630 1.838917 2.322299 0.0 1.0 1 5.0 12.0 3.0 8.0 1.0 5.0 1.0 -0.558852 -0.690051 -0.421488 0.0 0.0 2 3.0 10.0 3.0 11.0 6.0 3.0 1.0 0.174535 0.000144 1.146390 1.0 1.0 3 5.0 10.0 3.0 5.0 1.0 5.0 1.0 0.467889 -1.014015 1.146390 1.0 1.0 4 5.0 16.0 5.0 9.0 4.0 5.0 1.0 -1.365576 4.387854 -0.029518 0.0 0.0 5 5.0 10.0 1.0 5.0 2.0 5.0 1.0 0.174535 0.616141 1.146390 0.0 0.0 6 5.0 10.0 3.0 2.0 6.0 5.0 1.0 1.494630 0.898075 1.146390 0.0 1.0 7 5.0 12.0 3.0 5.0 6.0 5.0 1.0 0.101196 -0.713219 -0.421488 1.0 1.0 8 7.0 2.0 3.0 4.0 1.0 5.0 1.0 -0.338836 0.932638 -1.205427 0.0 0.0 <pre><code># pick some random rows of the df\nsample_df = df.iloc[[32513,32542,32553]]\n\nsample_df\n</code></pre> age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary 32513 23 Private 209955 HS-grad 9.0 Never-married Craft-repair Not-in-family White Male 0 0 40 United-States &lt;50k 32542 34 Private 98283 Prof-school 15.0 Never-married Tech-support Not-in-family Asian-Pac-Islander Male 0 1564 40 India &gt;=50k 32553 35 Self-emp-inc 135436 Prof-school 15.0 Married-civ-spouse Prof-specialty Husband White Male 0 0 50 United-States &gt;=50k <p>Lets loop through these rows and make predictions, printing out the predicted class, the probabilities and the actual class.</p> <pre><code>for i, r in sample_df.iterrows():\n    row, clas, probs = learn.predict(r)\n    print(f'the predicted class is {clas}')\n    print(f'with a probability of {probs}')\n    print(f'the actual class was {r.salary}')\n</code></pre> <pre>\n<code>the predicted class is 0\nwith a probability of tensor([0.9911, 0.0089])\nthe actual class was &lt;50k\n</code>\n</pre> <pre>\n<code>the predicted class is 0\nwith a probability of tensor([0.6258, 0.3742])\nthe actual class was &gt;=50k\n</code>\n</pre> <pre>\n<code>the predicted class is 1\nwith a probability of tensor([0.0919, 0.9081])\nthe actual class was &gt;=50k\n</code>\n</pre>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#lesson-1-deep-learning-for-coders","title":"Lesson 1: Deep Learning for Coders","text":"<p>06-09-2020</p> <p>This notebook will go over some of the practical material discussed in lesson 1 of the fastai 2020 course.</p> <p>I am going to cover 2 examples here - classification from image data and tabular data</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#example-1-computer-vision","title":"Example 1: Computer Vision","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2001/#create-an-imagedataloader","title":"Create an ImageDataLoader","text":"<ul> <li> <p>Fastai needs to know where to get the image labels from. Normally these labels are part of the filenames or folder structure. In this case the filenames contain the animal breeds.</p> </li> <li> <p><code>american_bulldog_146.jpg</code> and <code>Siamese_56.jpg</code> for example</p> <ul> <li>it so happens that cat breeds start with an uppercase letter.</li> </ul> </li> <li> <p>For this example, we will not classify all 37 breeds. We will instead classify whether the images are of dogs or cats.</p> </li> </ul> <p>First define a function <code>is_cat</code> that checks whether the first letter in the image label is uppercase. <code>is_cat</code> returns a boolean value that will be used as the new image label.  - <code>from_name_func</code> applies the function to our data to create the labels we need.</p> <ul> <li> <p><code>valid_pct=0.2</code>: hold 20% of the data aside for the validation set, 80% will be used for the training set</p> </li> <li> <p><code>item_tfms=Resize(224)</code>: resize images to 224x224</p> <ul> <li>fastai provides item transforms (applied to each image in this case) and batch transform which are applied to a batch of items at a time.</li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#create-a-cnn_learner","title":"Create a <code>cnn_learner</code>","text":"<ul> <li>using the <code>resnet34</code> architecture<ul> <li>resnet paper</li> </ul> </li> <li>this is a pretrained learner, which means when we fit the model, we will not need to train from scratch, rather, we will only fine tune the model</li> <li>by default, <code>freeze_epochs</code> is set to 1</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#testing-the-model","title":"Testing the model","text":"<ul> <li>Lets load in a picture of a cat and a dog to check the model</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#example-2-tabular","title":"Example 2: Tabular","text":"<p>For this example we will use the Adults data set. Our goal is to predict if a person is earning above or below $50k per year using information such as age, working class, education and occupation. There are about 32K rows in the dataset.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#create-an-tabulardataloader","title":"Create an TabularDataLoader","text":"<p>Again we create data loader using the <code>path</code>. We need to specify some information such as the y variable (the value we want to predict), and we also need to specify which columns contain categorical values and which contain continuous variables. Do this using <code>cat_names</code> and <code>cont_names</code>.</p> <p>Some data processing needs to occur.. - we need to specify how to handle missing data. Info below from the docs     - <code>FillMissing</code> by default sets <code>fill_strategy=median</code>     - <code>Normalize</code> will normalize the continuous variables (substract the mean and divide by the std)     - <code>Categorify</code> transform the categorical variables to something similar to <code>pd.Categorical</code></p> <p>This is another classification problem. Our goal is to predict whether a persons salary was below 50k (0) or above (1).</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2001/#check-the-model-by-making-predictions-on-the-dataset","title":"Check the model by making predictions on the dataset","text":"<p>using the data that was held aside which the model has not yet seen.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/","title":"Lesson 02","text":"<pre><code># !conda install -c conda-forge librosa -y\n</code></pre> <pre><code>from fastai.vision.all import *\nfrom fastai.vision.data import *\n\nimport matplotlib.pyplot as plt\n# hi-res plots\n%config InlineBackend.figure_format = 'retina'\n\nfrom pathlib import Path\n\n# sound library &amp; widget to play audio\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\n</code></pre> <pre><code>path = Path.cwd()\n\ndata_path = path/'lesson2_assets/cqt_data'\naudio_file = path/'lesson2_assets/A3_1.wav'\n\n# take a look at the filenames\ndata_path.ls()[1]\n</code></pre> <pre>\n<code>Path('/notebooks/lesson2_assets/cqt_data/A3_1.jpg')</code>\n</pre> <pre><code>y, sr = librosa.load(audio_file, mono=True)\nipd.Audio(y, rate=sr)\n</code></pre>                      Your browser does not support the audio element.                  <pre><code>doc(librosa.feature.chroma_cqt)\n</code></pre> <pre><code>plt.figure(figsize=(5,5))\n\nC = librosa.feature.chroma_cqt(y=y, sr=sr)\n\nlibrosa.display.specshow(C, y_axis='chroma');\n</code></pre> <p>For comparison, here is the same note visualised using a spectrogram...</p> <ul> <li>\"A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time.\" wiki</li> <li>There is a lot more information within this plot (such as the fundamental frequency and harmonics above it), however using these images would make our classification task much harder.</li> </ul> <pre><code>plt.figure(figsize=(5,5))\n\nD = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n\nlibrosa.display.specshow(D, y_axis='log');\n</code></pre> <pre><code>fnames = get_image_files(data_path)\n</code></pre> <pre><code>def label_func(fname): return fname.name[:2]\n\nlabel_func(fnames[37]) # verify the funciton works\n</code></pre> <pre>\n<code>'B3'</code>\n</pre> <pre><code>audio = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=label_func,\n    item_tfms=Resize(128)\n    )\n</code></pre> <pre><code>dls = audio.dataloaders(data_path, bs=32)\n\ndls.show_batch()\n</code></pre> <pre><code># no transformation applied\ndls.valid.show_batch(max_n=4, nrows=1)\n</code></pre> <p>Here is a list of available transforms..</p> <pre><code>aug_transforms(\n    mult=1.0,\n    do_flip=True,\n    flip_vert=False,\n    max_rotate=10.0,\n    min_zoom=1.0,\n    max_zoom=1.1,\n    max_lighting=0.2,\n    max_warp=0.2,\n    p_affine=0.75,\n    p_lighting=0.75,\n    xtra_tfms=None,\n    size=None,\n    mode='bilinear',\n    pad_mode='reflection',\n    align_corners=True,\n    batch=False,\n    min_scale=1.0,\n)\n</code></pre> <pre><code>aug_tfms = aug_transforms(max_lighting=0.8, do_flip=True, flip_vert=True, max_rotate=0)\n\naudio = audio.new(item_tfms=Resize(128), batch_tfms=aug_tfms)\ndls = audio.dataloaders(data_path)\ndls.train.show_batch(max_n=4, nrows=1)\n</code></pre> <pre><code>learn = cnn_learner(dls, resnet34, metrics=error_rate)\n</code></pre> <p>Before training, let's use <code>learn.lr_find</code> to help find a good learning rate. Two values are returned by running <code>lr_find</code></p> <ul> <li>one tenth of the minimum before the divergence</li> <li>when the slope is the steepest</li> </ul> <pre><code>lr_min, lr_steep = learn.lr_find()\n</code></pre> <pre><code># plot the values returned by lr_find\nlearn.recorder.plot_lr_find()\n\nplt.axvline(x=lr_min, color='red')\nplt.axvline(x=3e-3, color='green')\nplt.axvline(x=lr_steep, color='red');\n</code></pre> <p>I'm going to pick a value inbetween the suggested lr's for training.</p> <pre><code>lr_max = 3e-3\n\nlearn.fit_one_cycle(n_epoch=5, lr_max=lr_max)\n</code></pre> epoch train_loss valid_loss error_rate time 0 2.412440 1.861958 0.642857 00:02 1 1.202116 0.856408 0.261905 00:01 2 0.763907 0.548905 0.190476 00:01 3 0.543375 0.206846 0.095238 00:01 4 0.412221 0.038176 0.023810 00:01 <pre><code>learn.recorder.plot_loss()\n</code></pre> <pre><code>interp.plot_top_losses(k=4, figsize=(6,6))\n</code></pre> <pre><code>interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n</code></pre> <pre><code>learn.save('base_cqt_model')\n</code></pre> <pre>\n<code>Path('models/base_cqt_model.pth')</code>\n</pre> <p>Fine tune to try improve accuracy..</p> <pre><code>learn.fine_tune(1)\n</code></pre> epoch train_loss valid_loss error_rate time 0 0.000892 0.002096 0.000000 00:01 epoch train_loss valid_loss error_rate time 0 0.000499 0.000041 0.000000 00:02 <pre><code>interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n</code></pre>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#lesson-2-deep-learning-for-coders","title":"Lesson 2: Deep Learning for Coders","text":"<p>12-09-2020</p> <p>Lesson 2 goes a little deeper into computer vision and the fastai library by going a little deeper into the DataBlocks and DataLoaders. </p> <p>The course notebook uses Bing Images to download image data, the idea being that we curate our own data set for this exercise. Fastai provides some methods and instructions for doing this, you can see details in the notebook</p> <p>I have taken a different route to gathering data. My goal for this notebook is to build a model that is able to classify musical pitches.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#audio-data","title":"Audio Data","text":"<ul> <li> <p>generate audio samples using MIDI.</p> <ul> <li>I will not be worrying about sharps/flats simply to reduce complexity</li> </ul> </li> <li> <p>use librosa to process audio signals and generate chromagrams using the Constant Q Transform</p> <ul> <li>The Constant Q does a good job at isolating pitch but is not sensitive to octaves, thus, all audio samples are in the same octave.</li> <li>stackexchange</li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#load-in-data","title":"Load in Data","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2002/#sidebar-generating-a-chromagram","title":"sidebar.. generating a chromagram","text":"<p>Below is a sample note (A3 on the piano) followed by a demonstration of how to generate a Constant-Q chromagram. The Y axis is displaying the note name for convenience. These were removed to create the training data set.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#image-data","title":"Image Data","text":"<p>The filenames contain the classes that we are trying to predict. We need to define a function that will grab the first 2 characters of each file name to use as labels. This will look familiar to lesson one, excet we have more classes to predict</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#from-data-to-dataloader","title":"From Data to DataLoader","text":"<p>What is a DataBlock? - \"The data block API takes its name from the way it's designed: every bit needed to build the DataLoaders object (type of inputs, targets, how to label, split...) is encapsulated in a block, and you can mix and match those blocks\" - docs</p> <p>Breaking down the Block - the tutorial in the docs does a good job of stepping through building a block from scratch..</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#steps","title":"Steps","text":"<ol> <li>Start with an empty <code>DataBlock</code>.<ul> <li><code>dblock = DataBlock()</code></li> </ul> </li> <li>Tell the block how you want to assemble your items using a <code>get_items</code> function.<ul> <li>we will use <code>get_image_files</code> as we did in lesson 1.</li> </ul> </li> <li>Let the block know how/where to get our labels from in <code>get_y</code>.<ul> <li>the lesson notebook uses <code>parent_label</code> which inherits the label from the parent folder. We need to use the <code>label_func</code> we created for this task.</li> </ul> </li> <li>Specify the types of our data (images and labels).<ul> <li><code>ImageBlock</code> and <code>CategoryBlock</code>.</li> <li><code>blocks=(ImageBlock, CategoryBlock)</code>.</li> </ul> </li> <li>Decide how we want to split our data into training and valid datasets.<ul> <li>we will randomly split (80% training, 20% validation).</li> </ul> </li> <li>Specify any item transforms or batch transforms.</li> </ol>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#sidebar-data-augmentation-and-transforms","title":"Sidebar: Data Augmentation and Transforms","text":"<p>fastai provides a number of transforms that can be applied to data. In the case of computer vision, augmentation is useful for introducing variety into the dataset. Consider facial recognition, in production, you may not always be dealing with descent portraits; camera angle, lighting, perspective and lighting conditions may vary. Augmentation introduces some of these concepts into our traing and validation set.</p> <p>In the context of the data I am working with, not all transformations may be useful. I would not expect these images to suffer from perspective warping or rotation, however, mirroring the image on the vertical could be useful, as could increasing and decreasing brightness and contrast.</p> <p>Here is a quick example of how to apply some transforms to a batch of images at a time using <code>aug_transforms</code></p> <p>I am not going to apply any of these for training in this notebook.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#create-a-cnn_learner-and-train-the-model","title":"Create a <code>cnn_learner</code> and Train the model","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2002/#interpretation","title":"Interpretation","text":"<ul> <li>the model is performing quite well, only one note was incorrectly predicted (G3 predicted for F3 actual)</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2002/#summary","title":"Summary","text":"<p>This wasn't the hardest problem in the world. The Constant Q transform really simplifies pitch detection. I think this is an interesting problem space because there are opportunities to progress these examples; I'd like to try classify all 12 notes (by adding sharps/flats), then try multi-label classification using a phrase of notes, and hopefully then addressing the issue of identifying notes across octaves.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/","title":"Lesson 03 pt 1","text":"<pre><code>from fastai.vision.all import *\nfrom pathlib import Path\n</code></pre> <p>For this model we are going to create a digit classifier that will be able to classify an image as a 3 or a 7. Fastai has a sample of the MNIST dataset that we will be using.</p> <p>First, let's load the data and check that there are indeed, 3's an 7's in one of the folders. The folder layout is fairly typical, separate training and validation sets.</p> <pre><code>path = untar_data(URLs.MNIST_SAMPLE)\n</code></pre> <pre><code>(path/'train').ls()\n</code></pre> <pre>\n<code>(#2) [Path('/storage/data/mnist_sample/train/7'),Path('/storage/data/mnist_sample/train/3')]</code>\n</pre> <pre><code># 1 - check file names\nthrees = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\nthrees\n</code></pre> <pre>\n<code>(#6131) [Path('/storage/data/mnist_sample/train/3/10.png'),Path('/storage/data/mnist_sample/train/3/10000.png'),Path('/storage/data/mnist_sample/train/3/10011.png'),Path('/storage/data/mnist_sample/train/3/10031.png'),Path('/storage/data/mnist_sample/train/3/10034.png'),Path('/storage/data/mnist_sample/train/3/10042.png'),Path('/storage/data/mnist_sample/train/3/10052.png'),Path('/storage/data/mnist_sample/train/3/1007.png'),Path('/storage/data/mnist_sample/train/3/10074.png'),Path('/storage/data/mnist_sample/train/3/10091.png')...]</code>\n</pre> <pre><code># 2 - use PIL to open image\nim3_path = threes[1]\nim3 = Image.open(im3_path)\nim3\n</code></pre> <pre><code># 3 - use PyTorch to view tensor values\ntensor(im3)[4:10,4:10]\n</code></pre> <pre>\n<code>tensor([[  0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,  29],\n        [  0,   0,   0,  48, 166, 224],\n        [  0,  93, 244, 249, 253, 187],\n        [  0, 107, 253, 253, 230,  48],\n        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)</code>\n</pre> <pre><code># 4 - Getting creative with Pandas\nim3_t = tensor(im3)\ndf = pd.DataFrame(im3_t[4:15,4:22])\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 29 150 195 254 255 254 176 193 150 96 0 0 0 2 0 0 0 48 166 224 253 253 234 196 253 253 253 253 233 0 0 0 3 0 93 244 249 253 187 46 10 8 4 10 194 253 253 233 0 0 0 4 0 107 253 253 230 48 0 0 0 0 0 192 253 253 156 0 0 0 5 0 3 20 20 15 0 0 0 0 0 43 224 253 245 74 0 0 0 6 0 0 0 0 0 0 0 0 0 0 249 253 245 126 0 0 0 0 7 0 0 0 0 0 0 0 14 101 223 253 248 124 0 0 0 0 0 8 0 0 0 0 0 11 166 239 253 253 253 187 30 0 0 0 0 0 9 0 0 0 0 0 16 248 250 253 253 253 253 232 213 111 2 0 0 10 0 0 0 0 0 0 0 43 98 98 208 253 253 253 253 187 22 0 <pre><code># open all images, convert to tensor, store in list\n\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nlen(three_tensors), len(seven_tensors)\n</code></pre> <pre>\n<code>(6131, 6265)</code>\n</pre> <pre><code># lets check one of\nshow_image(three_tensors[1]);\n</code></pre> <pre><code>stacked_sevens = torch.stack(seven_tensors).float()/255\nstacked_threes = torch.stack(three_tensors).float()/255\nstacked_threes.shape\n</code></pre> <pre>\n<code>torch.Size([6131, 28, 28])</code>\n</pre> <p><code>tensor</code> jargon - rank: the number of axis - shape: the size of each axis</p> <pre><code>print('rank:',stacked_threes.ndim,'\\n',\n      'shape:', stacked_threes.shape)\n</code></pre> <pre>\n<code>rank: 3 \n shape: torch.Size([6131, 28, 28])\n</code>\n</pre> <p>We have 6,131 images of size 28x28 </p> <pre><code>mean3 = stacked_threes.mean(dim=0)\nshow_image(mean3);\n</code></pre> <pre><code>mean7 = stacked_sevens.mean(dim=0)\nshow_image(mean7);\n</code></pre> <pre><code># here is a random three for comparison\na_3 = stacked_threes[1]\nshow_image(a_3);\n</code></pre> <p>How could we calculate how similar a 3 is from this ideal 3? Typically there are two methods</p> <ul> <li>take the absolute value of differences (where there are negatives, replace with postive)<ul> <li>This is called the mean absolute difference or L1 norm</li> </ul> </li> <li>take the mean squared difference (which also makes all results positive) then take the square root<ul> <li>This is called the root mean squared error (RMSE) or L2 norm.</li> </ul> </li> </ul> <pre><code># 3\n# L1 Norm\n# mean absolute difference\n\ndist_3_abs = (a_3 - mean3).abs().mean()\ndist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\ndist_3_abs, dist_3_sqr\n</code></pre> <pre>\n<code>(tensor(0.1114), tensor(0.2021))</code>\n</pre> <pre><code># 7\n# L1 Norm\n# mean absolute difference\n\ndist_3_abs = (a_3 - mean7).abs().mean()\ndist_3_sqr = ((a_3 - mean7)**2).mean().sqrt()\ndist_3_abs, dist_3_sqr\n</code></pre> <pre>\n<code>(tensor(0.1586), tensor(0.3021))</code>\n</pre> <p>The distance between our \"ideal\" 3 and the real 3 is less than the distance from the real 3 to \"ideal\" 7. This is good - it means both methods will work and our simple model will give the correct prediction.</p> <p>PyTorch already provides these loss functions for us (though RMSE is only MSE, but we can work with that).</p> <pre><code># check results with PyTorch\n\nF.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()\n</code></pre> <pre>\n<code>(tensor(0.1586), tensor(0.3021))</code>\n</pre> <pre><code>valid_3_tens = torch.stack([tensor(Image.open(o)) \n                            for o in (path/'valid'/'3').ls()])\nvalid_3_tens = valid_3_tens.float()/255\nvalid_7_tens = torch.stack([tensor(Image.open(o)) \n                            for o in (path/'valid'/'7').ls()])\nvalid_7_tens = valid_7_tens.float()/255\nvalid_3_tens.shape,valid_7_tens.shape\n</code></pre> <pre>\n<code>(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))</code>\n</pre> <p><code>mnist_distance</code> calculates the difference between our ideal 3 and every 3 in the validation set. </p> <p>We call <code>mean((-1,-2))</code> in our fuction. The tuple <code>(-1,-2)</code> represents a range of axes, so the last -1, and second last -2. <code>mean((-1,-2))</code> says; take the mean over the last two axes in the tensor. Why? These axes represent the verticle and horizontal dimensions of an image. After taking the mean over the these axes, we have one axis left which indexes over the 1,010 images we have. </p> <pre><code># calculate the mean absolute error\n\ndef mnist_distance(a,b):\n    return (a-b).abs().mean((-1,-2))\n\n# check the function\nmnist_distance(a_3, mean3) # great!\n</code></pre> <pre>\n<code>tensor(0.1114)</code>\n</pre> <p>This works for a single image, but in order to calculate the overall accuracy, we want to calculate this distance to the ideal 3 for all images in the validation set. This can be achieved using a loop, but there is another way - broadcasting.</p> <p>Take a look at the shape of <code>valid_3_tens</code> and <code>mean3</code>, they are different...</p> <pre><code>valid_3_tens.shape, mean3.shape\n</code></pre> <pre>\n<code>(torch.Size([1010, 28, 28]), torch.Size([28, 28]))</code>\n</pre> <p>Now calculate the distance between the two...</p> <pre><code>valid_3_dist = mnist_distance(valid_3_tens, mean3)\n\nvalid_3_dist, valid_3_dist.shape\n</code></pre> <pre>\n<code>(tensor([0.1290, 0.1223, 0.1380,  ..., 0.1337, 0.1132, 0.1097]),\n torch.Size([1010]))</code>\n</pre> <p>our function has returned the distance for every single image as a rank-1 tensor of length 1,010. </p> <p>This is because we have added a subtraction <code>(a-b)</code> into our distance function and when PyTorch performs this subtraction, it uses broadcasting which will automatically expand the tensor with smaller rank to have the same size as the one with larger rank. Once this has happened, PyTorch will perform an element wise operation over the two tensors. </p> <p>In our case, PyTorch is treating <code>mean3</code> (a rank 2 tensor) as if it were 1,010 copies of that tensor.</p> <p>You can see that by performing a subtraction and checking the shape</p> <pre><code>(valid_3_tens-mean3).shape\n</code></pre> <pre>\n<code>torch.Size([1010, 28, 28])</code>\n</pre> <p>There are a couple of important points about how broadcasting is implemented, which make it valuable not just for expressivity but also for performance:</p> <ul> <li>PyTorch doesn't actually copy mean3 1,010 times. It pretends it were a tensor of that shape, but doesn't actually allocate any additional memory</li> <li>It does the whole calculation in C (or, if you're using a GPU, in CUDA, the equivalent of C on the GPU), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).</li> </ul> <p>source</p> <pre><code>def is_3(x): \n    return mnist_distance(x,mean3) &lt; mnist_distance(x,mean7)\n</code></pre> <pre><code># let's test it\n# you can convert a boolean to a float \n\nis_3(a_3), is_3(a_3).float()\n</code></pre> <pre>\n<code>(tensor(True), tensor(1.))</code>\n</pre> <p>Calculate the accuracy for each 3 and 7 by taking the average of <code>is_3</code> for all 3s and it's inverse for all 7s. </p> <pre><code>accuracy_3s =      is_3(valid_3_tens).float() .mean()\naccuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n\naccuracy_3s, accuracy_7s, (accuracy_3s+accuracy_7s)/2\n</code></pre> <pre>\n<code>(tensor(0.9168), tensor(0.9854), tensor(0.9511))</code>\n</pre> <p>Not bad, over 90% accuracy using a very simple model. This was also a very simple problem, 3s and 7s look very different so it's not really a surprise that this was so effective. </p> <p>We will nowe look at a system that will do some learning (automatically modify itself to improve its performance)</p> <p>In the next part, we will implement this more advanced model</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#lesson-3-under-the-hood-training-a-digit-classifier","title":"Lesson 3: Under the Hood: Training a Digit Classifier","text":"<p>20-09-2020</p> <p>This notebook will go over some of the practical material discussed in lesson 3 of the fastai 2020 course, namely, some different ways of training a digit classifier using the MNIST data set.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#primer","title":"Primer","text":"<ul> <li>load in some data</li> <li>visualise it</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#visualising-data","title":"Visualising Data","text":"<p>There are a number of ways we can check our data to get a better understanding of how it is structured and how it looks</p> <ol> <li>Take a look inside one of the folders and check file names</li> <li>Use PIL to open one of the images</li> <li>Use PyTorch/Numpy to check the tensor/array values</li> <li>Get creative</li> </ol>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#sidebar-think-about-the-problem","title":"Sidebar - think about the problem","text":"<p>Before jumping into solution mode (ie apply deep learning to everything!) think about the problem space and how you might be able to solve it. </p> <p>For this problem (digit recognition) using a simple average might be enough to get a descent result. That is exactly what we will do first.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#method-1-pixel-similarity","title":"Method 1: Pixel Similarity","text":"<ul> <li>find the average pixel value for every pixel of the 3s and 7s<ul> <li>this will give us 2 group averages that represent the \"ideal\" 3 and 7</li> </ul> </li> <li>to classify a digit, check the similarity against the ideal</li> <li>this method will form our baseline that we will improve upon later</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#step-1-organise-data","title":"Step 1: Organise data","text":"<ul> <li>create a tensor by stacking all of our 3s together<ul> <li>we will use list comprehension for this</li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#step-2-compute-the-average-pixel-value","title":"Step 2: Compute the average pixel value","text":"<ul> <li>For every pixel position, compute the average over all the images of the intensity of that pixel.</li> <li>To do this<ul> <li>combine all images into a single 3-dimensional tensor using <code>stack</code> which  \"Concatenates sequence of tensors along a new dimension.\"</li> <li>PuyTorch needs us to cast the <code>int</code> values to floats in order to compute the average.</li> <li>\"Generally when images are floats, the pixel values are expected to be between 0 and 1, so we will also divide by 255 here\" source</li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#step-3-compute-the-ideal-digits","title":"Step 3: Compute the ideal digits","text":"<ul> <li>compute the mean along the 0th dimension</li> <li>by visualising this ideal 3 we can indeed see that it represents a 3!</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#a-simple-model","title":"A simple model","text":"<p>A validation set is usually used to help avoid overfitting, our model has no trained components so this isn't going to be an issue, but let's stick with best practices.</p> <p>We will also define a function that will decide if an arbitrary image is a 3 or a 7. This will be achieved by measuring the distance between this digit and our ideal digits and determining which ideal it is closer to. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%201/#a-funtion-to-make-a-decision","title":"A funtion to make a decision","text":"<p><code>is_3</code> is going to use <code>mnist_distance</code> to figure out whether an image is a 3 or a 7. To do this it will check whether the distance between a digit, x and <code>mean3</code> is less than the difference between x and <code>mean7</code>.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/","title":"Lesson 03 pt 2","text":"<pre><code>from fastai.vision.all import *\nfrom utils import *\n</code></pre> <pre><code># define a quadratic function \n\ndef f(x): return x**2\n</code></pre> <p>I had some trouble finding the <code>plot_function</code> function so found the source code from the forums.</p> <pre><code>def plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n    x = torch.linspace(min,max)\n    fig,ax = plt.subplots(figsize=figsize)\n    ax.plot(x,f(x))\n    if tx is not None: ax.set_xlabel(tx)\n    if ty is not None: ax.set_ylabel(ty)\n    if title is not None: ax.set_title(title)\n</code></pre> <pre><code># plot that function\nplot_function(f, 'x', 'x**2')\n\n# start with a random value for a parameter\nplt.scatter(-1.5, f(-1.5), color='red');\n</code></pre> <p>Now we need to see what would happen if we increase or decrease our parameter by a small amout. The goal, to find the lowest point in the curve. We do this by calculating the gradient at a particular point. We can change our weight by a small amount in the direction of the slope, then calculate the loss, make an adjustment and repeat until we reach our goal.</p> <pre><code># define a vector xt\n# requires_grad_ lets OyTorch know we need to calculate gradients\n\nxt = tensor([3.,4.,10.]).requires_grad_()\nxt\n</code></pre> <pre>\n<code>tensor([ 3.,  4., 10.], requires_grad=True)</code>\n</pre> <pre><code># define a function x that takes a vector (rank 1 tensor)\n# and returns a scalar (rank 0 tensor)\n# do this by summing the result of x**2\n\ndef f(x): return (x**2).sum()\n\nyt = f(xt)\nyt\n</code></pre> <pre>\n<code>tensor(125., grad_fn=&lt;SumBackward0&gt;)</code>\n</pre> <p>calling <code>backward</code> refers to back propagation, which is the process of calculating the derivative of each layer. We can then use <code>.grad</code> to view the gradients.</p> <p>We can confirm that the derivative of <code>x**2</code> is <code>2*x</code></p> <pre><code>yt.backward()\nxt.grad\n</code></pre> <pre>\n<code>tensor([ 6.,  8., 20.])</code>\n</pre> <pre><code>time = torch.arange(0,20).float()\n\n# speed is a quadratic with some added noise\nspeed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n\nplt.scatter(time,speed);\n</code></pre> <p>We need to create a function that estimates at any time, the speed of the rollercoaster.</p> <p>Start with a random guess, here let's use a quadratic</p> <p><code>a*(time**2) + (b*time) + c</code></p> <pre><code># here the input t is time, params will be a list a,b,c\n\ndef f(t, params):\n    a,b,c = params\n    return a*(t**2) + (b*t) + c\n</code></pre> <p>So the goal is to find some function, or the best imaginable function that fits the data (we have simplified to finding the best quadratic function which is defined by the params <code>a</code>, <code>b</code> and <code>c</code>). So finding the best <code>f</code> can be achieved by finding the best <code>a</code>, <code>b</code> and <code>c</code> values.</p> <p>We will need a loss function for this task.</p> <pre><code>def mse(preds, targets): return ((preds-targets)**2).mean()\n</code></pre> <pre><code>params = torch.randn(3).requires_grad_()\n</code></pre> <pre><code>orig_params = params.clone() # save these to check later\n</code></pre> <p>2. Calculate the predictions using our function</p> <p>Then check how close/far the predictions are from the targets.</p> <pre><code>preds = f(time, params)\n</code></pre> <pre><code>def show_preds(preds, ax=None):\n    if ax is None: ax=plt.subplots()[1]\n    ax.scatter(time, speed)\n    ax.scatter(time, to_np(preds), color='r')\n    ax.set_ylim(-300,100)\n</code></pre> <pre><code>show_preds(preds)\n</code></pre> <p>3. Calculate the loss</p> <p>the goal is to improve the loss so we will need to know the gradients</p> <pre><code>loss = mse(preds, speed)\nloss\n</code></pre> <pre>\n<code>tensor(4422.5112, grad_fn=&lt;MeanBackward0&gt;)</code>\n</pre> <p>4. Calculate the gradients</p> <p>Then use these to improve the parameters. We need a learning rate for this</p> <pre><code>loss.backward()\nparams.grad\n</code></pre> <pre>\n<code>tensor([-20635.2617,  -1319.6385,   -108.2016])</code>\n</pre> <pre><code>lr = 1e-5\nparams.grad * lr\n</code></pre> <pre>\n<code>tensor([-0.2064, -0.0132, -0.0011])</code>\n</pre> <p>5. Step the weights</p> <p>update the parameters based on the gradients we have calculated.</p> <p>Stepping the weights is <code>w -= gradient(w) * lr</code></p> <p><code>.data</code> is a special attribute in torch that means we don't want the gradient calculated. Here, we do not want the gradient calculated for the step we are doing, we only want the gradiend of the function f to be calculated</p> <pre><code>params.data -= lr * params.grad.data\nparams.grad = None # delete the gradients we already had\n</code></pre> <pre><code># check if loss has improved\n# previous was 4422.5\n\npreds = f(time, params)\nmse(preds, speed)\n</code></pre> <pre>\n<code>tensor(1354.7021, grad_fn=&lt;MeanBackward0&gt;)</code>\n</pre> <pre><code>show_preds(preds)\n# the preds have indeed improved!\n</code></pre> <pre><code># repeat a few times\n\ndef apply_step(params, prn=True):\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    loss.backward()\n    params.data -= lr * params.grad.data\n    params.grad = None\n    if prn: print(loss.item())\n    return preds\n</code></pre> <p>6. Repeat the process by looping through and making improvements</p> <pre><code># repeat 10 times\n\nfor i in range(10):\n    apply_step(params)\n</code></pre> <pre>\n<code>1354.7021484375\n774.1762084960938\n664.3204956054688\n643.5296630859375\n639.5927734375\n638.8450317382812\n638.7008666992188\n638.6709594726562\n638.6625366210938\n638.6583862304688\n</code>\n</pre> <p>We can visualise this to see that for each step, an entirely different quadratic function is being tried</p> <pre><code>params = orig_params.detach().requires_grad_()\n</code></pre> <pre><code>_,axs = plt.subplots(1,4,figsize=(12,3))\n\nfor ax in axs: \n    show_preds(apply_step(params, False), ax)\nplt.tight_layout()\n</code></pre> <p>7. Stop</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#lesson-3-under-the-hood-training-a-digit-classifier","title":"Lesson 3: Under the Hood: Training a Digit Classifier","text":"<p>26-09-2020</p> <p>This notebook will go over some of the practical material discussed in lesson 3 of the fastai 2020 course, namely, some different ways of training a digit classifier using the MNIST data set.</p> <p>In part 1 we used a simple model that had no learned components. In this notebook, we will explore a smarter solution. We will apply this method back to the MNIST problem in the next notebook.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#stocastic-gradient-descent-sgd","title":"Stocastic Gradient Descent (SGD)","text":"<p>Instead of measuring how close something is to an \"ideal\" image, we could find a set of weights for each pixel, the highest weights will be associated with pixels that are most likely to be black for a particular category (in our case, number).</p> <p>This can be represented by a function and a set of weight values for each possible category - ie the probability of a category being an 8.</p> <p><code>def prob_eight(x,w) = (x*w)sum()</code></p> <p>Here <code>x</code> is a vector that represents an image (with all rows stacked up) and <code>w</code> is a vector of weights.</p> <p>With this function, we now just need a way to gradually update the weights to make them better and better until they are as good as they can get. </p> <p>In other words, we want to find the specific values of <code>w</code> that will cause the result of our function to be high when passed images of 8s and low for other digits. So by updating <code>w</code> we are optimising the function to recognise 8s.</p> <p>The steps we will follow are: 1. Initialize the weights.     - start out with a random guess. 2. For each image, use these weights to predict whether it appears to be a 3 or a 7. 3. Based on these predictions, calculate how good the model is (its loss). 4. Calculate the gradient, which measures for each weight, how changing that weight would change the loss. 5. Step (that is, update) all the weights based on that calculation. 6. Go back to the step 2, repeat the process. 7. Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer).</p> <p>source</p> <p>We will use a very simple example for illustration purposes.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#calculating-gradients","title":"Calculating Gradients","text":"<p>The slope of a line can be described as the rate of change of a verticle variable with respect to a horizontal variabe. This is the gradient. By calculating the gradient, it will tell us how much we have to change each weight to make our model better. </p> <p>A Derivative is the instantaneous rate of change at a particular point. So how much is y changing with respect to x at that point. You can achieve this by calculating the slope of a tangent line. This video provides a good explanation of the concept.</p> <p>We can calculate the derivative for any function. For the quadratic above, the derivative is another function that calculates change, rather than the value. If we know how our function changes at a particular value, then we know how to minimize it. </p> <p>\"This is the key to machine learning: having a way to change the parameters of a function to make it smaller. Calculus provides us with a computational shortcut, the derivative, which lets us directly calculate the gradients of our functions\" source</p> <p>PyTorch helps us do this using vector calculus. eg.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#stepping-with-a-learning-rate","title":"Stepping with a learning rate","text":"<p>Now that we know how to calculate the slope of our function, that tells us if we change our input a little bit, how will our out change correspondingly. </p> <p>let's call the weights <code>w</code> to update them we do the following</p> <p><code>w -= gradient(w) * lr</code></p> <p>So update <code>w</code> by subtracting the gradient of <code>w</code> multiplied by the learning rate <code>lr</code>. This process is known as, stepping your parameters, using and optimiser step. </p> <p>Defining a good learning rate is one of the key principles in machine learning. An intuitive way to think about it is, if the <code>lr</code> is too small, it will take you forever to reach the goal, if it is too big, you will over shoot that target. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#end-to-end-gradient-descent-example","title":"End-to-end Gradient Descent example.","text":"<p>Use gradient descent to see how finding a minimum can be used to train a model to fir better data..</p> <p>Let's measure the speed of a rollercoaster as it goes over a rise - starting fast, then slowing down at the peak, then speeding up again.</p> <p>If we measured the speed at 20 second intervals it might look something like this.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#implement-the-7-steps","title":"Implement the 7 steps","text":"<p>1. Initialize the weights (params) to random values. Let PyTorch know that we will need to calculate the gradients.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2003%20pt%202/#summary","title":"Summary","text":"<p>We have just seen that by comparing the outputs of our model to our targets using a loss function, we are able to minimize the loss by gradually improving our weights (params). </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/","title":"Lesson 04","text":"<pre><code># imports and things we need from previous notebooks\n\nfrom fastai.vision.all import *\n\n# data \npath = untar_data(URLs.MNIST_SAMPLE)\n\nthrees = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\n\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\n\nstacked_sevens = torch.stack(seven_tensors).float()/255\nstacked_threes = torch.stack(three_tensors).float()/255\n\nvalid_3_tens = torch.stack([tensor(Image.open(o)) \n                            for o in (path/'valid'/'3').ls()])\nvalid_3_tens = valid_3_tens.float()/255\nvalid_7_tens = torch.stack([tensor(Image.open(o)) \n                            for o in (path/'valid'/'7').ls()])\nvalid_7_tens = valid_7_tens.float()/255\n</code></pre> <pre><code>def plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n    x = torch.linspace(min,max)\n    fig,ax = plt.subplots(figsize=figsize)\n    ax.plot(x,f(x))\n    if tx is not None: ax.set_xlabel(tx)\n    if ty is not None: ax.set_ylabel(ty)\n    if title is not None: ax.set_title(title)\n</code></pre> <pre><code># concat 3s and 7s, then reshape into a matrix\n# so that each row is 1 image, with all rows and columns in a single vector\ntrain_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n\n# label the data\n# 3 == 1\n# 7 == 0\n# we need this to be a matrix\n# unsqueeze will do this for us\ntrain_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n\n# check the shape\ntrain_x.shape,train_y.shape\n</code></pre> <pre>\n<code>(torch.Size([12396, 784]), torch.Size([12396, 1]))</code>\n</pre> <pre><code># in PyTorch we need data to be in a tuple for each row\n# zip will help us with this\ndset = list(zip(train_x,train_y))\n\n# take a look at the first thing\nx,y = dset[0]\n\nx.shape, y\n</code></pre> <pre>\n<code>(torch.Size([784]), tensor([1]))</code>\n</pre> <p><code>(torch.Size([784]), tensor([1]))</code> this matches what we would expect</p> <pre><code># repeat for validation\nvalid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\nvalid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\nvalid_dset = list(zip(valid_x,valid_y))\n</code></pre> <p>Now we have training and validation data sets</p> <p>1. Randomly initialise weights for each pixel - use <code>torch.randn</code> to create tensor of randomly initialised weights</p> <pre><code>def init_params(size, var=1.0): \n    return (torch.randn(size)*var).requires_grad_()\n</code></pre> <pre><code>weights = init_params((28*28,1))\n\nweights.shape\n</code></pre> <pre>\n<code>torch.Size([784, 1])</code>\n</pre> <p>We need to add a bias term because just using <code>weights*pixels</code> will not be flexible enough. Our function will always be equal to zero when the pixels are equal to zero.  </p> <pre><code>bias = init_params(1)\n</code></pre> <p><code>y = w*x+b</code> is the formula for a line, where <code>w</code> are the weights, <code>b</code> is the bias. In neural network jargon, the weights and bias will be our parameters. </p> <p>This linear equation is one of the two fundamental equations of any neural network. The other is an activation function that we will see shortly.</p> <p>Let's use this to calculate a prediction for one image... <code>weights.T</code> will transpose the weights, this is done to make sure the rows and columns match up for our multiplication</p> <pre><code>(train_x[0]*weights.T).sum() + bias\n</code></pre> <pre>\n<code>tensor([13.3326], grad_fn=&lt;AddBackward0&gt;)</code>\n</pre> <p>Now we need to do this for all images. A for loop will be too slow. In PyTorch we can perform matrix multiplication using the @ operator OR by using <code>torch.matmul()</code>.</p> <pre><code># define a linear function that will \n# multiple the input by weights then add a bias term\n\ndef linear1(xb): return xb@weights + bias\n\npreds = linear1(train_x)\npreds\n</code></pre> <pre>\n<code>tensor([[13.3326],\n        [ 9.1011],\n        [ 9.4999],\n        ...,\n        [-1.0068],\n        [15.9130],\n        [12.6228]], grad_fn=&lt;AddBackward0&gt;)</code>\n</pre> <p>Notice the result are the same as we just saw above. We can confirm our function is working and can also see that the operation is performed for every image in <code>train_x</code></p> <p>checking accuracy - if a prediction is above the threshold, ie if &gt; 0 then it is a 3, less than 0, 7. - so we check if a prediction is greater than our threshold of 0, then check these against the validation set. - this will return true when a row is correctly predicted - we can convert these to floats using <code>.float()</code> then take their mean to check overall accuracy of our randomly initialised model</p> <pre><code>threshold = 0.0\naccuracy = (preds &gt; threshold).float() == train_y\naccuracy\n</code></pre> <pre>\n<code>tensor([[ True],\n        [ True],\n        [ True],\n        ...,\n        [ True],\n        [False],\n        [False]])</code>\n</pre> <pre><code>accuracy.float().mean().item()\n</code></pre> <pre>\n<code>0.484188437461853</code>\n</pre> <p>Let's change one of the weights by a small amount to see how accuracy is affected.</p> <pre><code>weights[0]+= 1.0001 # increase the weigh a little\npreds = linear1(train_x)\naccuracy2 = ((preds &gt; threshold).float() == train_y).float().mean().item()\naccuracy2\n</code></pre> <pre>\n<code>0.484188437461853</code>\n</pre> <p>This is exactly the same as before. We have a problem, when we calculate the change, our gradient is now 0, this is because if we change a single pixel by a very small amount we might not change an actual prediction.</p> <p>So because our gradient is 0, our step will be 0 which means our prediction will be unchanged. </p> <p>So our accuracy loss function is not very good. A small change in our weights does not result in a small change in accuracy, so we will have zero gradients.</p> <p>We need a new function that won't have a zero gradient, it needs to be more sensitive to small changes, so that a slightly better prediction needs to have a slightly better loss.</p> <p>In other words, then the predictions are close to the targets the loss needs to be small, when they are far away, it needs to be big.</p> <p>So let's create a new function to address this issue.</p> <pre><code># MNIST loss\n\ndef mnist_loss(preds, targets):\n    return torch.where(targets==1., 1.-preds, preds).mean()\n</code></pre> <pre><code># test case\n\nt = torch.tensor([1,0,1])         # targets\np = torch.tensor([0.9, 0.4, 0.2]) # predictions\n\n\n# this is the same as mnist_loss but before the mean\ntorch.where(t==1, 1-p, p)\n</code></pre> <pre>\n<code>tensor([0.1000, 0.4000, 0.8000])</code>\n</pre> <p><code>torch.where</code> is like list comprehension for tensors.</p> <p>This function returns a lower loss when predictions are more accurate and a higher loss when they are not.</p> <p>But for this to work, we need our predictions to be between 0 and 1, otherwise things do not work.</p> <pre><code>p2 = torch.tensor([1.2, -1, 0])   # predictions outside 0, 1 range\n\ntorch.where(t==1, 1-p2, p2)\n</code></pre> <pre>\n<code>tensor([-0.2000, -1.0000,  1.0000])</code>\n</pre> <pre><code>def sigmoid(x) : return 1 / (1 + torch.exp(-x))\n</code></pre> <pre><code>plot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)\n</code></pre> <pre><code># MNIST loss with sigmoid\n\ndef mnist_loss(predictions, targets):\n    preds = predictions.sigmoid()\n    return torch.where(targets==1., 1.-preds, preds).mean()\n</code></pre> <pre><code>coll = range(15)\n\ndl = DataLoader(coll, batch_size=5, shuffle=True)\nlist(dl)\n</code></pre> <pre>\n<code>[tensor([ 4, 12,  5,  6,  3]),\n tensor([10,  9,  2,  0, 14]),\n tensor([ 7, 13,  8, 11,  1])]</code>\n</pre> <pre><code># re-initialise weights and params\nweights = init_params((28*28,1))\nbias = init_params(1)\n</code></pre> <pre><code># create a data loader\ndl = DataLoader(dset, batch_size=256)\n\n# grab the first x and y\nxb, yb = first(dl)\n\n# check the shape\nxb.shape, yb.shape\n</code></pre> <pre>\n<code>(torch.Size([256, 784]), torch.Size([256, 1]))</code>\n</pre> <pre><code># repeat for validation set\nvalid_dl = DataLoader(valid_dset, batch_size=256)\n</code></pre> <pre><code># grab a mini batch to test on\nbatch = train_x[:4]\nbatch.shape\n</code></pre> <pre>\n<code>torch.Size([4, 784])</code>\n</pre> <pre><code># make some predictions\npreds = linear1(batch)\npreds\n</code></pre> <pre>\n<code>tensor([[-1.1306],\n        [-3.9293],\n        [-0.6736],\n        [-6.9805]], grad_fn=&lt;AddBackward0&gt;)</code>\n</pre> <pre><code>loss = mnist_loss(preds, train_y[:4])\nloss\n</code></pre> <pre>\n<code>tensor(0.8495, grad_fn=&lt;MeanBackward0&gt;)</code>\n</pre> <pre><code># calculate gradients\nloss.backward()\n\nweights.grad.shape, weights.grad.mean(), bias.grad\n</code></pre> <pre>\n<code>(torch.Size([784, 1]), tensor(-0.0153), tensor([-0.1070]))</code>\n</pre> <pre><code># take those 3 steps and put it in a function\n\ndef calc_grad(xb, yb, model):\n    preds = model(xb)\n    loss = mnist_loss(preds, yb)\n    loss.backward()\n</code></pre> <pre><code># test it\n\ncalc_grad(batch, train_y[:4], linear1)\n\nweights.grad.shape, weights.grad.mean(), bias.grad\n</code></pre> <pre>\n<code>(torch.Size([784, 1]), tensor(-0.0306), tensor([-0.2140]))</code>\n</pre> <pre><code># zero the gradients\nweights.grad.zero_()\nbias.grad.zero_()\n</code></pre> <pre>\n<code>tensor([0.])</code>\n</pre> <p>The last step is to work out how to update the weights and bias based on the gradient and learning rate. </p> <p><code>train_epoch</code> loops through the data loader, grab x batch and y batch, calculate the gradient, make a prediction and calculate the loss. Go through each parameter (weights and bias) and for each update with gradient * lr, then zero these in prep for the next loop. </p> <p><code>p.data</code> is used because PyTorch keeps track of all operations so it can calculate the gradients, but we do not want the gradients to be calculated on the gradient descent step. </p> <pre><code>def train_epoch(model, lr, params):\n    for xb, yb in dl:\n        calc_grad(xb, yb, model) \n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()        \n</code></pre> <p><code>batch_accuracy</code> is similar to the previous loss function, but since we use a sigmoid, which constrains our preds between 0 and 1, we need to check whether preds &gt; 0.5.  </p> <pre><code>def batch_accuracy(xb, yb):\n    preds = xb.sigmoid()\n    correct = (preds&gt;0.5) == yb # check predictions against target\n    return correct.float().mean()\n</code></pre> <pre><code>batch_accuracy(linear1(train_x[:4]), train_y[:4])\n</code></pre> <pre>\n<code>tensor(0.)</code>\n</pre> <pre><code># check accuracy for every batch in the validation set\n# stack converts the list of items into tensor\n\ndef validate_epoch(model):\n    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n    return round(torch.stack(accs).mean().item(), 4)\n</code></pre> <pre><code>validate_epoch(linear1)\n</code></pre> <pre>\n<code>0.407</code>\n</pre> <p>This is a starting point, let's train for one epoch and see if accuracy improves.</p> <p>as a reminder, the linear1 function was...  - <code>def linear1(xb): return xb@weights + bias</code></p> <pre><code>lr = 1.\nparams = weights, bias\ntrain_epoch(linear1, lr, params)\nvalidate_epoch(linear1)\n</code></pre> <pre>\n<code>0.6932</code>\n</pre> <pre><code>for i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1), end=' ')\n</code></pre> <pre>\n<code>0.8242 0.9042 0.9355 0.9501 0.9555 0.9614 0.9638 0.9677 0.9736 0.9751 0.9751 0.976 0.977 0.9775 0.9775 0.978 0.9785 0.979 0.9795 0.979 </code>\n</pre> <p>Accuracy has indeed improved! We have built an SGD optimizer that has reached about 97% accuracy.</p> <pre><code>nn.Linear?\n</code></pre> <pre><code># remove our linear function\n# in place for torch module\n\n# creates a matrix of size 28*28\n# with bias of 1\n\nlinear_model = nn.Linear(28*28,1)\n</code></pre> <pre><code># check model params\n\nw,b = linear_model.parameters()\n\nw.shape, b.shape\n</code></pre> <pre>\n<code>(torch.Size([1, 784]), torch.Size([1]))</code>\n</pre> <p>Create a basic optimiser</p> <ul> <li>pass in params to optimise and lr</li> <li>store these away</li> <li>step though each param (weights and bias) and for each, update with gradient * lr</li> <li>zero the gradients in prep for the next step</li> </ul> <pre><code>class BasicOptim:\n    def __init__(self, params, lr): \n        self.params, self.lr = list(params), lr\n\n    def step(self, *args, **kwargs):\n        for p in self.params: \n            p.data -= p.grad.data * self.lr\n\n    def zero_grad(self, *args, **kwargs):\n        for p in self.params: \n            p.grad = None\n</code></pre> <pre><code># create an optimiser by passing in parameters from model\nopt = BasicOptim(linear_model.parameters(), lr)\n</code></pre> <pre><code># simplify the training loop\ndef train_epoch(model):\n    for xb, yb in dl:\n        calc_grad(xb, yb, model)\n        opt.step()\n        opt.zero_grad()\n</code></pre> <pre><code>validate_epoch(linear_model)\n</code></pre> <pre>\n<code>0.5075</code>\n</pre> <p>Now create a function <code>train_model</code> that will call <code>train_epoch</code> on our model for the specified number of epochs</p> <pre><code>def train_model(model, epochs):\n    for i in range(epochs):\n        train_epoch(model)\n        print(validate_epoch(model), end=' ')\n</code></pre> <pre><code>train_model(linear_model, 20)\n</code></pre> <pre>\n<code>0.4932 0.7876 0.852 0.916 0.9345 0.9497 0.957 0.9638 0.9658 0.9677 0.9697 0.9721 0.9731 0.9751 0.9755 0.9765 0.9775 0.9775 0.978 0.9785 </code>\n</pre> <p>The results are very similar to what we have seen before.</p> <p>Fastai provides <code>SGD</code> that we can use instead of writing our own, again the results are very similar.</p> <pre><code>linear_model = nn.Linear(28*28, 1)\nopt = SGD(linear_model.parameters(), lr)\ntrain_model(linear_model, 20)\n</code></pre> <pre>\n<code>0.4932 0.9091 0.8056 0.9043 0.9316 0.9443 0.9546 0.9619 0.9648 0.9668 0.9692 0.9707 0.9731 0.9746 0.976 0.976 0.9775 0.9775 0.9785 0.979 </code>\n</pre> <p>Let's refactor some more, using some fastai classes. The <code>Learner</code> implements everything we have implemented manually.</p> <pre><code># Previously we used DataLoader not DataLoaders\n\ndls = DataLoaders(dl, valid_dl)\n\nlearn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)\nlearn.fit(10)\n</code></pre> epoch train_loss valid_loss batch_accuracy time 0 0.480832 0.461122 0.843474 00:00 1 0.466804 0.441299 0.908734 00:00 2 0.450758 0.422136 0.934249 00:00 3 0.433590 0.403750 0.943572 00:00 4 0.416052 0.386223 0.949460 00:00 5 0.398675 0.369610 0.952404 00:00 6 0.381799 0.353943 0.956820 00:00 7 0.365630 0.339228 0.957311 00:00 8 0.350289 0.325455 0.959764 00:00 9 0.335835 0.312599 0.960255 00:00 <p>The results again are very similar, but with some additional functionality (like printing out results in a pretty table!</p> <pre><code>def basic_net(xb):\n    res = xb@w1 + b1\n    res = res.max(tensor(0.0))\n    res = res@w2 + b2\n    return res\n</code></pre> <pre><code>plot_function(F.relu)\n</code></pre> <p>Like we have seen previously.. - <code>w1</code> and <code>w2</code> are weight tensors - <code>b1</code> and <code>b2</code> are bias tensors</p> <p>we can initialise these the same as we have done previously..</p> <p><code>w1</code> has 30 output activations, so in order for <code>w2</code> to match it require 30 input activations. </p> <pre><code>w1 = init_params((28*28,30))\nb1 = init_params(30)\nw2 = init_params((30,1))\nb2 = init_params(1)\n</code></pre> <p>We can simplify further using PyTorch... </p> <p>What we did in <code>basic_net</code> was called function composition, where we passed the results of one function into another function and then into another function. This is what neural nets are doing with linear layers and activation functions. <code>nn.Sequential()</code> will do this for us...</p> <pre><code>simple_net = nn.Sequential(\n    nn.Linear(28*28, 30), # 28*28 in, 30 out\n    nn.ReLU(),\n    nn.Linear(30,1)       # 30 in 1 out\n)\n</code></pre> <pre><code>learn = Learner(dls, simple_net, opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)\n\nlearn.fit(40,0.1)\n</code></pre> epoch train_loss valid_loss batch_accuracy time 0 0.301185 0.414520 0.506379 00:00 1 0.142869 0.223012 0.814033 00:00 2 0.079959 0.114103 0.916094 00:00 3 0.053115 0.077652 0.939156 00:00 4 0.040578 0.060868 0.953876 00:00 5 0.034118 0.051373 0.963690 00:00 6 0.030368 0.045362 0.965653 00:00 7 0.027905 0.041246 0.965162 00:00 8 0.026117 0.038246 0.968597 00:00 9 0.024726 0.035950 0.969087 00:00 10 0.023596 0.034124 0.971050 00:00 11 0.022651 0.032629 0.972031 00:00 12 0.021847 0.031376 0.973503 00:00 13 0.021151 0.030301 0.974485 00:00 14 0.020542 0.029363 0.974485 00:00 15 0.020002 0.028535 0.975957 00:00 16 0.019519 0.027797 0.976448 00:00 17 0.019083 0.027134 0.976938 00:00 18 0.018687 0.026535 0.977920 00:00 19 0.018325 0.025991 0.978901 00:00 20 0.017992 0.025495 0.978901 00:00 21 0.017684 0.025040 0.978901 00:00 22 0.017398 0.024621 0.979392 00:00 23 0.017131 0.024233 0.979392 00:00 24 0.016881 0.023874 0.980373 00:00 25 0.016645 0.023541 0.980373 00:00 26 0.016424 0.023232 0.980373 00:00 27 0.016214 0.022943 0.980864 00:00 28 0.016015 0.022673 0.980864 00:00 29 0.015827 0.022421 0.981354 00:00 30 0.015648 0.022185 0.981845 00:00 31 0.015476 0.021963 0.982336 00:00 32 0.015313 0.021756 0.982336 00:00 33 0.015156 0.021561 0.982336 00:00 34 0.015006 0.021378 0.982826 00:00 35 0.014863 0.021204 0.982826 00:00 36 0.014725 0.021041 0.982336 00:00 37 0.014592 0.020886 0.982336 00:00 38 0.014464 0.020740 0.982336 00:00 39 0.014341 0.020601 0.982336 00:00 <pre><code># this is what our model now looks like\nlearn.model\n</code></pre> <pre>\n<code>Sequential(\n  (0): Linear(in_features=784, out_features=30, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=30, out_features=1, bias=True)\n)</code>\n</pre> <pre><code># plot the loss\nlearn.recorder.plot_loss()\n</code></pre> <pre><code># learn.recorder.values hold the table values above\n# lets plot the accuracy\n\nplt.plot(L(learn.recorder.values).itemgot(2));\n</code></pre> <pre><code># let's visualise some of the parameters\n\n# 1. grab your model\nm = learn.model # (0): Linear(in_features=784, out_features=30, bias=True)\n\n# 2. look inside and grab the weights and biases\nw,b = m[0]. parameters()\n\n# 3. grab first (or any) row, reshape, and plot\nshow_image(w[0].view(28,28), figsize=(4,4))\n</code></pre> <pre>\n<code>&lt;AxesSubplot:&gt;</code>\n</pre> <pre><code>from fastai.vision.all import *\nfrom pathlib import Path\n</code></pre> <pre><code>path = Path.cwd()/'datasets/fastai/mnist_sample'\n</code></pre> <pre><code>dls = ImageDataLoaders.from_folder(path)\n\nlearn = cnn_learner(dls, resnet18, pretrained=False,\n                   loss_func=F.cross_entropy, metrics=accuracy)\n\nlearn.fit_one_cycle(1, 0.1)\n</code></pre> epoch train_loss valid_loss accuracy time 0 0.086805 0.025215 0.994603 00:11"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#lesson-4-under-the-hood-training-a-digit-classifier","title":"Lesson 4: Under the Hood: Training a Digit Classifier","text":"<p>28-09-2020</p> <p>This notebook will go over some of the practical material discussed in lesson 4 of the fastai 2020 course, namely, some different ways of training a digit classifier using the MNIST data set. The lesson 4 video is an extension on the lesson 3 video. There is a lot to cover...</p> <p>In the last notebook we looked at some simple examples of using SGD to optimise a model. In this notebook we will apply the concepts to the MNIST problem from scratch then leter, we will refactor the code using PyTorch and fastai modules.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#mnist-loss-function","title":"MNIST Loss function","text":"<p>Our X values will be pixels, we need to reshape the data using <code>view</code>. We want to concatenate our x's into a single tensor, then change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). Why? Because this example is meant to be simplified. </p> <p><code>view</code> will return a new tensor with the same data as the original tensor but with a different shape that we define.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#the-sigmoid-function","title":"The Sigmoid function","text":"<ul> <li>This function will constrain our numbers between 0 and 1.</li> <li>It squashes any input in the range (-inf, inf) to some value in the range (0, 1)</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#sgd-and-mini-batches","title":"SGD and Mini-batches","text":"<p>By batching images and running computations over them is a way to compromise between speed and computational efficiency. </p> <p>The size of the batch will impact your accuracy and estimates as well as the speed at which you are able to run computations. The batch size is something to be considered during training.</p> <p>The <code>DataLoader</code> class in pytorch helps with batching. It returns an iterator which we can loop through.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#putting-it-together","title":"Putting it together","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2004/#refactor-and-clean-up","title":"Refactor and clean up","text":"<ul> <li>create an optimiser </li> <li>use PyTorch modules and functions where available<ul> <li>like <code>nn.Linear</code></li> <li>which \"Applies a linear transformation to the incoming data: $y = xA^T + b$\"</li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#non-linearity","title":"Non-Linearity","text":"<p>To create a simple neural net, using a linear function like we did before is not enough. We need to add in a non-linearity between two linear functions. </p> <p>This is the basic definition for a neural net..</p> <p>The universal approximation theorem says, that given any arbitrarily complex continuous function, we can approximate it with a neural network. I found this useful for visualising how this works. This is what we are trying to do.</p> <p>In our <code>basic_net</code>, each line represents a layer in our network, the first and 3rd layers are known as linear layers the second, as a nonlinearity or an activation.</p> <p><code>res.max(tensor(0.0))</code> takes the result of our linear function and sets any negative value to 0.0 while maintaining any positive values.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2004/#looking-inside","title":"Looking inside...","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2004/#fastai-in-full","title":"fastai in full","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2004/#summary","title":"Summary","text":"<p>We have gone over creating and training a neural network from scratch using the simple example of a digit classifier. The key idea for the last few notebooks was to start with planning out the problem and identifying a way to solve it using a simple common sense solution - the pixel similarity model. </p> <p>This proved successful but it was not really robust beyond the straightforward example we chose - identifying 3s and 7s. We then implemented a more complex solution that could be applied to more complicated problems. </p> <p>After each step or concept had been implemented manually, we refactored the code to use convenient PyTorch functions and modules, eventually ending up with using fastai's implementation which abstracts away from all of the underlying heavy lifting. This is done for convenience and in my own opinion, to help lower the entry barrier into deep learning. </p> <p>Ultimately I believe it is fundamentally important to understand the concepts and implementation if your goal (and this is my goal) is to implement deep learning solutions to solve business problems within your industry.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/","title":"Lesson 06 pt 1","text":"<pre><code># imports\nfrom fastai.vision.all import *\n\n# dataset\npath = untar_data(URLs.PASCAL_2007)\n</code></pre> <pre><code>df = pd.read_csv(path/'train.csv')\ndf.head()\n</code></pre> fname labels is_valid 0 000005.jpg chair True 1 000007.jpg car True 2 000009.jpg horse person True 3 000012.jpg car False 4 000016.jpg bicycle True <p>Let's create a dataset from scratch using fastais suggested methods.</p> <p>We need to grab the appropriate fields from the data frame, that is...</p> <ul> <li>The Independent variable will be the images</li> <li>The Label will be extracted from space separated strings</li> </ul> <pre><code># convenience for setting the base path to the path\nPath.BASE_PATH = path\n</code></pre> <pre><code># helper functions\n\n# create functions to grab x from training path\n# create a function to split lables for y\n\ndef get_x(r): return path/'train'/r['fname']\ndef get_y(r): return r['labels'].split(' ')\n\n# training/valid splitter\n\ndef splitter(df):\n    train = df.index[~df['is_valid']].tolist()\n    valid = df.index[df['is_valid']].tolist()\n    return train,valid\n</code></pre> <pre><code>dblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock),\n    splitter=splitter,\n    get_x=get_x, \n    get_y=get_y,\n    item_tfms=RandomResizedCrop(128, min_scale=0.35))\n\ndsets = dblock.datasets(df)\ndsets.train[0]\n</code></pre> <pre>\n<code>(PILImage mode=RGB size=500x333,\n TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0.]))</code>\n</pre> <pre><code>dsets.train[0][0].to_thumb(192)\n</code></pre> <pre><code># for our image, check where the vocab == 1\n# filter vocab by this to check that our car is a car\n\nidx = torch.where(dsets.train[0][1]==1.)[0]\ndsets.train.vocab[idx]\n</code></pre> <pre>\n<code>(#1) ['car']</code>\n</pre> <p><code>TensorMultiCategory</code> is a one-hot encoded vector, this means that instead of having a label or list of labels, for each image we have a tensor that will have a 1 for the labels for that image, and a 0 for all other labels. The <code>vocab</code> is useful to see which label classes are avaiable.</p> <pre><code>dsets.train.vocab.o2i\n</code></pre> <pre>\n<code>{'aeroplane': 0,\n 'bicycle': 1,\n 'bird': 2,\n 'boat': 3,\n 'bottle': 4,\n 'bus': 5,\n 'car': 6,\n 'cat': 7,\n 'chair': 8,\n 'cow': 9,\n 'diningtable': 10,\n 'dog': 11,\n 'horse': 12,\n 'motorbike': 13,\n 'person': 14,\n 'pottedplant': 15,\n 'sheep': 16,\n 'sofa': 17,\n 'train': 18,\n 'tvmonitor': 19}</code>\n</pre> <pre><code>dblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock),\n    splitter=splitter,\n    get_x=get_x, \n    get_y=get_y,\n    item_tfms=RandomResizedCrop(128, min_scale=0.35))\n\ndls = dblock.dataloaders(df)\n\ndls.show_batch(nrows=1, ncols=3)\n</code></pre> <pre><code># Create a CNN learner\nlearn = cnn_learner(dls, resnet18)\n</code></pre> <pre><code># we can check the activations of our model \n# by passing in a mini-batch of the independent variable\nx,y = to_cpu(dls.train.one_batch())\nactivs = learn.model(x)\nactivs.shape\n</code></pre> <pre>\n<code>torch.Size([64, 20])</code>\n</pre> <p>Why this shape?</p> <ul> <li>batch size = 64</li> <li>number of categories = 20</li> </ul> <pre><code># check the 20 activations\n# this is just to see what they look like\nactivs[0]\n</code></pre> <pre>\n<code>tensor([-1.0697,  2.5707, -0.2860, -2.3535,  3.0095,  4.3694,  1.0534,  0.7723,\n        -3.6078,  3.1691, -2.0013,  0.9257,  2.9621, -1.3111,  0.7584,  0.0951,\n         1.2465,  0.9465, -0.1643,  0.6763], grad_fn=&lt;SelectBackward&gt;)</code>\n</pre> <p>These activations are not between 0 and 1. We need them to represent probabilities so will need to run them through a sigmoid. </p> <p>Remember, here, we do not need the sum of them to add up to one.</p> <p>We will use <code>F.binary_cross_entropy_with_logits</code> because this contains a sigmoid.</p> <pre><code>loss_func = nn.BCEWithLogitsLoss()\nloss = loss_func(activs, y)\nloss\n</code></pre> <pre>\n<code>tensor(1.0935, grad_fn=&lt;BinaryCrossEntropyWithLogitsBackward&gt;)</code>\n</pre> <pre><code>learn = cnn_learner(dls, \n                    resnet50, \n                    metrics=partial(accuracy_multi, thresh=0.2))\n\nlearn.fine_tune(3, base_lr=3e-3, freeze_epocs=4)\n</code></pre> epoch train_loss valid_loss accuracy_multi time 0 0.855198 0.581906 0.323546 00:21 epoch train_loss valid_loss accuracy_multi time 0 0.562123 0.351448 0.488068 00:24 1 0.379880 0.169467 0.896534 00:23 2 0.268020 0.150422 0.924243 00:23 <p>How do we pick a good threshold? By trial and error!</p> <pre><code>preds,targs = learn.get_preds()\n\nxs = torch.linspace(0.05, 0.95, 29)\naccs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs,accs); # somewhere just above 0.5\n</code></pre> <pre><code>path = untar_data(URLs.BIWI_HEAD_POSE)\n</code></pre> <p>Inspect the data, there are 24 directories that correspond to 24 different people photographed. </p> <pre><code>Path.BASE_PATH = path\npath.ls().sorted()\n</code></pre> <pre>\n<code>(#50) [Path('01'),Path('01.obj'),Path('02'),Path('02.obj'),Path('03'),Path('03.obj'),Path('04'),Path('04.obj'),Path('05'),Path('05.obj')...]</code>\n</pre> <pre><code># take a look inside one directory\n(path/'01').ls().sorted()\n</code></pre> <pre>\n<code>(#1000) [Path('01/depth.cal'),Path('01/frame_00003_pose.txt'),Path('01/frame_00003_rgb.jpg'),Path('01/frame_00004_pose.txt'),Path('01/frame_00004_rgb.jpg'),Path('01/frame_00005_pose.txt'),Path('01/frame_00005_rgb.jpg'),Path('01/frame_00006_pose.txt'),Path('01/frame_00006_rgb.jpg'),Path('01/frame_00007_pose.txt')...]</code>\n</pre> <p>each directory contains image files and a pose file wich shows the location of the centre of the head. We can use a function that will return the cooordinates of the head centre point.</p> <p><code>get_image_files</code> will recursively get all image files</p> <p><code>img2pose</code> will convert an image filename to its associated pose file</p> <pre><code>img_files = get_image_files(path)\ndef img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\nimg2pose(img_files[0])\n</code></pre> <pre>\n<code>Path('16/frame_00182_pose.txt')</code>\n</pre> <pre><code># take alook at the shape of an image and a sample image\nim = PILImage.create(img_files[0])\n\nim.shape\n</code></pre> <pre>\n<code>(480, 640)</code>\n</pre> <pre><code>im.to_thumb(160)\n</code></pre> <pre><code># this function is supplied by BIWI dataset website\n# returns the coordinates as a tensor\n\ncal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\n\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n    return tensor([c1,c2])\n</code></pre> <pre><code># test it\n\nget_ctr(img_files[0])\n</code></pre> <pre>\n<code>tensor([324.0023, 251.5637])</code>\n</pre> <pre><code>biwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    get_y=get_ctr,\n    splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n    batch_tfms=[*aug_transforms(size=(240,320)), \n                Normalize.from_stats(*imagenet_stats)]\n)\n</code></pre> <pre><code># check some data\ndls = biwi.dataloaders(path)\ndls.show_batch(max_n=9, figsize=(8,6))\n</code></pre> <pre><code># check the shape of one batch\nxb,yb = dls.one_batch()\nxb.shape,yb.shape\n</code></pre> <pre>\n<code>(torch.Size([64, 3, 240, 320]), torch.Size([64, 1, 2]))</code>\n</pre> <p>Understanding <code>torch.Size([64, 3, 240, 320])</code></p> <ul> <li>mini batch is 64 items</li> <li>there are 3 channels R,G,B</li> <li>image size is 240x320</li> </ul> <p><code>torch.Size([64, 1, 2])</code></p> <ul> <li>64 items in mini batch</li> <li>each item is one point, represented by 2 coordinates (1,2)</li> </ul> <pre><code>learn = cnn_learner(dls, resnet18, y_range=(-1,1))\n</code></pre> <pre><code># we didn't specify the loss\n# what has fastai picked?\ndls.loss_func\n</code></pre> <pre>\n<code>FlattenedLoss of MSELoss()</code>\n</pre> <p>MSE will be suitable for this problem since we are trying to predict something as close as possible to the given coordinates.</p> <pre><code>lr_min, lr_steep = learn.lr_find()\n</code></pre> <pre><code>learn.recorder.plot_lr_find()\nplt.axvline(x=lr_min, color='orange')\nplt.axvline(x=lr_steep, color='r');\n</code></pre> <pre><code>lr=lr_min\nlearn.fine_tune(3,lr)\n</code></pre> epoch train_loss valid_loss time 0 0.059350 0.002665 01:51 epoch train_loss valid_loss time 0 0.005905 0.002256 02:29 1 0.003000 0.000682 02:29 2 0.001558 0.000083 02:29 <p>We got a loss of 0.000083 This corresponds to an average coordinate prediction error of...</p> <pre><code>math.sqrt(0.000083)\n</code></pre> <pre>\n<code>0.0091104335791443</code>\n</pre> <pre><code># check results against actuals\nlearn.show_results(ds_idx=1, nrows=3, figsize=(6,8))\n</code></pre>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#lesson-6-multi-label-classification","title":"Lesson 6: Multi-Label Classification","text":"<p>06-10-2020</p> <p>This notebook will go over some of the practical material discussed in lesson 6 of the fastai 2020 course. Lesson 5 was an extension on the pet classifier we built as well as a discussion on data ethics.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#dataset-pascal","title":"Dataset: PASCAL","text":"<p>Our data set contains images along with a csv containing the labels. There are multiple labels per image, these are space sparated.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#datablock","title":"DataBlock","text":"<p>We need to tell our datablock </p> <ul> <li>where to get the data from</li> <li>where to get the labels from</li> <li>what kind of data we are working with<ul> <li>this is an image classification problem so images and labels</li> <li><code>MultiCategoryBlock</code> expects a list of category labels</li> </ul> </li> <li>how to split our data</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#putting-it-all-together","title":"putting it all together","text":"<ul> <li>we now have a complete data block so will swap out<ul> <li>dsets = <code>dblock.datasets(df)</code></li> <li>for <code>dsets = dblock.dataloaders(df)</code></li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#binary-cross-entropy-loss","title":"Binary cross entropy loss","text":"<ul> <li>Binary Cross entropy loss is used for classificaiton problems. For multi-label classification, we do not need the sum of different classes to add up to one so we will not need <code>softmax</code> here. </li> <li>WHy? Because we might see multiple objects that we are confident appear in an image, so using softmax to restrict this is not a good idea for this problem. </li> <li>We may also want the sum to be less than one if the model is not confident that any of the categories appear in the image.</li> <li>Each activation will be compared to each target for each column, so we don't have to do anything to make this function work for multiple columns.</li> </ul> <p>Some explainations I found useful...</p> <ul> <li>here</li> <li>and here</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#defining-a-metric","title":"Defining a metric","text":"<ul> <li><code>accuracy</code> will only work for single label classification problems. The reason is because it takes the input (final layer activatons) and performs argmax on these. Argmax will return the largest value from the inputs. Then it compares this to the target and takes the mean. </li> <li> <p>So it will only make sense when there is a single maximum we are looking for.</p> </li> <li> <p><code>accuracy_multi</code> will be used instead</p> </li> <li>We need something that works for multiple labels. To do this we will compare the final layer activations to a threshold (0.5 by default). Then we say, if the sigmoid is grater than the threshold, assume that category is there, else if it is less, then it is not there. We then compare this list of trues and falses to the target, then take the mean.</li> <li>We might not want to use 0.5 for our threshold. We can do this using partials when we create our learner by passing in the required argument <code>thresh=0.2</code>.  </li> </ul> <p>Fastai by default will know we are doing a multilabel classification problem so don't need to specify the loss.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#image-regression","title":"Image Regression","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#create-a-datablock","title":"create a DataBlock","text":"<p>we will not use a random splitter because there are multiple images of each person in the data set. We want the model to generalise well on people it has not yet seen. So we will hold back one person for validation.</p> <p>Our data block will be an <code>ImageBlock</code> with two continuous values (the coordinate files). <code>PointBlock</code> specifies this for us.</p> <p><code>get_ctr</code> will return our y values.</p> <p>we will also half the size of our images with <code>aug_transforms(size=(240,320))</code></p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#training-the-model","title":"Training the model","text":"<p>create a learner in the standard way with <code>cnn_learner</code>. We use <code>y_range=(-1,1)</code> to tell fastai what range of data we expect to see in the dependent variable.</p> <p><code>y_range</code> uses a sigmoid function mapped to the low and high values you supplied.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%201/#summary","title":"Summary","text":"<p>For the image regression problem, we were able to use <code>fine_tune</code> rather than train from scratch because our pre-trained model has enough information about faces that retro-fitting it to a different problem is somewhat trivial for it. This is a pretty powerful idea, these algoriths are advanced enough so that there is a certain amount of flexibility in them that can be trained further and utilised on other problems.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/","title":"Lesson 06 pt 2","text":"<pre><code>from fastai.collab import *\nfrom fastai.tabular.all import *\npath = untar_data(URLs.ML_100k)\n</code></pre> <pre><code>ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n                      names=['user','movie','rating','timestamp'])\nratings.head()\n</code></pre> user movie rating timestamp 0 196 242 3 881250949 1 186 302 3 891717742 2 22 377 1 878887116 3 244 51 2 880606923 4 166 346 1 886397596 <p>The goal is to predict or guess what films users might like to watch. You could easily imagine that a user might have a preference for certain genres, and based on films they have seen from a particular genre, you might be able to say something like, user <code>123</code> likes <code>action</code> movies, therefore it would be safe to suggest an action movie to them. </p> <p>Given that we have minimal information in our data set (userid, movieid, rating and timestamp), collaborative filter seeks to solve this problem by extracting latent features from the data. </p> <p>For example, assume that these features range between -1 and +1, with postive numbers indicating stronger mathes to certain factors. </p> <p>We can use a simple example to illustrate the point. Take the following three dummy factors <code>science-fiction</code>, <code>action</code>, and <code>old movies</code>, we can compare user preferences against these for two different movies and see how they score.</p> <pre><code>import numpy as np\n\nlast_skywalker = np.array([0.98,0.9,-0.9])\ncasablanca = np.array([-0.99,-0.3,0.8])\n\nuser1 = np.array([0.9,0.8,-0.6])\n</code></pre> <p>We can compute the dot product and arrive at a match</p> <pre><code>m1 = (user1*last_skywalker).sum()\nm2 = (user1*casablanca).sum()\n\nprint(f'last skywalker match: {m1.round(2)} \\n casablanca match: {m2.round(2)}')\n</code></pre> <pre>\n<code>last skywalker match: 2.14 \n casablanca match: -1.61\n</code>\n</pre> <p>Voila! based on this we might want to recommend Last Skywalker but not Casablanca to this user. </p> <p>So how do we find these latent factors? They can be learned.</p> <pre><code>movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n                     usecols=(0,1), names=('movie','title'), header=None)\nmovies.head()\n</code></pre> movie title 0 1 Toy Story (1995) 1 2 GoldenEye (1995) 2 3 Four Rooms (1995) 3 4 Get Shorty (1995) 4 5 Copycat (1995) <pre><code># join on movie titles\nratings = ratings.merge(movies)\nratings.head()\n</code></pre> user movie rating timestamp title 0 196 242 3 881250949 Kolya (1996) 1 63 242 3 875747190 Kolya (1996) 2 226 242 5 883888671 Kolya (1996) 3 154 242 3 879138235 Kolya (1996) 4 306 242 5 876503793 Kolya (1996) <pre><code>dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\ndls.show_batch()\n</code></pre> user title rating 0 494 Shawshank Redemption, The (1994) 5 1 806 Wrong Trousers, The (1993) 5 2 91 Glory (1989) 5 3 497 Lawnmower Man 2: Beyond Cyberspace (1996) 2 4 630 Rainmaker, The (1997) 3 5 89 That Thing You Do! (1996) 2 6 442 Brothers McMullen, The (1995) 3 7 37 Braveheart (1995) 5 8 159 Kansas City (1996) 1 9 585 Cinema Paradiso (1988) 5 <pre><code>dls.classes\n</code></pre> <pre>\n<code>{'user': (#944) ['#na#',1,2,3,4,5,6,7,8,9...],\n 'title': (#1665) ['#na#',\"'Til There Was You (1997)\",'1-900 (1994)','101 Dalmatians (1996)','12 Angry Men (1957)','187 (1997)','2 Days in the Valley (1996)','20,000 Leagues Under the Sea (1954)','2001: A Space Odyssey (1968)','3 Ninjas: High Noon At Mega Mountain (1998)'...]}</code>\n</pre> <pre><code>n_users  = len(dls.classes['user'])\nn_movies = len(dls.classes['title'])\nn_factors = 5\n\nuser_factors = torch.randn(n_users, n_factors)\nmovie_factors = torch.randn(n_movies, n_factors)\n\nuser_factors.size()\n</code></pre> <pre>\n<code>torch.Size([944, 5])</code>\n</pre> <pre><code>df = pd.DataFrame(['adam', 'beatrix', 'cam'])\n\ndf\n</code></pre> 0 0 adam 1 beatrix 2 cam <pre><code># the categorical variables are represented by 1s and 0s\npd.get_dummies(df)\n</code></pre> 0_adam 0_beatrix 0_cam 0 1 0 0 1 0 1 0 2 0 0 1 <p>In order to calculate a result for a particular user and movie combination, we weill need to look up the index of the movie, and the index of a user in the respective latent factor matrices, then perform a dot product. </p> <p>But this is not something that our model is capable of doing. It is capable of performing dot products though.. </p> <p>Here is another example of how we can use dot products to return elements from a matrix...</p> <p>say the rows in matrix <code>w</code> represent latent movie factors and the matrix <code>v</code> is our one hot encoded movie ids</p> <pre><code>w = torch.randn((3,3))\nw\n</code></pre> <pre>\n<code>tensor([[-1.7224, -0.4789,  0.3553],\n        [-1.3465, -0.3057,  0.6882],\n        [ 0.4594,  0.7893,  0.0150]])</code>\n</pre> <pre><code>v = torch.tensor([[1,0,0],[0,1,0],[0,0,1]])\nv\n</code></pre> <pre>\n<code>tensor([[1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]])</code>\n</pre> <p>we can retrieve the factors for movie 2 (row 2 of <code>w</code>) by preforming a matrix product on the corresponding row of <code>v</code></p> <pre><code>v[1].float() @ w\n</code></pre> <pre>\n<code>tensor([-1.3465, -0.3057,  0.6882])</code>\n</pre> <p>this is the same as calling..</p> <pre><code>w[1]\n</code></pre> <pre>\n<code>tensor([-1.3465, -0.3057,  0.6882])</code>\n</pre> <p>One hot encoding is basically performing an index lookup on our data. This is however memory intensive since we now have these huge matrices to deal with and most of the values will be 0. </p> <p>Enter embeddings. Embeddings are a computational shortcut for doing matrix multiplication of one-hot-encoded vectors </p> <p>I found this link useful</p> <pre><code>class DotProduct(Module):\n    def __init__(self, n_users, n_movies, n_factors):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.movie_factors = Embedding(n_movies, n_factors)\n\n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        return (users * movies).sum(dim=1)\n</code></pre> <pre><code>x,y = dls.one_batch()\n\n# check the shape of x\nx.shape\n</code></pre> <pre>\n<code>torch.Size([64, 2])</code>\n</pre> <pre><code># check the first 5 things in x\nx[:5]\n\n# user ids and movie ids\n</code></pre> <pre>\n<code>tensor([[ 396, 1021],\n        [ 118,  887],\n        [ 206,  380],\n        [ 207,  938],\n        [ 923,  861]], device='cuda:0')</code>\n</pre> <p>What does <code>torch.Size([64, 2])</code> tell us? - batch size is 64 - then we have 2 items, the user ids and movie ids     - check with <code>x[:,0]</code> and <code>x[:,1]</code></p> <pre><code># check the first 5 things of 7\ny[:5]\n\n# these are the ratings\n</code></pre> <pre>\n<code>tensor([[4],\n        [5],\n        [1],\n        [3],\n        [4]], device='cuda:0', dtype=torch.int8)</code>\n</pre> <pre><code>model = DotProduct(n_users, n_movies, n_factors=50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\n</code></pre> <pre><code>learn.fit_one_cycle(5, 5e-3)\n</code></pre> epoch train_loss valid_loss time 0 1.362978 1.286954 00:08 1 1.051144 1.094442 00:08 2 0.963542 0.975438 00:08 3 0.841074 0.893598 00:08 4 0.788252 0.873474 00:08 <p>Not bad but we can make some improvements. We can use a <code>sigmoid</code> to contrain our ratings between 0 and 5, matching what we see in our original data set. We will actually use 0-5.5 otherwise the sigmoid will prevent us ever getting a 5.</p> <pre><code># check rating scores/categories\nratings.rating.value_counts()\n</code></pre> <pre>\n<code>4    34174\n3    27145\n5    21201\n2    11370\n1     6110\nName: rating, dtype: int64</code>\n</pre> <pre><code>help(sigmoid_range)\n</code></pre> <pre>\n<code>Help on function sigmoid_range in module fastai.layers:\n\nsigmoid_range(x, low, high)\n    Sigmoid function with range `(low, high)`\n\n</code>\n</pre> <pre><code>class DotProduct(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.movie_factors = Embedding(n_movies, n_factors)\n        self.y_range = y_range\n\n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)\n</code></pre> <pre><code>model = DotProduct(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3)\n</code></pre> epoch train_loss valid_loss time 0 1.024472 0.989683 00:08 1 0.882552 0.901929 00:08 2 0.684762 0.860367 00:08 3 0.479302 0.864543 00:08 4 0.347512 0.870277 00:08 <p>Not much better....</p> <pre><code># Add in a bias term for each user and each movie. \n\nclass DotProductBias(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.user_bias = Embedding(n_users, 1)\n        self.movie_factors = Embedding(n_movies, n_factors)\n        self.movie_bias = Embedding(n_movies, 1)\n        self.y_range = y_range\n\n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        res = (users * movies).sum(dim=1, keepdim=True)\n        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n        return sigmoid_range(res, *self.y_range)\n</code></pre> <pre><code>model = DotProduct(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3)\n</code></pre> epoch train_loss valid_loss time 0 0.969996 0.988517 00:08 1 0.900296 0.907242 00:08 2 0.691395 0.859838 00:08 3 0.491507 0.861104 00:08 4 0.365541 0.864733 00:08 <p>Our final result is slightly better but we are actually overfitting! How can we stop this and train for longer?</p> <pre><code>model = DotProductBias(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n</code></pre> epoch train_loss valid_loss time 0 0.953578 0.935531 00:08 1 0.846484 0.874122 00:07 2 0.718206 0.829690 00:07 3 0.593549 0.817133 00:07 4 0.474108 0.818135 00:08 <p>much better!</p> <pre><code># create a tensor as a parameter, with random initialization\n\ndef create_params(size):\n    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))\n</code></pre> <p>The below is <code>DotProductBias</code> refactored</p> <pre><code>class DotProductBias(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = create_params([n_users, n_factors])\n        self.user_bias = create_params([n_users])\n        self.movie_factors = create_params([n_movies, n_factors])\n        self.movie_bias = create_params([n_movies])\n        self.y_range = y_range\n\n    def forward(self, x):\n        users = self.user_factors[x[:,0]]\n        movies = self.movie_factors[x[:,1]]\n        res = (users*movies).sum(dim=1)\n        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n        return sigmoid_range(res, *self.y_range)\n</code></pre> <pre><code>model = DotProductBias(n_users, n_movies, 50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n</code></pre> epoch train_loss valid_loss time 0 0.958299 0.949737 00:08 1 0.890685 0.870207 00:08 2 0.742867 0.825684 00:08 3 0.575261 0.817917 00:08 4 0.467277 0.818017 00:09 <pre><code>movie_bias = learn.model.movie_bias.squeeze()\nidxs = movie_bias.argsort()[:5]\n[dls.classes['title'][i] for i in idxs]\n</code></pre> <pre>\n<code>['Children of the Corn: The Gathering (1996)',\n 'Lawnmower Man 2: Beyond Cyberspace (1996)',\n 'Robocop 3 (1993)',\n 'Leave It to Beaver (1997)',\n 'Vampire in Brooklyn (1995)']</code>\n</pre> <pre><code># most liked films\nidxs = movie_bias.argsort(descending=True)[:5]\n[dls.classes['title'][i] for i in idxs]\n</code></pre> <pre>\n<code>['Titanic (1997)',\n \"Schindler's List (1993)\",\n 'As Good As It Gets (1997)',\n 'L.A. Confidential (1997)',\n 'Apt Pupil (1998)']</code>\n</pre> <pre><code>g = ratings.groupby('title')['rating'].count()\ntop_movies = g.sort_values(ascending=False).index.values[:1000]\ntop_idxs = tensor([learn.dls.classes['title'].o2i[m] for m in top_movies])\nmovie_w = learn.model.movie_factors[top_idxs].cpu().detach()\nmovie_pca = movie_w.pca(3)\nfac0,fac1,fac2 = movie_pca.t()\nidxs = list(range(50))\nX = fac0[idxs]\nY = fac2[idxs]\nplt.figure(figsize=(12,12))\nplt.scatter(X, Y)\nfor i, x, y in zip(top_movies[idxs], X, Y):\n    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()\n</code></pre> <p>The most interesting cluster I can see is on the mid-right hand side. Conspiracy Theory, Mission Impossible, Air Force One etc. Asside from Liar Liar, these seem like the kinds of movies that someone who likes action films would likely enjoy. </p> <pre><code>learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n</code></pre> <pre><code>learn.fit_one_cycle(5, 5e-3, wd=0.1)\n</code></pre> epoch train_loss valid_loss time 0 0.941142 0.945376 00:08 1 0.861970 0.873035 00:08 2 0.724418 0.828043 00:08 3 0.617956 0.815366 00:08 4 0.488715 0.815252 00:08"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#lesson-6-collaborative-filtering","title":"Lesson 6: Collaborative Filtering","text":"<p>This notebook will cover collaborative filtering using the MovieLens data set.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#data","title":"Data","text":"<p>\"MovieLens data sets were collected by the GroupLens Research Project at the University of Minnesota.</p> <p>This data set consists of:</p> <ul> <li>100,000 ratings (1-5) from 943 users on 1682 movies. </li> <li>Each user has rated at least 20 movies. </li> <li>Simple demographic info for the users (age, gender, occupation, zip)\"</li> </ul> <p>Additional Info</p> <ul> <li><code>u.data</code> contains the full data set, 100,000 ratings by 943 users on 1,682 items. </li> <li>Each user has rated at least 20 movies.  </li> <li>Users and items are numbered consecutively from 1.  </li> <li>The data is randomly ordered. </li> <li>This is a tab separated list of <ul> <li><code>user id</code> | <code>item id</code> | <code>rating</code> | <code>timestamp</code> </li> <li>The time stamps are unix seconds since 1/1/1970 UTC   </li> </ul> </li> </ul> <p>source</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#step-1-randomly-initialize-parameters","title":"Step 1: Randomly Initialize Parameters","text":"<p>Randomly assign parameters to represent our latent factors for each user and each movie. We get to decide how many of these factors we want to use.  </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#step-2-calculate-predictions","title":"Step 2: Calculate Predictions","text":"<p>Calculate predictions. This is done as we have just seen, by computing the dot product. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#step-3-improve-predictions","title":"Step 3: Improve Predictions","text":"<p>Then improve the prediction using gradient descent on these latent factors</p> <p>First, let's add the movie titles to our data set for readability</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#create-a-dataloader","title":"Create a DataLoader","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#randomly-initialize-parameters","title":"Randomly initialize parameters","text":"<ul> <li>create <code>user_factors</code> and <code>movie_factors</code> of size n users x n factors and n movies by n factors</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#one-hot-encoding","title":"One Hot Encoding","text":"<p>We need to prepare our data in a specific way before we can pass it to our model. Some algorithms can work directly with category labels, but many cannot. </p> <p>One hot encoding is a way of representing categorical data by transforming categorical labels into vectors of 0s and 1s. </p> <p>To get a sense of how one-hot-encoding is operating, here is a simple example...</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#collaborative-filtering-from-scratch","title":"Collaborative filtering from Scratch","text":"<p><code>forward</code> is a very important method name in PyTorch. <code>forward</code> will be the method that handles computation.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#dotproduct","title":"<code>DotProduct</code>","text":"<p>The <code>forward</code> method here will get passed users and movies in two column (<code>x</code>). We then grab the factors from an embedding by calling <code>user_factors</code> just like a function. Assign these to <code>users</code> and <code>movies</code> then perform the dot product using <code>(users * movies).sum(dim=1)</code>. <code>dim=1</code> is used because we want to sum over the second index</p> <pre><code>class DotProduct(Module):\n    def __init__(self, n_users, n_movies, n_factors):\n        self.user_factors = Embedding(n_users, n_factors)\n        self.movie_factors = Embedding(n_movies, n_factors)\n\n    def forward(self, x):\n\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        return (users * movies).sum(dim=1)\n</code></pre>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#create-a-learner","title":"Create a learner","text":"<ul> <li>our model will be the <code>DotProduct</code> class with 50 latent factors</li> <li>loss function will be MSE<ul> <li>this is a regression problem for continuous variables</li> </ul> </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#adding-in-a-bias-term","title":"Adding in a Bias term","text":"<p>We can make further improvements by adding a bias term to our model. </p> <p>Why would we do this? Some movies may have a high rating because they are genuinely better movies, and some users may skew towards being more positive and therefore their rating could generally be more positive. The idea of the bias term is that we now have a way to represent this missing piece of information. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#regularisation","title":"Regularisation","text":"<p>Regularisation is a set of techniques that help to reduce the capacity of the model. Regularisations helps to prevent overfitting of models. Rather than reduce the parameters, we can try to force the parameters to be smaller, unless they are required to be big. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#weight-decay","title":"Weight Decay","text":"<p>Also known as L2 regularisation. It consists of adding to the loss function the sum of all the parameters squared. </p> <p>Why does this work and why would this prevent overfitting?  - one way to decrease loss is to decrease the weights - limiting the weights is going to hinder the training (won't fit training set as well) but will help the model to generalise better</p> <p>In practice what we are doing is adding onto the gradients, the weights multiplied by some hyper parameter.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#creating-our-own-embedding-module","title":"Creating our own Embedding module","text":"<p>Let's recreate the <code>DotProductBias</code> without using the Embedding class.</p> <p>to recap: - an embedding layer is a computational shortcut for performing a matrix multiplication by a one hot encoded matrix, which is the same as indexing into an array.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#interpreting-embeddings-and-biases","title":"Interpreting Embeddings and Biases","text":"<p>Let's take a look at some of the films with the smallest bias. These would be movies that were liked a lot less than others. </p> <p>We can then do the opposite to see the most liked movies (sorting by bias)</p> <p>The goal is to see what the model has learnt and to gain some information about how it is operating. </p> <p>Then using PCA we can reduce the number of latent factors and plot these to view the \"space\". Again, this is a way we can interpret what the model has learnt.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#the-fastai-way","title":"The fastai way","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2006%20pt%202/#summary","title":"Summary","text":"<p>We have just implemented a simple collaborative filtering model from scratch. The idea with this lesson, as with most of them so far, is to dig into the theory, code a model from scratch (mostly), improve the mode, then use the fastai implementation. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/","title":"Lesson 07","text":"<pre><code>from pathlib import Path\n\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n\nfrom fastai.tabular.all import *\n# helper functions\nfrom fastbook import *\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor,export_graphviz\n\nfrom dtreeviz.trees import *\n\nimport IPython\nfrom IPython.display import Image, display_svg, SVG\n\nimport os\n</code></pre> <p>Load credentials from json file. This is a simple file with the following information...</p> <pre><code>{\"username\":\"xxx\",\"key\":\"xxx\"}\n</code></pre> <pre><code>import json\n\nwith open('creds.json') as f:\n    creds = json.load(f)\n</code></pre> <pre><code>os.environ['KAGGLE_USERNAME']=creds[\"username\"]\nos.environ['KAGGLE_KEY']=creds[\"key\"]\n</code></pre> <pre><code>from kaggle import api\n\napi.competition_download_cli('bluebook-for-bulldozers')\n</code></pre> <pre>\n<code> 10%|\u2588         | 5.00M/48.4M [00:00&lt;00:01, 30.5MB/s]</code>\n</pre> <pre>\n<code>Downloading bluebook-for-bulldozers.zip to /notebooks\n</code>\n</pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 48.4M/48.4M [00:01&lt;00:00, 28.5MB/s]</code>\n</pre> <pre>\n<code>\n</code>\n</pre> <pre>\n<code>\n</code>\n</pre> <pre><code>p = Path.cwd()\n\nfor i in p.iterdir():\n    print(i)\n</code></pre> <pre>\n<code>/notebooks/.ipynb_checkpoints\n/notebooks/.kaggle\n/notebooks/course-v4\n/notebooks/fastbook\n/notebooks/lesson1_assets\n/notebooks/models\n/notebooks/20200920_fastai_lesson_prod_app.ipynb\n/notebooks/20201006_fastai_lesson_6.ipynb\n/notebooks/20201026_fastai_lesson_6_collab.ipynb\n/notebooks/bluebook-for-bulldozers.zip\n/notebooks/lesson_7_tabular.ipynb\n/notebooks/storage\n/notebooks/datasets\n</code>\n</pre> <pre><code>fname = p/'bluebook-for-bulldozers.zip'\n\ndest = p/'storage/data/bluebook'\n# dest.mkdir()\n\n# only run once!\n#file_extract(fname, dest)\n</code></pre> <pre><code>df = pd.read_csv(dest/'TrainAndValid.csv', low_memory=False)\n\ndf.head()\n</code></pre> SalesID SalePrice MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand saledate ... Undercarriage_Pad_Width Stick_Length Thumb Pattern_Changer Grouser_Type Backhoe_Mounting Blade_Type Travel_Controls Differential_Type Steering_Controls 0 1139246 66000.0 999089 3157 121 3.0 2004 68.0 Low 11/16/2006 0:00 ... NaN NaN NaN NaN NaN NaN NaN NaN Standard Conventional 1 1139248 57000.0 117657 77 121 3.0 1996 4640.0 Low 3/26/2004 0:00 ... NaN NaN NaN NaN NaN NaN NaN NaN Standard Conventional 2 1139249 10000.0 434808 7009 121 3.0 2001 2838.0 High 2/26/2004 0:00 ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 3 1139251 38500.0 1026470 332 121 3.0 2001 3486.0 High 5/19/2011 0:00 ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 4 1139253 11000.0 1057373 17311 121 3.0 2007 722.0 Medium 7/23/2009 0:00 ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN <p>5 rows \u00d7 53 columns</p> <pre><code>df.columns\n</code></pre> <pre>\n<code>Index(['SalesID', 'SalePrice', 'MachineID', 'ModelID', 'datasource',\n       'auctioneerID', 'YearMade', 'MachineHoursCurrentMeter', 'UsageBand',\n       'saledate', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc',\n       'fiModelSeries', 'fiModelDescriptor', 'ProductSize',\n       'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc',\n       'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control',\n       'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension',\n       'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics',\n       'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size',\n       'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow',\n       'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb',\n       'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type',\n       'Travel_Controls', 'Differential_Type', 'Steering_Controls'],\n      dtype='object')</code>\n</pre> <pre><code>df['ProductSize'].unique()\n</code></pre> <pre>\n<code>array([nan, 'Medium', 'Small', 'Large / Medium', 'Mini', 'Large',\n       'Compact'], dtype=object)</code>\n</pre> <pre><code>sizes = 'Large','Large / Medium','Medium','Small','Mini','Compact'\n</code></pre> <pre><code>df['ProductSize'] = df['ProductSize'].astype('category')\ndf['ProductSize'].cat.set_categories(sizes, ordered=True, inplace=True)\n</code></pre> <p>dependent variable here is <code>SalePrice</code>, this is the variable we want to predict. Kaggle specifically tells us the metric to use: root mean squared log error (RMSLE). To use this metric, we need to take the log of the dependent variable which will allow use to use RMSE</p> <pre><code>dep_var = 'SalePrice'\n</code></pre> <pre><code>df[dep_var] = np.log(df[dep_var])\n</code></pre> <pre><code>df = add_datepart(df, 'saledate')\n</code></pre> <pre>\n<code>/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/tabular/core.py:33: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n  for n in attr: df[prefix + n] = getattr(field.dt, n.lower())\n</code>\n</pre> <pre><code>df_test = pd.read_csv(dest/'Test.csv', low_memory=False)\ndf_test = add_datepart(df_test, 'saledate')\n</code></pre> <pre><code>procs = [Categorify, FillMissing]\n</code></pre> <p>Validation Set</p> <p>hold aside some data (approx 2 weeks) as per the competition rules - do this with <code>np.where</code></p> <pre><code>cond = (df.saleYear&lt;2011) | (df.saleMonth&lt;10)\n\ntrain_idx = np.where(cond)[0]\nvalid_idx = np.where(~cond)[0] # inverse condition\n\nsplits = (list(train_idx), list(valid_idx))\n</code></pre> <p>Here <code>cont_cat_split</code> is a helper function that returns column names of cont and cat variables from given <code>df</code>.</p> <pre><code># define continuous and categorical columns for TabularPandas\n\ncont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n</code></pre> <pre><code>to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n</code></pre> <pre><code>len(to.train), len(to.valid)\n</code></pre> <pre>\n<code>(404710, 7988)</code>\n</pre> <p>Look at the data with <code>to.show</code>. This will show the data in human readable form. <code>to.items.head</code> will show the processed data in numerical form.</p> <pre><code>to.show(3)\n</code></pre> UsageBand fiModelDesc fiBaseModel fiSecondaryDesc fiModelSeries fiModelDescriptor ProductSize fiProductClassDesc state ProductGroup ProductGroupDesc Drive_System Enclosure Forks Pad_Type Ride_Control Stick Transmission Turbocharged Blade_Extension Blade_Width Enclosure_Type Engine_Horsepower Hydraulics Pushblock Ripper Scarifier Tip_Control Tire_Size Coupler Coupler_System Grouser_Tracks Hydraulics_Flow Track_Type Undercarriage_Pad_Width Stick_Length Thumb Pattern_Changer Grouser_Type Backhoe_Mounting Blade_Type Travel_Controls Differential_Type Steering_Controls saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed auctioneerID_na MachineHoursCurrentMeter_na SalesID MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter saleYear saleMonth saleWeek saleDay saleDayofweek saleDayofyear SalePrice 0 Low 521D 521 D #na# #na# #na# Wheel Loader - 110.0 to 120.0 Horsepower Alabama WL Wheel Loader #na# EROPS w AC None or Unspecified #na# None or Unspecified #na# #na# #na# #na# #na# #na# #na# 2 Valve #na# #na# #na# #na# None or Unspecified None or Unspecified #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# Standard Conventional False False False False False False 1163635200 False False 1139246 999089 3157 121 3.0 2004 68.0 2006 11 46 16 3 320 11.097410 1 Low 950FII 950 F II #na# Medium Wheel Loader - 150.0 to 175.0 Horsepower North Carolina WL Wheel Loader #na# EROPS w AC None or Unspecified #na# None or Unspecified #na# #na# #na# #na# #na# #na# #na# 2 Valve #na# #na# #na# #na# 23.5 None or Unspecified #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# Standard Conventional False False False False False False 1080259200 False False 1139248 117657 77 121 3.0 1996 4640.0 2004 3 13 26 4 86 10.950807 2 High 226 226 #na# #na# #na# #na# Skid Steer Loader - 1351.0 to 1601.0 Lb Operating Capacity New York SSL Skid Steer Loaders #na# OROPS None or Unspecified #na# #na# #na# #na# #na# #na# #na# #na# #na# Auxiliary #na# #na# #na# #na# #na# None or Unspecified None or Unspecified None or Unspecified Standard #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# #na# False False False False False False 1077753600 False False 1139249 434808 7009 121 3.0 2001 2838.0 2004 2 9 26 3 57 9.210340 <pre><code>to.items.head(3)\n</code></pre> SalesID SalePrice MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand fiModelDesc ... saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed auctioneerID_na MachineHoursCurrentMeter_na 0 1139246 11.097410 999089 3157 121 3.0 2004 68.0 2 963 ... 320 1 1 1 1 1 1 2647 1 1 1 1139248 10.950807 117657 77 121 3.0 1996 4640.0 2 1745 ... 86 1 1 1 1 1 1 2148 1 1 2 1139249 9.210340 434808 7009 121 3.0 2001 2838.0 1 336 ... 57 1 1 1 1 1 1 2131 1 1 <p>3 rows \u00d7 67 columns</p> <p>check the vocab with <code>to.classes</code></p> <pre><code>to.classes['ProductSize']\n</code></pre> <pre>\n<code>(#7) ['#na#','Large','Large / Medium','Medium','Small','Mini','Compact']</code>\n</pre> <pre><code># save the tabular object for later\n\n# (dest/'to.pkl').save(to)\n</code></pre> <pre><code># had to copy from \n# https://github.com/anandsaha/fastai.part1.v2/blob/master/fastai/structured.py\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n\"\"\" Draws a representation of a random forest in IPython.\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    \"\"\"\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))\n</code></pre> <pre><code>xs,y = to.train.xs, to.train.y\n\nvalid_xs, valid_y = to.valid.xs, to.valid.y\n</code></pre> <pre><code>m = DecisionTreeRegressor(max_leaf_nodes=4)\nm.fit(xs, y);\n</code></pre> <pre><code>draw_tree(m, xs, precision=2);\n</code></pre> Tree 0 Coupler_System \u2264 0.5 mse = 0.48 samples = 404710 value = 10.1 1 YearMade \u2264 1991.5 mse = 0.42 samples = 360847 value = 10.21 0-&gt;1 True 2 mse = 0.12 samples = 43863 value = 9.21 0-&gt;2 False 3 mse = 0.37 samples = 155724 value = 9.97 1-&gt;3 4 ProductSize \u2264 4.5 mse = 0.37 samples = 205123 value = 10.4 1-&gt;4 5 mse = 0.31 samples = 182403 value = 10.5 4-&gt;5 6 mse = 0.17 samples = 22720 value = 9.62 4-&gt;6 <pre><code>samp_idx = np.random.permutation(len(y))[:500]\ndtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')\n</code></pre> G node4 2020-11-30T06:28:05.016208 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ leaf5 2020-11-30T06:28:05.560116 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node4-&gt;leaf5 leaf6 2020-11-30T06:28:05.654756 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node4-&gt;leaf6 node1 2020-11-30T06:28:05.131089 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node1-&gt;node4 leaf3 2020-11-30T06:28:05.398894 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node1-&gt;leaf3 leaf2 2020-11-30T06:28:05.742191 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node0 2020-11-30T06:28:05.254063 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node0-&gt;node1 &lt; node0-&gt;leaf2 \u2265 <p>Using Dtreeviz is a little more intuitive and provides a bit more information. For example, <code>YearMade</code> is showing that there are years equal to 1000, which is obviously an error in the data. Let's fix that</p> <pre><code>xs.loc[xs['YearMade']&lt;1900, 'YearMade'] = 1950\nvalid_xs.loc[valid_xs['YearMade']&lt;1900, 'YearMade'] = 1950\n</code></pre> <pre><code>m = DecisionTreeRegressor(max_leaf_nodes=4).fit(xs, y)\n\ndtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')\n</code></pre> G node4 2020-11-30T06:28:21.881440 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ leaf5 2020-11-30T06:28:22.494637 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node4-&gt;leaf5 leaf6 2020-11-30T06:28:22.604794 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node4-&gt;leaf6 node1 2020-11-30T06:28:22.010995 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node1-&gt;node4 leaf3 2020-11-30T06:28:22.367366 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node1-&gt;leaf3 leaf2 2020-11-30T06:28:22.694135 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node0 2020-11-30T06:28:22.156796 image/svg+xml Matplotlib v3.3.1, https://matplotlib.org/ node0-&gt;node1 &lt; node0-&gt;leaf2 \u2265 <pre><code># remove max_leaf_nodes\n# build a bigger tree\nm = DecisionTreeRegressor()\nm.fit(xs, y)\n</code></pre> <pre>\n<code>DecisionTreeRegressor()</code>\n</pre> <pre><code>def r_mse(preds,y): return round(math.sqrt(((preds-y)**2).mean()),6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)\n</code></pre> <pre><code>m_rmse(m, xs, y)\n</code></pre> <pre>\n<code>0.0</code>\n</pre> <pre><code>m_rmse(m, valid_xs, valid_y)\n</code></pre> <pre>\n<code>0.333069</code>\n</pre> <p>Our training set is 0 and validation set is worse than the observed value from the original tree viz. The reason is that there are almost as many leaves in our model than observations in our data set. To avoid this, we need to pick some stopping criteria, like some threshold that will tell the model, don't split this if there are less than x number of items in the leaf node. Do this with <code>min_samples_leaf</code>.</p> <pre><code>m.get_n_leaves(), len(xs)\n</code></pre> <pre>\n<code>(324549, 404710)</code>\n</pre> <p>we have nearly as many leaf nodes as observations in our dataset</p> <p>we need to create some rules here</p> <pre><code>m = DecisionTreeRegressor(min_samples_leaf=25)\nm.fit(to.train.xs, to.train.y)\nm_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n</code></pre> <pre>\n<code>(0.248593, 0.323391)</code>\n</pre> <pre><code>m.get_n_leaves()\n</code></pre> <pre>\n<code>12397</code>\n</pre> <pre><code>def rf(xs, y, n_estimators=40, max_samples=200_000,\n      max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n      max_samples=max_samples, max_features=max_features,\n      min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)\n</code></pre> <pre><code>m = rf(xs, y)\n</code></pre> <pre><code>m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)\n</code></pre> <pre>\n<code>(0.171231, 0.234308)</code>\n</pre> <p>That is much better!</p> <pre><code>preds = np.stack([t.predict(valid_xs) for t in m.estimators_])\n</code></pre> <pre><code>preds\n</code></pre> <pre>\n<code>array([[10.11121098,  9.94458659,  9.42150625, ...,  9.17998473,\n         9.29954442,  9.29954442],\n       [10.14101274,  9.82777866,  9.55376172, ...,  9.48364408,\n         9.48364408,  9.48364408],\n       [10.01018006, 10.1378665 ,  9.27639723, ...,  9.49919689,\n         9.18244871,  9.18244871],\n       ...,\n       [ 9.88747565,  9.52539463,  9.46619672, ...,  9.24248886,\n         9.22252042,  9.22252042],\n       [10.5004158 ,  9.98228111,  9.20137348, ...,  9.43222591,\n         9.30666413,  9.30666413],\n       [10.08093796, 10.61704159,  9.33421822, ...,  9.26213868,\n         9.29758778,  9.29758778]])</code>\n</pre> <p>This represents every prediction for each and every tree for every row of data.</p> <pre><code>r_mse(preds.mean(axis=0), valid_y)\n</code></pre> <pre>\n<code>0.234308</code>\n</pre> <p>Here is how to make a single rediction. I think!!</p> <pre><code># slice a row of data\nvalid_xs.iloc[0]\n</code></pre> <pre>\n<code>UsageBand             2.0\nfiModelDesc        2301.0\nfiBaseModel         706.0\nfiSecondaryDesc      43.0\nfiModelSeries         0.0\n                    ...  \nsaleMonth            10.0\nsaleWeek             40.0\nsaleDay               3.0\nsaleDayofweek         0.0\nsaleDayofyear       276.0\nName: 22915, Length: 66, dtype: float64</code>\n</pre> <pre><code># predict requires a 2D array, reshape your data\n\ndata = valid_xs.iloc[0].values.reshape(1,-1)\n\nm.predict(data)\n</code></pre> <pre>\n<code>array([10.0005727])</code>\n</pre> <p>You can visualise how RMSE improvs as more and more trees are added</p> <pre><code>plt.plot([r_mse(preds[:i+1].mean(0), valid_y) for i in range(40)]);\n</code></pre> <p>validation set is worse than the training set. Why?</p> <ul> <li>we might be overfitting</li> <li>the last two weeks of the auction data may have been different somehow</li> </ul> <pre><code>r_mse(m.oob_prediction_, y)\n</code></pre> <pre>\n<code>0.211059</code>\n</pre> <p>What is happening here?</p> <p>OOB error gives you a sense of how much you are overfitting. </p> <pre><code>preds_std = preds.std(0)\npreds_std\n</code></pre> <pre>\n<code>array([0.24516726, 0.17149769, 0.12129906, ..., 0.1911843 , 0.16064838,\n       0.16064838])</code>\n</pre> <pre><code>def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols': df.columns, 'imp': m.feature_importances_}\n                        ).sort_values('imp', ascending=False)\n</code></pre> <pre><code>fi = rf_feat_importance(m, xs)\n\nfi[:10]\n</code></pre> cols imp 58 YearMade 0.175870 6 ProductSize 0.118317 30 Coupler_System 0.099115 7 fiProductClassDesc 0.071253 31 Grouser_Tracks 0.064081 55 ModelID 0.061831 50 saleElapsed 0.051997 32 Hydraulics_Flow 0.042906 3 fiSecondaryDesc 0.039384 1 fiModelDesc 0.031282 <pre><code>def plot_fi(fi):\n    return fi.plot.barh('cols', 'imp', figsize=(12,8), legend=False)\n\nplot_fi(fi[:30]);\n</code></pre> <pre><code>to_keep = fi[fi.imp&gt;0.005].cols\nlen(to_keep)\n</code></pre> <pre>\n<code>20</code>\n</pre> <p>retrain model using only this subset of columns</p> <pre><code>xs_imp = xs[to_keep]\nvalid_xs_imp = valid_xs[to_keep]\n</code></pre> <pre><code>m = rf(xs_imp, y)\n</code></pre> <pre><code>m_rmse(m, xs_imp, y), m_rmse(m, valid_xs, valid_y)\n</code></pre> <pre>\n<code>(0.180874, 0.231109)</code>\n</pre> <pre><code>cluster_columns??\n</code></pre> <pre><code>cluster_columns(xs_imp)\n</code></pre> <p>seems like we could remove some of the clustered columns. </p> <p>Let's calculate a baseline using a sample of data</p> <pre><code>def get_oob(df):\n    m = RandomForestRegressor(n_estimators=40, min_samples_leaf=15,\n        max_samples=50000, max_features=0.5, n_jobs=-1, oob_score=True)\n    m.fit(df, y)\n    return m.oob_score_\n</code></pre> <pre><code>get_oob(xs_imp)\n</code></pre> <pre>\n<code>0.8769414512037411</code>\n</pre> <p>now remove redundant columns one at a time</p> <pre><code>{c:get_oob(xs_imp.drop(c, axis=1)) for c in (\n    'saleYear', 'saleElapsed', 'ProductGroupDesc','ProductGroup',\n    'fiModelDesc', 'fiBaseModel',\n    'Hydraulics_Flow','Grouser_Tracks', 'Coupler_System')}\n</code></pre> <pre>\n<code>{'saleYear': 0.8754647378064608,\n 'saleElapsed': 0.8723764211506366,\n 'ProductGroupDesc': 0.8765810711892142,\n 'ProductGroup': 0.8773280451665235,\n 'fiModelDesc': 0.8758816619476205,\n 'fiBaseModel': 0.8756967579434771,\n 'Hydraulics_Flow': 0.8769591574648032,\n 'Grouser_Tracks': 0.876871969234521,\n 'Coupler_System': 0.8762546455208067}</code>\n</pre> <p>not much change here so try dropping multiple variables</p> <pre><code>to_drop = ['saleYear', 'ProductGroupDesc', 'fiBaseModel', 'Grouser_Tracks']\nget_oob(xs_imp.drop(to_drop, axis=1))\n</code></pre> <pre>\n<code>0.875680776530026</code>\n</pre> <pre><code>xs_final = xs_imp.drop(to_drop, axis=1)\nvalid_xs_final = valid_xs_imp.drop(to_drop, axis=1)\n</code></pre> <p>check rmse again to confirm accuracy hasn't really changed</p> <pre><code>m = rf(xs_final, y)\nm_rmse(m, xs_final, y), m_rmse(m, valid_xs_final, valid_y)\n</code></pre> <pre>\n<code>(0.182544, 0.23238)</code>\n</pre> <p>similar accuracy but less features!</p> <pre><code>p = valid_xs_final['ProductSize'].value_counts(sort=False).plot.barh()\nc = to.classes['ProductSize']\nplt.yticks(range(len(c)),c);\n</code></pre> <p>largest group is actual #na#</p> <p>do the same for yearmade</p> <pre><code>ax = valid_xs_final['YearMade'].hist()\n</code></pre> <pre><code>from sklearn.inspection import plot_partial_dependence\n\nfig,ax = plt.subplots(figsize=(12, 4))\nplot_partial_dependence(m, valid_xs_final, ['YearMade','ProductSize'],\n                        grid_resolution=20, ax=ax);\n</code></pre> <p>what is partial dependence telling us?</p> <p>We want to look at how year affects the sale price, that is, all else being equal, what affect does year have on sale price</p> <pre><code>#!pip install treeinterpreter\n#!pip install waterfallcharts\n</code></pre> <pre><code>import warnings\nwarnings.simplefilter('ignore', FutureWarning)\n\nfrom treeinterpreter import treeinterpreter\nfrom waterfall_chart import plot as waterfall\n</code></pre> <pre><code>row = valid_xs_final.iloc[:5]\n</code></pre> <pre><code>prediction,bias,contributions = treeinterpreter.predict(m, row.values)\n</code></pre> <pre><code>prediction[0], bias[0], contributions[0].sum()\n</code></pre> <pre>\n<code>(array([10.03875756]), 10.104200155980113, -0.06544259554720655)</code>\n</pre> <pre><code>waterfall(valid_xs_final.columns, contributions[0], threshold=0.08, \n          rotation_value=45,formatting='{:,.3f}');\n</code></pre> <pre><code>np.random.seed(42)\n</code></pre> <pre><code>x_lin = torch.linspace(0,20, steps=40)\ny_lin = x_lin + torch.randn_like(x_lin)\nplt.scatter(x_lin, y_lin);\n</code></pre> <pre><code>xs_lin = x_lin.unsqueeze(1)\nx_lin.shape, xs_lin.shape\n</code></pre> <pre>\n<code>(torch.Size([40]), torch.Size([40, 1]))</code>\n</pre> <p>you can do the same using <code>None</code></p> <pre><code>x_lin[:,None].shape\n</code></pre> <pre>\n<code>torch.Size([40, 1])</code>\n</pre> <pre><code>m_lin = RandomForestRegressor().fit(x_lin[:30].reshape(-1, 1), y_lin[:30])\n</code></pre> <pre><code>plt.scatter(x_lin, y_lin, 20)\nplt.scatter(x_lin, m_lin.predict(xs_lin), color='red', alpha=0.5);\n</code></pre> <p>random forrext cannot extrapolate outside of the bounds of the training data</p> <p>we need to make sure validation set does not contain out of domain data</p> <p>test and training set may vary, how do we tell??</p> <pre><code>df_dom = pd.concat([xs_final, valid_xs_final])\nis_valid = np.array([0]*len(xs_final) + [1]*len(valid_xs_final))\n\nm = rf(df_dom, is_valid)\nrf_feat_importance(m, df_dom)[:6]\n</code></pre> cols imp 5 saleElapsed 0.915808 10 SalesID 0.069088 13 MachineID 0.011871 0 YearMade 0.000678 4 ModelID 0.000536 12 Hydraulics 0.000529 <pre><code>m = rf(xs_final, y)\nprint('orig', m_rmse(m, valid_xs_final, valid_y))\n\nfor c in ('SalesID','saleElapsed','MachineID'):\n    m = rf(xs_final.drop(c,axis=1), y)\n    print(c, m_rmse(m, valid_xs_final.drop(c,axis=1), valid_y))\n</code></pre> <pre>\n<code>orig 0.233484\nSalesID 0.231357\nsaleElapsed 0.236643\nMachineID 0.231104\n</code>\n</pre> <pre><code>time_vars = ['SalesID','MachineID']\nxs_final_time = xs_final.drop(time_vars, axis=1)\nvalid_xs_time = valid_xs_final.drop(time_vars, axis=1)\n\nm = rf(xs_final_time, y)\nm_rmse(m, valid_xs_time, valid_y)\n</code></pre> <pre>\n<code>0.229127</code>\n</pre> <pre><code>xs['saleYear'].hist();\n</code></pre> <pre><code>filt = xs['saleYear']&gt;2004\nxs_filt = xs_final_time[filt]\ny_filt = y[filt]\n</code></pre> <pre><code>m = rf(xs_filt, y_filt)\nm_rmse(m, xs_filt, y_filt), m_rmse(m, valid_xs_time, valid_y)\n</code></pre> <pre>\n<code>(0.176904, 0.22864)</code>\n</pre> <pre><code># load data\ndf_nn = pd.read_csv(dest/'TrainAndValid.csv', low_memory=False)\n\n# set ProductSize as categorical\ndf_nn['ProductSize'] = df_nn['ProductSize'].astype('category')\ndf_nn['ProductSize'].cat.set_categories(sizes, ordered=True, inplace=True)\n\n# take log of dependent variable\ndf_nn[dep_var] = np.log(df_nn[dep_var])\n\n# do some date prep\ndf_nn = add_datepart(df_nn, 'saledate')\n</code></pre> <pre><code>df_nn_final = df_nn[list(xs_final_time.columns) + [dep_var]]\n</code></pre> <pre><code>cont_nn,cat_nn = cont_cat_split(df_nn_final, max_card=9000, dep_var=dep_var)\n</code></pre> <pre><code>cont_nn.append('saleElapsed')\ncat_nn.remove('saleElapsed')\n</code></pre> <pre><code>df_nn['saleElapsed'] = df_nn['saleElapsed'].astype(int)\n</code></pre> <pre><code>df_nn_final[cat_nn].nunique()\n</code></pre> <pre>\n<code>YearMade                73\nProductSize              6\nCoupler_System           2\nfiProductClassDesc      74\nModelID               5281\nHydraulics_Flow          3\nfiSecondaryDesc        177\nfiModelDesc           5059\nEnclosure                6\nProductGroup             6\nHydraulics              12\nfiModelDescriptor      140\nDrive_System             4\ndtype: int64</code>\n</pre> <pre><code>xs_filt2 = xs_filt.drop('fiModelDescriptor', axis=1)\nvalid_xs_time2 = valid_xs_time.drop('fiModelDescriptor', axis=1)\nm2 = rf(xs_filt2, y_filt)\nm_rmse(m2, xs_filt2, y_filt), m_rmse(m2, valid_xs_time2, valid_y)\n</code></pre> <pre>\n<code>(0.178922, 0.230357)</code>\n</pre> <pre><code>cat_nn.remove('fiModelDescriptor')\n</code></pre> <pre><code>df_nn_final['saleElapsed'].astype('int64', copy=False)\n\ndf_nn_final.dtypes\n</code></pre> <pre>\n<code>YearMade                 int64\nProductSize           category\nCoupler_System          object\nfiProductClassDesc      object\nModelID                  int64\nsaleElapsed              int64\nHydraulics_Flow         object\nfiSecondaryDesc         object\nfiModelDesc             object\nEnclosure               object\nProductGroup            object\nHydraulics              object\nfiModelDescriptor       object\nDrive_System            object\nSalePrice              float64\ndtype: object</code>\n</pre> <pre><code>procs_nn = [Categorify, FillMissing, Normalize]\nto_nn = TabularPandas(df=df_nn_final, \n                      procs=procs_nn, \n                      cat_names=cat_nn, \n                      cont_names=cont_nn,\n                      splits=splits, \n                      y_names=dep_var)\n</code></pre> <pre><code>dls = to_nn.dataloaders(1024)\n</code></pre> <p>This is a regression model so we want to set our <code>y_range</code> based on the min and max of the dependent variable.</p> <pre><code>y = to_nn.train.y\ny.min(),y.max()\n</code></pre> <pre>\n<code>(8.465899, 11.863583)</code>\n</pre> <pre><code>learn = tabular_learner(dls, y_range=(8,12), layers=[500,250],\n                        n_out=1, loss_func=F.mse_loss)\n</code></pre> <pre><code>learn.lr_find()\n</code></pre> <pre>\n<code>SuggestedLRs(lr_min=0.003981071710586548, lr_steep=0.00019054606673307717)</code>\n</pre> <pre><code>learn.fit_one_cycle(5, 1e-2)\n</code></pre> epoch train_loss valid_loss time 0 0.069223 0.062953 00:11 1 0.056285 0.055872 00:13 2 0.048484 0.055052 00:12 3 0.043525 0.051425 00:12 4 0.040454 0.051055 00:11 <pre><code>preds,targs = learn.get_preds()\nr_mse(preds,targs)\n</code></pre> <pre>\n<code>0.225954</code>\n</pre>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#lesson-7-tabular-data","title":"Lesson 7: Tabular Data","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#pt-1","title":"Pt 1","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#decision-tree-ensembles","title":"Decision Tree Ensembles","text":"<p>Some examples include... - Random Forest (Regressor / Classifier) - Gradient Boost (Regressor / Classifier) - XGBoost (Regressor / Classifier)</p> <p>We will use the Scikit-Learn library for this task rather than PyTorch. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#the-data","title":"The Data","text":"<ul> <li>Blue Book for Bulldozers Kaggle Competition</li> <li>The goal being to predict sale price of heavy equipment at auction based on ussage, type and configuration.</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#kaggle-setup-help","title":"Kaggle setup help","text":"<p>There are a number of different ways to do this, I had some trouble doing this so after some reading, tried this instead.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#fastai-helper-functions","title":"fastai helper functions","text":"<ul> <li>Had some trouble importing fastais helper functions, found that someone has added them all here</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#the-data_1","title":"The Data","text":"<p>each row of the dataset represents the sale of a single machine at an auction</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#transforming-data","title":"Transforming data","text":"<ul> <li>convert categorical ie <code>ProductSize</code></li> <li>set order</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#decision-trees","title":"Decision Trees","text":"<ul> <li>ask binary questions about data<ul> <li>ie is x &gt; y</li> </ul> </li> <li>the trouble is we don't know what binary questions to ask, and through machine learning, we need to decide on what these will be. </li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#handling-dates","title":"Handling Dates","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#using-tabularpandas-and-tabularproc","title":"Using TabularPandas and TabularProc","text":"<p>we will use two tabular transforms to modify our data.  - Categorify     - replaces a column with numeric category - FillMissign     - fills any missing data with the median     - also adds a boolean column where <code>True</code> will be set for any data point that was missing</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#create-a-tabular-object-to","title":"create a Tabular Object (to)","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#decision-tree-regressor-for-continuous-variables","title":"Decision Tree Regressor: for continuous variables","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#catagorical-variables","title":"Catagorical Variables","text":"<p>Unlike with collab filtering, we do not need to create dummy variables with categorical values because through pre-processing, we have already transformed these into numerical values. </p> <p>However, you can one-hot encode if you like. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#bagging","title":"Bagging","text":"<p>A technique developed by professor Leo Breiman. The idea is that you can bootstrap subsets of your data, train your model, store the predictions, then average the predictions.</p> <p>Steps 1. randomly choose a subset 2. train a model on the subset 3. save the model, return to step one 4. make a prediction using all of the models, then take the average of each model's prediction</p> <p>Leo furthered his thinking by not only selecting a random subset of rows, but also a random subset of columns. This is known as a Random Forrest.</p> <p>The function <code>rf</code> below uses the following arguments - <code>n_estimators</code> defines the number of trees  - <code>max_samples</code> defines how many rows to sample for training each tree - <code>max_features</code> defines how many columns to sample at each split point (0.5 means \"take half the total number of columns\").  - <code>min_samples_leaf</code> specify when to stop splitting the tree nodes     - effectively limiting the depth of the tree - <code>n_jobs=-1</code> use CPUs to build the trees in parallel. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#making-predictions","title":"Making Predictions","text":"<p>To understand the impact of <code>n_estimators</code> you can get predictions from each individual tree in the forest</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#check-this","title":"CHECK THIS","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#out-of-bag-error-oob-error","title":"Out of Bag Error (OOB error)","text":"<p>how can we check? we can use OOB predictions from the model and run rmse on the oob error.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#model-interpretation","title":"Model interpretation","text":"<p>source</p> <p>For tabular data, model interpretation is particularly important. For a given model, the things we are most likely to be interested in are:</p> <ul> <li>How confident are we in our predictions using a particular row of data?</li> <li>For predicting with a particular row of data, what were the most important factors, and how did they influence that prediction?</li> <li>Which columns are the strongest predictors, which can we ignore?</li> <li>Which columns are effectively redundant with each other, for purposes of prediction?</li> <li>How do predictions vary, as we vary these columns?</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#feature-important","title":"Feature Important","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#removing-low-importance-variables","title":"Removing low-importance variables","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#partial-dependence","title":"Partial Dependence","text":"<p>what is the relationship between variables</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#tree-interpreter","title":"Tree Interpreter","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#the-extrapolation-problem","title":"The extrapolation problem","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#finding-out-of-domain-data","title":"Finding out of domain data","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#using-a-neural-net","title":"Using a Neural Net","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2007/#normalize","title":"Normalize","text":"<p><code>Normalize</code> subtracts the mean, then divides by the standard deviation. We didn't need this for a decision tree because we were only performing binary splits. However, we do need to normalize for neaural nets because we don't want things with crazy distributions.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2007/#summary","title":"Summary","text":"<p>Random Forests are easy to train, resillient, don't require much pre-processing, train quickly and don't overfit. They can be less accurate than a neural net and can take longer at inference time to evaluate the trees.</p> <p>Neural Nets are probably the fiddliest models to implement and set up but can give slightly better results.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/","title":"Lesson 08","text":"<pre><code>from fastai.text.all import *\npath = untar_data(URLs.IMDB)\n</code></pre> <p><code>get_text_files</code> gets all the text files in a path. We can also optionally pass folders to restrict the search to a particular list of subfolders:</p> <pre><code># only using 50k sample due to size of dataset\n# results may vary from fastai book\n\nfiles = get_text_files(path, folders = ['train', 'test', 'unsup'])[:50000]\n</code></pre> <pre><code># print out slice of first review\ntxt = files[0].open().read()\n\ntxt[:75]\n</code></pre> <pre>\n<code>\"The worst movie I've ever seen, hands down. It is ten times more a rip-off \"</code>\n</pre> <p><code>first()</code> - First element of <code>x</code>, or None if missing</p> <p><code>coll_repr</code> - String repr of up to <code>max_n</code> items of (possibly lazy) collection <code>c</code></p> <pre><code>spacy = WordTokenizer()\ntoks = first(spacy([txt]))\n\nprint(coll_repr(toks,30))\n</code></pre> <pre>\n<code>(#156) ['The','worst','movie','I',\"'ve\",'ever','seen',',','hands','down','.','It','is','ten','times','more','a','rip','-','off','of','Lake','Placid','than','it','is','a','sequel','.','Director'...]\n</code>\n</pre> <p>fastai provides additional functionality to tokenisers, such as adding in special tokens like begining of string <code>xxbos</code> or lowercasing all strings and adding the <code>xxmaj</code> token before. This is done to preserve importance and reduce some complexity.</p> <pre><code>tkn = Tokenizer(spacy)\n\nprint(coll_repr(tkn(txt),31))\n</code></pre> <pre>\n<code>(#176) ['xxbos','xxmaj','the','worst','movie','xxmaj','i',\"'ve\",'ever','seen',',','hands','down','.','xxmaj','it','is','ten','times','more','a','rip','-','off','of','xxmaj','lake','xxmaj','placid','than','it'...]\n</code>\n</pre> <p>You can explore the rules like so</p> <pre><code>defaults.text_proc_rules\n</code></pre> <pre>\n<code>[&lt;function fastai.text.core.fix_html(x)&gt;,\n &lt;function fastai.text.core.replace_rep(t)&gt;,\n &lt;function fastai.text.core.replace_wrep(t)&gt;,\n &lt;function fastai.text.core.spec_add_spaces(t)&gt;,\n &lt;function fastai.text.core.rm_useless_spaces(t)&gt;,\n &lt;function fastai.text.core.replace_all_caps(t)&gt;,\n &lt;function fastai.text.core.replace_maj(t)&gt;,\n &lt;function fastai.text.core.lowercase(t, add_bos=True, add_eos=False)&gt;]</code>\n</pre> <p>then check the source code for each using ?? like <code>fix_html??</code></p> <pre><code>txts = L(o.open().read() for o in files[:2000])\n</code></pre> <p>We instantiate our tokeniser, by defining the size of the vocab, then training it. </p> <p>meaing, have the tokeniser read the documents, find the common sequences of characters then create the vocab. in fastai, this is done with <code>setup</code>. </p> <pre><code>def subword(sz):\n    sp = SubwordTokenizer(vocab_sz=sz)\n    sp.setup(txts)\n    return ' '.join(first(sp([txt]))[:40])\n</code></pre> <pre><code>subword(1000)\n</code></pre> <pre>\n<code>\"\u2581The \u2581worst \u2581movie \u2581I ' ve \u2581ever \u2581seen , \u2581hand s \u2581down . \u2581It \u2581is \u2581t en \u2581time s \u2581more \u2581a \u2581 r i p - off \u2581of \u2581L ake \u2581P la ci d \u2581than \u2581it \u2581is \u2581a \u2581sequel .\"</code>\n</pre> <p>the special character \u2581 represents a space character in the original text.</p> <p>using a smaller vocab results in each token representing fewer characters, and will need more tokens to represent a sentence</p> <pre><code>subword(200)\n</code></pre> <pre>\n<code>\"\u2581The \u2581w or s t \u2581movie \u2581I ' ve \u2581 e ver \u2581s e en , \u2581 h an d s \u2581d o w n . \u2581I t \u2581is \u2581 t en \u2581 t i m es \u2581mo re \u2581a\"</code>\n</pre> <p>Using larger vocab will result in most common English words ending up in the vocab, and fewer tokens will be needed to represent a sentence</p> <pre><code>subword(10000)\n</code></pre> <pre>\n<code>\"\u2581The \u2581worst \u2581movie \u2581I ' ve \u2581ever \u2581seen , \u2581hands \u2581down . \u2581It \u2581is \u2581ten \u2581times \u2581more \u2581a \u2581rip - off \u2581of \u2581Lake \u2581Placid \u2581than \u2581it \u2581is \u2581a \u2581sequel . \u2581Director \u2581David \u2581F lo re s \u2581clearly \u2581did \u2581not \u2581go\"</code>\n</pre> <p>There are trade-off to be made here: larger vocab means fewer tokens per sentence leading to faster training and less memory and state required for the model. The downside is larger embedding matrices which require more data to learn.</p> <p>Subword tokenisation provides an easy way to scale between character and word tokenisation while also being useful for applications involving languages other than english.</p> <pre><code>toks = tkn(txt)\n\nprint(coll_repr(tkn(txt), 32))\n</code></pre> <pre>\n<code>(#176) ['xxbos','xxmaj','the','worst','movie','xxmaj','i',\"'ve\",'ever','seen',',','hands','down','.','xxmaj','it','is','ten','times','more','a','rip','-','off','of','xxmaj','lake','xxmaj','placid','than','it','is'...]\n</code>\n</pre> <pre><code># a small example\ntoks200 = txts[:200].map(tkn)\n\ntoks200[0]\n</code></pre> <pre>\n<code>(#176) ['xxbos','xxmaj','the','worst','movie','xxmaj','i',\"'ve\",'ever','seen'...]</code>\n</pre> <pre><code>num = Numericalize()\nnum.setup(toks200)\n\ncoll_repr(num.vocab,20)\n</code></pre> <pre>\n<code>\"(#2144) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','in','it','i'...]\"</code>\n</pre> <p>this is our vocab, starting with special tokens, then english words in order of highest frequency.</p> <p>we can now use the <code>Numericalize</code> object as a function and apply it to our tokens to see the integers they now represent</p> <pre><code>nums = num(toks)[:20]\n\nnums\n</code></pre> <pre>\n<code>tensor([  2,   8,   9, 310,  27,   8,  19, 218, 158, 141,  10,   0, 229,  11,\n          8,  18,  16, 550, 299,  66])</code>\n</pre> <pre><code>nums200 = toks200.map(num)\n</code></pre> <pre><code>dl = LMDataLoader(nums200)\n</code></pre> <pre><code>x,y = first(dl)\n\nx.shape, y.shape\n</code></pre> <pre>\n<code>(torch.Size([64, 72]), torch.Size([64, 72]))</code>\n</pre> <p><code>batch size</code> = 64</p> <p><code>stream length</code> = 72</p> <p>Looking at the first row of the independent variable should contain the start of the text</p> <pre><code>' '.join(num.vocab[o] for o in x[0][:20])\n</code></pre> <pre>\n<code>\"xxbos xxmaj the worst movie xxmaj i 've ever seen , xxunk down . xxmaj it is ten times more\"</code>\n</pre> <p>the dependent variable will be the same but offset by one token</p> <pre><code>' '.join(num.vocab[o] for o in y[0][:20])\n</code></pre> <pre>\n<code>\"xxmaj the worst movie xxmaj i 've ever seen , xxunk down . xxmaj it is ten times more a\"</code>\n</pre> <pre><code>get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n\ndls_lm = DataBlock(\n    blocks=TextBlock.from_folder(path, is_lm=True),\n    get_items=get_imdb,\n    splitter=RandomSplitter(0.1)\n    ).dataloaders(path, path=path, bs=128, seq_len=80)\n</code></pre> <pre><code>dls_lm.show_batch(max_n=2)\n</code></pre> text text_ 0 xxbos xxmaj my sincere advice to all : do n't watch the movie . \\n\\n xxmaj do n't even go near to the theater where this movie is being played ! ! even a glimpse of it is bad for health . serious . no jokes . it 's xxunk am in the morning . and i returned from this crappiest movie on this universe . xxup four xxup hours xxup damn xxrep 3 ! i am proud that i xxmaj my sincere advice to all : do n't watch the movie . \\n\\n xxmaj do n't even go near to the theater where this movie is being played ! ! even a glimpse of it is bad for health . serious . no jokes . it 's xxunk am in the morning . and i returned from this crappiest movie on this universe . xxup four xxup hours xxup damn xxrep 3 ! i am proud that i survived 1 what has led to the overwhelmingly negative reaction . \\n\\n xxmaj the shock value is the least appealing thing about this film - a minor detail that has been blown out of proportion . xxmaj the story is of xxmaj pierre 's downfall - and the subsequent destruction of those around him - which is overtly demonstrated in his features , demeanour and xxunk . xxmaj the dialogue and soundtrack set this film apart from any other i have seen has led to the overwhelmingly negative reaction . \\n\\n xxmaj the shock value is the least appealing thing about this film - a minor detail that has been blown out of proportion . xxmaj the story is of xxmaj pierre 's downfall - and the subsequent destruction of those around him - which is overtly demonstrated in his features , demeanour and xxunk . xxmaj the dialogue and soundtrack set this film apart from any other i have seen , <pre><code>learn = language_model_learner(\n    dls_lm, AWD_LSTM, drop_mult=0.3, \n    metrics=[accuracy, Perplexity()]).to_fp16()\n</code></pre> <pre><code>learn.fit_one_cycle(1, 2e-2)\n</code></pre> epoch train_loss valid_loss accuracy perplexity time 0 4.129613 3.911054 0.299887 49.951557 34:09 <pre><code>learn.save('1epoch')\n</code></pre> <pre><code>learn = learn.load('1epoch')\n</code></pre> <pre><code>learn.unfreeze()\nlearn.fit_one_cycle(5, 2e-3)\n</code></pre> epoch train_loss valid_loss accuracy perplexity time 0 3.870227 3.766035 0.318266 43.208385 35:48 1 3.772985 3.673187 0.329042 39.377213 35:38 2 3.677068 3.615694 0.335646 37.177132 35:36 3 3.570553 3.582507 0.339907 35.963577 35:56 4 3.526067 3.577981 0.340754 35.801178 35:58 <pre>\n<code>IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nIOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n</code>\n</pre> <pre><code>from fastai.text.all import *\npath = untar_data(URLs.HUMAN_NUMBERS)\n</code></pre> <pre><code>path.ls()\n</code></pre> <pre>\n<code>(#2) [Path('/storage/data/human_numbers/valid.txt'),Path('/storage/data/human_numbers/train.txt')]</code>\n</pre> <p>Lake a look at some of the data</p> <pre><code>lines = L()\n\nwith open(path/'train.txt') as f: lines += L(*f.readlines())\nwith open(path/'valid.txt') as f: lines += L(*f.readlines())\n\nlines\n</code></pre> <pre>\n<code>(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]</code>\n</pre> <p>concat all into one big stream, with \".\" to separate</p> <pre><code>text = ' . '.join([l.strip() for l in lines])\ntext[:100]\n</code></pre> <pre>\n<code>'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'</code>\n</pre> <p>use work tokenisation by splitting on spaces</p> <pre><code>tokens = L(text.split(' '))\ntokens[100:110]\n</code></pre> <pre>\n<code>(#10) ['.','forty','two','.','forty','three','.','forty','four','.']</code>\n</pre> <p>for numericalisation, we need to create a list of all unique words. we can then convert these into numbers</p> <pre><code>vocab = L(tokens).unique()\nvocab\n</code></pre> <pre>\n<code>(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]</code>\n</pre> <pre><code>word2idx = {w:i for i,w in enumerate(vocab)}\n\nnums = L(word2idx[i] for i in tokens)\n\ntokens, nums\n</code></pre> <pre>\n<code>((#63095) ['one','.','two','.','three','.','four','.','five','.'...],\n (#63095) [0,1,2,1,3,1,4,1,5,1...])</code>\n</pre> <p>We now have a small dataset that we can use for language modelling.</p> <pre><code>L((tokens[i:i+3], tokens[i+3]) for i in range(0, len(tokens)-4,3))[0]\n</code></pre> <pre>\n<code>((#3) ['one','.','two'], '.')</code>\n</pre> <p>We can see from looking at the first items that <code>['one','.','two']</code> are the independent variable and <code>'.'</code> is the dependent variable.</p> <p>What the model will actually use are tensors of the numericalised values.</p> <pre><code>seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0, len(nums)-4,3))\n\nseqs\n</code></pre> <pre>\n<code>(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]</code>\n</pre> <pre><code>bs = 64\ncut = int(len(seqs) * 0.8)\ndls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)\n</code></pre> <p></p> <p>In code we can represent this like so...</p> <p>To go from the input to hidden layer we use an embedding. We create one embedding which subsequent words will also go through, and each time we add this to the current set of activations.</p> <p>Why use the same embedding layer?? Conceptually, the words all represent english spellings of numbers, so they have the same meaning and therefore wouldn't need separate embeddings.</p> <p>Once we have the embedding, we send this through the linear layer, then through relu. As with embeddings, we can use the same Linear layer because we are doing the same kind of computation.</p> <p>The computation happens from the inner most brackets out so this...<code>F.relu(self.h_h(self.i_h(x[:,0])))</code> - starts with sending word 1 <code>x[:,0]</code> through the embedding layer <code>self.i_h(x[:,0])</code> - then through a Linear layer <code>self.h_h(self.i_h(x[:,0]))</code>  - and finally through the relu <code>F.relu(self.h_h(self.i_h(x[:,0])))</code></p> <pre><code>class LMModel1(Module):\n    # vocab_sz == vocab size\n    def __init__(self, vocab_sz, n_hidden):\n        # the embedding layer\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        # the linear layer\n        self.h_h = nn.Linear(n_hidden, n_hidden)\n        # final linear layer\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n\n    def forward(self, x):\n        # h is the hidden state\n        # word 1 to embedding\n        h = F.relu(self.h_h(self.i_h(x[:,0])))\n        # word 2 to same embedding\n        h = h + self.i_h(x:,1)    \n        h = F.relu(self.h_h(h))                \n        h = h + self.i_h(x[:,2])  # word 3 to same embedding\n        h = F.relu(self.h_h(h))\n\n        # hidden to output\n        return self.h_o(h)\n</code></pre> <p>the activations in the model are known as the \"hidden state\"</p> <pre><code>class LMModel1(Module):\n    def __init__(self, vocab_sz, n_hidden):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.h_h = nn.Linear(n_hidden, n_hidden)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n\n    def forward(self, x):\n        h = F.relu(self.h_h(self.i_h(x[:,0])))\n        h = h + self.i_h(x[:,1])\n        h = F.relu(self.h_h(h))                \n        h = h + self.i_h(x[:,2])\n        h = F.relu(self.h_h(h))\n        return self.h_o(h)\n</code></pre> <pre><code>learn = Learner(dls, LMModel1(len(vocab), 64), \n                loss_func=F.cross_entropy, \n                metrics=accuracy)\n\nlearn.fit_one_cycle(4, 1e-3)\n</code></pre> epoch train_loss valid_loss accuracy time 0 1.863818 2.031583 0.464939 00:02 1 1.392999 1.803210 0.467079 00:02 2 1.410863 1.698382 0.490849 00:02 3 1.371146 1.703473 0.411457 00:02 <p>So far our accuracy is just under 50%. Not bad. We can improve by first refactoring... <code>LMModel1</code> has a few repeated steps, we can remove this by adding in a for loop.</p> <p></p> <pre><code>class LMModel2(Module):\n    def __init__(self, vocab_sz, n_hidden):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.h_h = nn.Linear(n_hidden, n_hidden)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n\n    def forward(self,x):\n        # initialise h as 0.\n        # this gets braodcast to a tensor in the loop\n        h = 0.\n\n        for i in range(3):\n            h = h + self.i_h(x[:,i])\n            h = F.relu(self.h_h(h))  \n        return self.h_o(h)\n</code></pre> <pre><code># check we get the same results\n\nlearn = Learner(dls, LMModel2(len(vocab), 64), \n                loss_func=F.cross_entropy, \n                metrics=accuracy)\n\nlearn.fit_one_cycle(4, 1e-3)\n</code></pre> epoch train_loss valid_loss accuracy time 0 1.877445 2.006204 0.479914 00:02 1 1.398311 1.774232 0.482054 00:03 2 1.421882 1.650312 0.492988 00:03 3 1.372779 1.634449 0.484906 00:02 <p>We have actually just created a Recurrent Nuearal Net. </p> <p>Reminder - Hidden State represents the activations that are occurring inside the neural net.</p> <pre><code>class LMModel3(Module):\n    def __init__(self, vocab_sz, n_hidden):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.h_h = nn.Linear(n_hidden, n_hidden)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h = 0.\n\n    def forward(self,x):\n        for i in range(3):\n            self.h = self.h + self.i_h(x[:,i])\n            self.h = F.relu(self.h_h(self.h))\n        out = self.h_o(self.h)\n        self.h = self.h.detach()\n        return out\n\n    def reset(self): self.h = 0.\n</code></pre> <pre><code>m = len(seqs)//bs\nm,bs,len(seqs)\n</code></pre> <pre>\n<code>(328, 64, 21031)</code>\n</pre> <pre><code>def group_chunks(ds, bds):\n    m = len(ds)//bs\n    new_ds = L()\n    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n    return new_ds\n</code></pre> <pre><code>cut = int(len(seqs) * 0.8)\ndls = DataLoaders.from_dsets(\n    group_chunks(seqs[:cut], bs), \n    group_chunks(seqs[cut:], bs), \n    bs=bs, drop_last=True, shuffle=False)\n</code></pre> <pre><code>learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy,\n                metrics=accuracy, cbs=ModelResetter)\nlearn.fit_one_cycle(10, 3e-3)\n</code></pre> epoch train_loss valid_loss accuracy time 0 1.720635 1.881263 0.397837 00:03 1 1.319839 1.718479 0.460337 00:03 2 1.100321 1.620753 0.508413 00:03 3 1.016059 1.486176 0.543750 00:02 4 0.995253 1.397851 0.554567 00:03 5 0.965056 1.494172 0.529567 00:03 6 0.928281 1.383823 0.590625 00:03 7 0.841828 1.437241 0.601442 00:03 8 0.796445 1.491238 0.609615 00:03 9 0.787689 1.509905 0.606731 00:03 <p>This RNN keeps the state from batch to batch and the results show the uplift from this change. </p> <p>By only predicting every 4th word, we are throwing away signal, which seems wastful. By moving the output stage inside the loop (ie after every hidden state was created we make a prediction) it means we can predict the next word after every single word, rather than every 3 words. </p> <p>To do this we have to change our data so that the dependent variable has each of the three next words after each of out three input words. </p> <pre><code>sl = 16 # sequence length\n\nseqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n         for i in range(0,len(nums)-sl-1,sl))\n\ncut = int(len(seqs) * 0.8)\n\ndls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n                             group_chunks(seqs[cut:], bs),\n                             bs=bs, drop_last=True, shuffle=False)\n</code></pre> <p>We can see from the first two items in <code>seqs</code> that they are the same length but the second list is offset by 1</p> <pre><code>[L(vocab[o] for o in s) for s in seqs[0]]\n</code></pre> <pre>\n<code>[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n (#16) ['.','two','.','three','.','four','.','five','.','six'...]]</code>\n</pre> <p>update the model by creating a list to store outputs, then append to this after every element in the loop</p> <pre><code># Modify the model to output a prediction after every word\n\nclass LMModel4(Module):\n    def __init__(self, vocab_sz, n_hidden):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n        self.h_h = nn.Linear(n_hidden, n_hidden)     \n        self.h_o = nn.Linear(n_hidden,vocab_sz)\n        self.h = 0\n\n    def forward(self, x):\n        outs = []\n        for i in range(sl):\n            self.h = self.h + self.i_h(x[:,i])\n            self.h = F.relu(self.h_h(self.h))\n            outs.append(self.h_o(self.h))\n        self.h = self.h.detach()\n        return torch.stack(outs, dim=1)\n\n    def reset(self): self.h = 0\n</code></pre> <pre><code># flatten targets to fit loss function\n\ndef loss_func(inp, targ):\n    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))\n</code></pre> <pre><code>learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n               metrics=accuracy, cbs=ModelResetter)\n\nlearn.fit_one_cycle(15, 3e-3)\n</code></pre> epoch train_loss valid_loss accuracy time 0 3.212160 3.065020 0.248291 00:01 1 2.303481 1.984242 0.440511 00:01 2 1.722320 1.854335 0.428141 00:01 3 1.448855 1.685089 0.516846 00:01 4 1.267960 1.905218 0.549316 00:01 5 1.135633 1.983428 0.591064 00:01 6 1.026269 2.132295 0.593994 00:01 7 0.943246 2.123302 0.622966 00:01 8 0.850973 2.263324 0.638346 00:01 9 0.784856 2.315861 0.662028 00:01 10 0.729662 2.344142 0.649821 00:01 11 0.689929 2.379879 0.648519 00:01 12 0.656299 2.397321 0.655355 00:01 13 0.634652 2.373445 0.661947 00:01 14 0.623158 2.386648 0.659424 00:01 <pre><code>class LMModel5(Module):\n    def __init__(self, vocab_sz, n_hidden, n_layers):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h = torch.zeros(n_layers, bs, n_hidden)\n\n    def forward(self, x):\n        res,h = self.rnn(self.i_h(x), self.h)\n        self.h = h.detach()\n        return self.h_o(res)\n\n    def reset(self): self.h.zero_()\n</code></pre> <pre><code># using 2 layers\n\nlearn = Learner(dls, LMModel5(len(vocab), 64,2), loss_func=loss_func,\n               metrics=accuracy, cbs=ModelResetter)\n\nlearn.fit_one_cycle(15, 3e-3)\n</code></pre> epoch train_loss valid_loss accuracy time 0 3.054249 2.617002 0.445882 00:01 1 2.159026 1.819027 0.470703 00:01 2 1.711899 1.820897 0.402262 00:01 3 1.492573 1.740131 0.468669 00:01 4 1.336913 1.825282 0.494303 00:01 5 1.205158 1.927248 0.513591 00:01 6 1.079775 1.974853 0.543864 00:01 7 0.975060 2.035518 0.549235 00:01 8 0.899264 2.100957 0.536458 00:01 9 0.847659 2.070400 0.546956 00:01 10 0.796934 2.078454 0.546875 00:01 11 0.756011 2.080719 0.546956 00:01 12 0.725375 2.105812 0.549886 00:01 13 0.704403 2.089411 0.549723 00:01 14 0.693146 2.079454 0.550700 00:01 <p>Our results are worse! </p> <p>Why? Deep models are hard to train. This can be due to exploding or disappearing activiations. This basically means that our results either become very very large or very very small. This causes an explosion or vanishing of a number and can be computationally intensive or the accuracy of the floating point numbers gets lost. </p> <p>We can avoid this in a number of ways... </p> <pre><code># Training with LSTM\n\nclass LMModel6(Module):\n    def __init__(self, vocab_sz, n_hidden, n_layers):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n\n    def forward(self, x):\n        res,h = self.rnn(self.i_h(x), self.h)\n        self.h = [h_.detach() for h_ in h]\n        return self.h_o(res)\n\n    def reset(self): \n        for h in self.h: h.zero_()\n</code></pre> <pre><code>learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n                loss_func=CrossEntropyLossFlat(), \n                metrics=accuracy, cbs=ModelResetter)\nlearn.fit_one_cycle(15, 1e-2)\n</code></pre> epoch train_loss valid_loss accuracy time 0 3.040422 2.731378 0.391113 00:02 1 2.212882 1.787726 0.447917 00:02 2 1.632609 1.882631 0.484049 00:02 3 1.323149 2.013697 0.508057 00:02 4 1.091380 2.002088 0.518880 00:02 5 0.832751 1.733890 0.622233 00:02 6 0.620027 1.593947 0.696370 00:03 7 0.412642 1.505920 0.715495 00:04 8 0.257724 1.480889 0.761475 00:04 9 0.157874 1.392939 0.771973 00:04 10 0.097578 1.393537 0.774984 00:02 11 0.064152 1.374384 0.778158 00:02 12 0.046606 1.387635 0.785889 00:02 13 0.037822 1.404215 0.781982 00:02 14 0.033807 1.398724 0.782389 00:03 <p>Results are much much better!</p> <pre><code>class Dropout(Module):\n    def __init__(self, p): self.p = p\n    def forward(self, x):\n        if not self.training: return x\n        mask = x.new(*x.shape).bernoulli(1-p)\n        return x * mask.div_(1-p)\n</code></pre> <pre><code>p = .3\n\nB = torch.ones((3,3)).bernoulli(1-p)\n</code></pre> <pre><code>B\n</code></pre> <pre>\n<code>tensor([[0., 1., 1.],\n        [1., 0., 0.],\n        [0., 0., 0.]])</code>\n</pre> <p>In this example, 1-<code>p</code> adds 3 ones in the 3*3 matrix. Basically the probability of drawing a one here is 3/9 or 0.3. As we saw earlier with one hot encodings, this matrix will act as a lookup when you multiply it by another matrix. </p> <p>In context of what we are doing, by performing this multiplication you are randomly prunning elements of the other matrix</p> <pre><code>A = tensor([[1., 2., 3.],\n            [4., 5., 6.],\n            [7., 8., 9.]])\n</code></pre> <pre><code>A*B\n</code></pre> <pre>\n<code>tensor([[0., 2., 3.],\n        [4., 0., 0.],\n        [0., 0., 0.]])</code>\n</pre> <p>Corresponding elements of <code>A</code> are returned only if there is a 1 in the same position in matrix <code>B</code></p> <pre><code>class LMModel7(Module):\n    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n        self.drop = nn.Dropout(p)\n        self.h_o = nn.Linear(n_hidden, vocab_sz)\n        self.h_o.weight = self.i_h.weight\n        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n\n    def forward(self, x):\n        raw,h = self.rnn(self.i_h(x), self.h)\n        out = self.drop(raw)\n        self.h = [h_.detach() for h_ in h]\n        return self.h_o(out),raw,out\n\n    def reset(self): \n        for h in self.h: h.zero_()\n</code></pre> <pre><code>learn = Learner(dls, LMModel7(len(vocab), 64, 2, 0.5),\n                loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n                cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])\n</code></pre> <p>This is the same as above but <code>TextLearner</code> adds the additions peices for you</p> <pre><code>learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n</code></pre> <pre><code>learn.fit_one_cycle(15, 1e-2, wd=0.1)\n</code></pre> epoch train_loss valid_loss accuracy time 0 0.030605 1.401770 0.780680 00:02 1 0.029504 1.535201 0.766602 00:03 2 0.045721 1.465324 0.771484 00:03 3 0.057497 1.550894 0.807780 00:02 4 0.043013 1.394347 0.807292 00:02 5 0.029584 1.430816 0.807536 00:02 6 0.025191 1.391779 0.826009 00:02 7 0.021182 1.496358 0.825439 00:03 8 0.016158 1.389334 0.817139 00:02 9 0.014285 1.503886 0.828369 00:02 10 0.011608 1.421619 0.823079 00:02 11 0.009167 1.429033 0.825521 00:02 12 0.007534 1.449290 0.824382 00:02 13 0.006630 1.455278 0.824300 00:02 14 0.006208 1.456966 0.824056 00:02 <p>Almost 85% accuracy! </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#lesson-8-deep-learning-for-coders","title":"Lesson 8: Deep Learning for Coders","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#nlp","title":"NLP","text":"<p>This notebook will take a dive into Natural Language Processing and will attempt to train an NLP classifyer. This is a binary classification task using movie review sentiment. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#the-pretrained-model","title":"The pretrained model","text":"<p>In lesson 1, we acheived over 90% accuracy because we were using a pre-trained model that we fine-tuned further. So what is a pre-trained language model?</p> <p>A language model is one where we try to predict the next word in a sentence. For lesson one, this was a neaural net pre-trained on wiki articles (Wikitext 103). </p> <p>How does this help with sentiment anlysis? Like pre-trained image models, language models too contain a lot of information that can be leveraged rather than training from scratch. Fine-tuning will throw away the last layer(s) and train these rather than the entire model.</p> <p>Through transfer learning, we will create an Imdb language model using the wikitext model as a base.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#text-preprocessing","title":"Text preprocessing","text":"<ul> <li>Tokenization: Convert the text into a list of words (or characters, or substrings, depending on the granularity of your model)</li> <li>Numericalization: Make a list of all of the unique words that appear (the vocab), convert each word into a number, by looking up its index in the vocab.</li> <li>Language model data loader creation: fastai provides an <code>LMDataLoader</code> class which automatically handles creating a dependent variable that is offset from the independent variable by one token. It also handles some important details, such as how to shuffle the training data in such a way that the dependent and independent variables maintain their structure as required</li> <li>Language model creation: We need a special kind of model that does something we haven't seen before: handles input lists which could be arbitrarily big or small. There are a number of ways to do this; in this chapter we will be using a recurrent neural network (RNN).</li> </ul> <p>source</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#tokenisation","title":"Tokenisation","text":"<p>There are different approaches to tokenisation these are... - Word based: which splits a sentence on spaces  - Subword based: splits words into smaller parts based on the most commonly occuring substrings - Character bases: splits a sentence into individual characters</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#word-tokenisation-with-fastai","title":"Word tokenisation with fastai","text":"<ul> <li>there are a number of tokenisers out there, fastai makes it easy to switch between them.</li> <li>currently fastai default is from the spaCy library</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#data","title":"Data","text":"<ul> <li>The IMDB Large dataset contains 25,000 highly polar movie reviews for training, and 25,000 for testing. It is very large!</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#subword-tokenisation","title":"Subword Tokenisation","text":"<p>Word tokenisation relies on spaces within the document.</p> <p>Subword tokenisation does two things 1. analyses a corpus of documents to find the most commonly occurring groups of letters. These then become the vocab 2. Tokenise the corpus using this vocab of subword units</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#numericalisation","title":"Numericalisation","text":"<p>This is the process of mapping tokens to integers. It is nearly identical to the steps necessary to create a <code>Category</code> variable</p> <ol> <li>Make a list of all possible levels of that categorical variable (vocab)</li> <li>replace each level with it's index in the vocab</li> </ol>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#create-batches-for-language-model","title":"Create batches for language model","text":"<p>Batches are split based on the sequence length and batch size.</p> <p>Batches are created by concatenating individual texts into a stream. Order of inputs are randomised, meaning the order of the documents (not order of words in these) are shuffled.</p> <p>The stream is then divided into batches. </p> <p>This is done at every epoch - shuffle the collection of documents - concatenate them together into a stream of tokens - cut the stream into batches of fixed size consecutive mini streams</p> <p>This is all done in fastai using <code>LMDataLoader</code>. For example</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#pt-1-training-a-text-classifier-using-fastai","title":"Pt 1: Training a Text Classifier using fastai","text":"<p>The reason that <code>TextBlock</code> is special is because setting up the numericalizer's vocab can take a long time (we have to read and tokenize every document to get the vocab). To be as efficient as possible the <code>TextBlock</code> performs a few optimizations:</p> <ul> <li>It saves the tokenized documents in a temporary folder, so it doesn't have to tokenize them more than once</li> <li>It runs multiple tokenization processes in parallel, to take advantage of your computer's CPUs</li> </ul> <p>We need to tell <code>TextBlock</code> how to access the texts, so that it can do this initial preprocessing\u2014that's what from_folder does.</p> <p><code>show_batch</code> then works in the usual way</p> <p>source</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#fine-tuning","title":"Fine tuning","text":"<p>To convert the integer word indices into activations for the neural net, we will use embeddings. These are then fed into the RNN using an architecture called <code>AWD_LSTM</code></p> <p>cross entropy loss is sutable here since this is a classification problem. Often a metric called perplexity is used in NLP, this is the exponential of the loss (<code>torch.exp(cross_entropy)</code>). To this we will also add accuracy to determine how the model performs when trying to predict the next word. </p> <p><code>to_fp16</code> uses less GPU memory and trains faster</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#saving-and-loading-models","title":"Saving and Loading models","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#pt-2-a-language-model-from-scratch","title":"Pt 2: A Language Model from Scratch","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#data_1","title":"Data","text":"<ul> <li>The Human Numbers data set contains the first 10,000 numbers written in english. It was created by Jeremy for experimentation.</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#creating-a-language-model","title":"Creating a Language Model","text":"<p>For this simple example, we will predict the next word based on the previous 3 words. </p> <p>To do this, create a list with the independent variable being the first 3 words, and dependent variable being the 4th word.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#create-a-dataloader","title":"Create a DataLoader","text":"<ul> <li>batch size of 64</li> <li>split randomly, taking 80%</li> </ul>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#the-model-in-pytorch","title":"The model in PyTorch","text":"<p>A simple linear model has an input of size (batch size x #inputs), followed by a single hidden layer that computes a matrix product followed by ReLU; Out of which we will get some activations, the size of which will be (batch size x #activations). This is then followed by more computation, a matrix product followed by softmax. The final output size will be (batch size x #classes).</p> <p>We will take this approach and modify it for our model. </p> <p>Our model will be a Neural Net with 3 layers     - The embedding layer (input to hidden <code>i_h</code>)     - The Linear Layer (hidden to hidden <code>h_h</code>)         - this layer created the activations for the next word         - this layer will be used for words 1-3     - Final Linear layer to predict the fourth word (hidden to output layer <code>h_o</code>)</p> <p>In the diagram below, the arrows represent the computational steps (a linear layer followed by non-linearity (ReLU))</p> <p>To start, take the word 1 input and put it through the linear layer and ReLU to get first set of activations. </p> <p>Then put that through another linear layer and non-linearity. These activations are added (or concatenated would be fine) to the resulting activations of word 2 which is also run through a linear layer and non-linearity. </p> <p>Again the results are run through another linear layer and non-linearity while also adding in the result of putting word 3 through a computation layer as we did with word 2. </p> <p>These activations then go through a final linear layer and softmax to create the output activations. </p> <p>What is interesting about this model is that inputs are entering in later layer and added into the network. Also, arrows of the same colour mean that the same weight matrix is being used. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#our-first-recurrent-neural-net","title":"Our first Recurrent Neural Net","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#maintaining-the-hidden-state","title":"Maintaining the Hidden State","text":"<p>we can do this by storing the hidden state and updating it. <code>detach</code> throws away the gradient history, also known as truncated back propagation.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#look-into-this","title":"look into this!!","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#callbacks","title":"Callbacks","text":"<p><code>ModelResetter</code> is a fastai callback that resets the model at each training/validation step.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#multilayer-rnn","title":"Multilayer RNN","text":"<p>Our model is deep but every hidden to hidden layer uses the same weight matrix which means it isn't that deep at all. It is using the same weight matrix every time, so not very sophisticated. </p> <p>Let's refactor again to pass the activations of our current net into a second recurrent neaural network. This is called a stacked or multilayered RNN.</p> <p>Using PyTorch's <code>nn.RNN</code> module lets us define the number of layers (<code>n_layers</code>). We can also remove the loop and just call <code>self.rnn</code></p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#lstm","title":"LSTM","text":"<p>Replacing the matrix multiplication in an RNN with this architecture, basically means the model is able to make decisions about how much of an update to do each time. This helps the model to avoid updating too much or too little.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#training-a-language-model-using-lstms","title":"Training a Language Model Using LSTMs","text":"<p>This is the same network but the RNN is replaced with an LSTM. We need to increase the number of layers in our hidden state for this to work because the LSTM has more layers.</p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#regularising-an-lstm","title":"Regularising an LSTM","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#dropout","title":"Dropout","text":"<ul> <li>Dropout improves neaural net training by deleting random activations. This reduces the computation but also prevents the model from overfitting. </li> <li>Dropout helps the model to generalise by ensuring certain activations don't over specialise during the learning process</li> </ul> <p>class <code>Droput</code> - <code>p</code> the probability that an activation gets deleted - only perform dropout in training - <code>mask</code> the mask a tensor with random zeros with probability (<code>p</code>) and ones with probability (<code>p</code>-1) </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#a-simple-example","title":"A simple example","text":""},{"location":"fastai%20deep%20learning%202020/lesson%2008/#ar-and-tar-regularisation","title":"AR and TAR regularisation","text":"<p>AR (activation regularisation) and TAR (temporal activation regularisation) are very similar to weight decay but are applied to activations instead of weights. </p> <p>TAR is linked to the fact that we are trying to predict a sequence of tokens. So we take the difference of the activations between time steps. It limits the changes in activations between time steps. </p>"},{"location":"fastai%20deep%20learning%202020/lesson%2008/#weight-tying","title":"Weight Tying","text":"<p>Sets the hidden to output weights equal to the input to hidden weights. The idea is that converting words to activations and activations to words should conceptually be the same thing since the language is consistent, and the computation is consistent so why would you need to change the weights? </p>"},{"location":"graph%20representation%20learning/","title":"About","text":""},{"location":"graph%20representation%20learning/#graph-representation-learning","title":"Graph Representation Learning","text":""},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/","title":"01 Node Prediction with Graph Deep Learning","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.utils import to_networkx\n\nimport random\nimport networkx as nx\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>from torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(root='/tmp/Cora', name='Cora')\ndata = dataset[0]\ndata\n</code></pre> <pre>\n<code>Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])</code>\n</pre> <pre><code># edges are bidirectional, meaning messages can be passed \n# in both directions between a pair of nodes\n\ndata.is_undirected()\n</code></pre> <pre>\n<code>True</code>\n</pre> <pre><code>def convert_to_networkx(graph, n_sample=None):\n\n    g = to_networkx(graph, node_attrs=[\"x\"])\n    y = graph.y.numpy()\n\n    if n_sample is not None:\n        sampled_nodes = random.sample(g.nodes, n_sample)\n        g = g.subgraph(sampled_nodes)\n        y = y[sampled_nodes]\n\n    return g, y\n\n\ndef plot_graph(g, y):\n\n    plt.figure(figsize=(9, 7))\n    nx.draw_spring(g, node_size=30, arrows=False, node_color=y)\n    plt.show() \n\n\ng, y = convert_to_networkx(data, n_sample=1000)\nplot_graph(g, y)\n</code></pre> <pre><code>import torch_geometric.transforms as T\n\nsplit = T.RandomNodeSplit(num_val=0.1, num_test=0.2)\ndata = split(data)\ndata\n</code></pre> <pre>\n<code>Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])</code>\n</pre> <pre><code>class MLP(nn.Module):\n\"\"\"\n    simple MLP for classification\n    \"\"\"\n    def __init__(self, n_input, n_output, n_hidden=64):\n        super().__init__()\n\n        self.layers = nn.Sequential(\n            nn.Linear(n_input, n_hidden),\n            nn.ReLU(),\n\n            nn.Linear(n_hidden, n_hidden//2),\n            nn.ReLU(),\n\n            nn.Linear(n_hidden//2, n_output)\n        )\n\n    def forward(self, data):\n        out = self.layers(data.x)\n        return out\n</code></pre> <pre><code>def train_node_classifier(model, data, optimiser, criterion, n_epochs=200):\n\n    for epoch in range(1, n_epochs+1):\n        model.train()\n        optimiser.zero_grad()\n\n        out = model(data)\n        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n\n        loss.backward()\n        optimiser.step()\n\n        pred = out.argmax(dim=1)\n        acc = eval_node_classifier(model, data)\n\n        log = f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val Acc: {acc:.3f}'\n\n        if epoch % 10 == 0:\n            print(log)\n\n    return model\n\n\n\ndef eval_node_classifier(model, data):\n\n    model.eval()\n    pred = model(data).argmax(dim=1)\n\n    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n    acc = int(correct) / int(data.test_mask.sum())\n\n    return acc\n</code></pre> <pre><code>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# init\nmlp = MLP(n_input=dataset.num_node_features, n_output=dataset.num_classes).to(device)\n\n# optimiser and loss\noptimizer_mlp = torch.optim.Adam(mlp.parameters(), lr=0.01, weight_decay=5e-4)\n\ncriterion = nn.CrossEntropyLoss()\n</code></pre> <pre><code>mlp(data).shape\n\n#criterion(mlp(data), data.y)\n</code></pre> <pre>\n<code>torch.Size([2708, 7])</code>\n</pre> <pre><code># TRAIN\n# ------\n\nmlp = train_node_classifier(mlp, data, optimizer_mlp, criterion, n_epochs=150)\n\ntest_acc = eval_node_classifier(mlp, data)\nprint(f'Test Acc: {test_acc:.3f}')\n</code></pre> <pre>\n<code>Epoch: 010, Train Loss: 0.958, Val Acc: 0.631\nEpoch: 020, Train Loss: 0.109, Val Acc: 0.738\nEpoch: 030, Train Loss: 0.017, Val Acc: 0.725\nEpoch: 040, Train Loss: 0.011, Val Acc: 0.729\nEpoch: 050, Train Loss: 0.013, Val Acc: 0.725\nEpoch: 060, Train Loss: 0.011, Val Acc: 0.723\nEpoch: 070, Train Loss: 0.009, Val Acc: 0.736\nEpoch: 080, Train Loss: 0.008, Val Acc: 0.734\nEpoch: 090, Train Loss: 0.008, Val Acc: 0.736\nEpoch: 100, Train Loss: 0.007, Val Acc: 0.742\nEpoch: 110, Train Loss: 0.007, Val Acc: 0.742\nEpoch: 120, Train Loss: 0.006, Val Acc: 0.742\nEpoch: 130, Train Loss: 0.006, Val Acc: 0.745\nEpoch: 140, Train Loss: 0.006, Val Acc: 0.747\nEpoch: 150, Train Loss: 0.006, Val Acc: 0.745\nTest Acc: 0.745\n</code>\n</pre> <pre><code>class GCN(nn.Module):\n    def __init__(self, in_features, out_features, n_hidden=16):\n        super().__init__()\n\n        self.conv1 = GCNConv(in_features, n_hidden)\n        self.conv2 = GCNConv(n_hidden, out_features)\n\n    def forward(self, data):\n\n        x, edge_index = data.x, data.edge_index\n\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        out = self.conv2(x, edge_index)\n\n        return out\n</code></pre> <pre><code>gcn = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n\noptimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = nn.CrossEntropyLoss()\n</code></pre> <pre><code># FYI\ndataset.num_node_features, data.num_node_features\n</code></pre> <pre>\n<code>(1433, 1433)</code>\n</pre> <pre><code>gcn = train_node_classifier(gcn, data, optimizer_gcn, criterion)\n</code></pre> <pre>\n<code>Epoch: 010, Train Loss: 0.682, Val Acc: 0.751\nEpoch: 020, Train Loss: 0.121, Val Acc: 0.786\nEpoch: 030, Train Loss: 0.029, Val Acc: 0.777\nEpoch: 040, Train Loss: 0.014, Val Acc: 0.785\nEpoch: 050, Train Loss: 0.013, Val Acc: 0.787\nEpoch: 060, Train Loss: 0.014, Val Acc: 0.805\nEpoch: 070, Train Loss: 0.016, Val Acc: 0.812\nEpoch: 080, Train Loss: 0.017, Val Acc: 0.810\nEpoch: 090, Train Loss: 0.017, Val Acc: 0.811\nEpoch: 100, Train Loss: 0.016, Val Acc: 0.810\nEpoch: 110, Train Loss: 0.015, Val Acc: 0.808\nEpoch: 120, Train Loss: 0.014, Val Acc: 0.808\nEpoch: 130, Train Loss: 0.013, Val Acc: 0.811\nEpoch: 140, Train Loss: 0.013, Val Acc: 0.810\nEpoch: 150, Train Loss: 0.012, Val Acc: 0.812\nEpoch: 160, Train Loss: 0.012, Val Acc: 0.811\nEpoch: 170, Train Loss: 0.011, Val Acc: 0.811\nEpoch: 180, Train Loss: 0.011, Val Acc: 0.810\nEpoch: 190, Train Loss: 0.011, Val Acc: 0.810\nEpoch: 200, Train Loss: 0.010, Val Acc: 0.810\n</code>\n</pre> <pre><code>class GCN2(torch.nn.Module):\n    def __init__(self, in_features, out_features, n_hidden=16):\n        super().__init__()\n        self.conv1 = GCNConv(in_features, n_hidden)\n        self.conv2 = GCNConv(n_hidden, out_features)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n\n        return F.log_softmax(x, dim=1)\n</code></pre> <pre><code>gcn2 = GCN2(dataset.num_node_features, dataset.num_classes).to(device)\n\noptimizer_gcn2 = torch.optim.Adam(gcn2.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion2 = nn.NLLLoss()\n</code></pre> <pre><code>gcn2 = train_node_classifier(gcn2, data, optimizer_gcn2, criterion2)\n</code></pre> <pre>\n<code>Epoch: 010, Train Loss: 0.874, Val Acc: 0.755\nEpoch: 020, Train Loss: 0.260, Val Acc: 0.800\nEpoch: 030, Train Loss: 0.126, Val Acc: 0.799\nEpoch: 040, Train Loss: 0.060, Val Acc: 0.783\nEpoch: 050, Train Loss: 0.046, Val Acc: 0.790\nEpoch: 060, Train Loss: 0.040, Val Acc: 0.791\nEpoch: 070, Train Loss: 0.042, Val Acc: 0.791\nEpoch: 080, Train Loss: 0.053, Val Acc: 0.791\nEpoch: 090, Train Loss: 0.048, Val Acc: 0.796\nEpoch: 100, Train Loss: 0.031, Val Acc: 0.804\nEpoch: 110, Train Loss: 0.028, Val Acc: 0.799\nEpoch: 120, Train Loss: 0.032, Val Acc: 0.808\nEpoch: 130, Train Loss: 0.042, Val Acc: 0.793\nEpoch: 140, Train Loss: 0.053, Val Acc: 0.812\nEpoch: 150, Train Loss: 0.042, Val Acc: 0.796\nEpoch: 160, Train Loss: 0.023, Val Acc: 0.805\nEpoch: 170, Train Loss: 0.020, Val Acc: 0.801\nEpoch: 180, Train Loss: 0.023, Val Acc: 0.809\nEpoch: 190, Train Loss: 0.036, Val Acc: 0.804\nEpoch: 200, Train Loss: 0.029, Val Acc: 0.813\n</code>\n</pre> <p>Overall the first GCN performed slightly better than the second, however both performed better than the MLP (~17% uplift).</p> <p>Let's check the first few predictions against the target to see the results</p> <pre><code># predictions\npreds = gcn(data).argmax(dim=-1)\n\n# true values\ndata.y[:10]\n</code></pre> <pre>\n<code>tensor([3, 4, 4, 0, 3, 2, 0, 3, 3, 2])</code>\n</pre> <pre><code>preds[:10]\n</code></pre> <pre>\n<code>tensor([3, 4, 4, 0, 3, 2, 0, 3, 3, 2])</code>\n</pre>"},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/#node-classification-with-graph-neural-networks","title":"Node Classification With Graph Neural Networks","text":"<p>Generally speaking, there are three main prediction tasks on graphs: graph-level, node-level &amp; edge-level. </p> <p>In graph-level tasks we are looking to make a prediction on the entire graph for example classifying molecules or proteins. For node-level, we aim to predict an attribute at the node level ie node classification or regression. Edge-level seeks to make predictions about the connections between nodes ie whether or not a connection exists between two nodes and potentially what the strength of that connection is.</p> <p>We will focus on node classification in the following example using the Cora dataset. </p> <p>\"The Cora dataset consists of 2708 scientific publications classified into one of seven classes... Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\"</p> <p>Class labels</p> <ul> <li><code>0: theory</code></li> <li><code>1: reinforcement_learning</code></li> <li><code>2: genetic_algotrithms</code></li> <li><code>3: neural_networks</code></li> <li><code>4: probabilistic_methods</code></li> <li><code>5: case_based</code></li> <li><code>6: rule_learning</code></li> </ul> <p>The goal will be to correctly predict the class label of nodes in the graph.</p>"},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/#visualise-the-graph","title":"Visualise the graph","text":""},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/#node-classification","title":"Node Classification","text":"<p>For the node classification problem, we are splitting the nodes into train, valid, and test using the <code>RandomNodeSplit</code> module from PyG (we are replacing the original split masks in the data as it has a too small train set).</p>"},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/#baseline-mlp-classifyer","title":"Baseline MLP classifyer","text":""},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/#gcn-for-node-classification","title":"GCN for Node Classification","text":"<p>Architecture</p> <p>This is a simple GCN that we will train to compare performance against the baseline MLP. </p> <p>The architecture is fairly straightforward, two convolutional layers with a ReLU activation function between them. This is a very shallow network, in practice you would experiment with deep vs wide neural nets to understand the effects and trade-offs between computational complexity and predictive accuracy. </p> <p>Loss</p> <p>For classification tasks with $C$ targets, the Cross Entropy criterion is a good choice. The loss function computes the cross entropy between input logits and target. For cross entropy in PyTorch, the input is expected to contain the unnormalized logits for each class. In general, these do not need to be positive or sum to 1.</p>"},{"location":"graph%20representation%20learning/01%20Node%20Prediction%20with%20Graph%20Deep%20Learning/#slightly-different-gcn-architecture","title":"Slightly different GCN architecture","text":"<p>This architecture is identical to the first but adds in a dropout layer. Dropout is a widely used technique to reduce overfitting in neural networks. During training, dropout randomly ignores some number of layer outputs. This has the effect of reducing the capacity or \"thinnning-out\" the network. It also regularises the network by helping ensure that nodes withing the network are not codependent on each other.</p> <p>The loss has been changed to <code>NLLLoss</code> which, when preceeded by <code>LogSoftmax</code> is an equivalent to <code>CrossEntropyLoss</code>.</p>"},{"location":"machine%20learning/","title":"About","text":""},{"location":"machine%20learning/#machine-learning-with-pytorch-and-scikit-learn","title":"Machine Learning with PyTorch and Scikit-Learn","text":"<p>Notes from the excellent book by Sebastian Raschka</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/","title":"01 Topic Modeling","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport tarfile\n\n#import os\n#import sys\n\nfrom tqdm import tqdm\nfrom pathlib import Path\n</code></pre> <pre><code>p = Path.cwd()\n</code></pre> <pre><code>with tarfile.open('data/aclImdb_v1.tar.gz', 'r:gz') as tar:\n    tar.extractall()\n</code></pre> <pre><code>basepath = p/'data/aclImdb'\nlabels = {'pos':1, 'neg':0}\n\npbar = tqdm(range(50000))\ndf = pd.DataFrame()\n\nfor s in ('test','train'):\n    for l in ('pos', 'neg'):\n        path = basepath/s/l\n        for file in path.iterdir():\n            with open(path/file, 'r', encoding='utf-8') as infile:\n                txt = infile.read()\n            df = df.append([[txt, labels[l]]], ignore_index=True)\n\n            pbar.update()\n\ndf.columns = ['review', 'sentiment']\n</code></pre> <pre>\n<code>  0%|                                                                         | 0/50000 [00:00&lt;?, ?it/s]/var/folders/h6/76mmjn5902lf0r8382f_r52r0000gn/T/ipykernel_56182/3956242205.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df = df.append([[txt, labels[l]]], ignore_index=True)\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 49971/50000 [02:01&lt;00:00, 258.76it/s]</code>\n</pre> <pre><code>df.head()\n</code></pre> review sentiment 0 Based on an actual story, John Boorman shows t... 1 1 This is a gem. As a Film Four production - the... 1 2 I really like this show. It has drama, romance... 1 3 This is the best 3-D experience Disney has at ... 1 4 Of the Korean movies I've seen, only three had... 1 <pre><code>df.sentiment.value_counts()\n</code></pre> <pre>\n<code>1    25000\n0    25000\nName: sentiment, dtype: int64</code>\n</pre> <pre><code># shuffle index\ndf = df.reindex(np.random.permutation(df.index))\n\n# save for later\ndf.to_csv(p/'data'/'imdb_review_data.csv', index=False, encoding='utf-8')\n</code></pre> <pre><code>from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\ndocs = np.array([\n    'the sun is shining',\n    'the weather is sweet',\n    'the sun is shining, the weather is sweet',\n    'and one and one is two'\n])\n\nbag = vectorizer.fit_transform(docs)\n</code></pre> <pre><code># list of unique words with integer indices \n# ie, sort alphabetically then assign index\n\nvectorizer.vocabulary_\n</code></pre> <pre>\n<code>{'the': 6,\n 'sun': 4,\n 'is': 1,\n 'shining': 3,\n 'weather': 8,\n 'sweet': 5,\n 'and': 0,\n 'one': 2,\n 'two': 7}</code>\n</pre> <pre><code># let's sort these for convenience\nsorted(vectorizer.vocabulary_.items(), key=lambda x: x[1])\n</code></pre> <pre>\n<code>[('and', 0),\n ('is', 1),\n ('one', 2),\n ('shining', 3),\n ('sun', 4),\n ('sweet', 5),\n ('the', 6),\n ('two', 7),\n ('weather', 8)]</code>\n</pre> <p>let's look at the feature vectors</p> <pre><code>bag.toarray()\n</code></pre> <pre>\n<code>array([[0, 1, 0, 1, 1, 0, 1, 0, 0],\n       [0, 1, 0, 0, 0, 1, 1, 0, 1],\n       [0, 2, 0, 1, 1, 1, 2, 0, 1],\n       [2, 1, 2, 0, 0, 0, 0, 1, 0]])</code>\n</pre> <p>Each index position in the feature vectors corresponds to the sorted vocabulary, and represents the frequency of the word within that vector. For example...</p> <p>Looking at the last row (<code>[2, 1, 2, 0, 0, 0, 0, 1, 0]</code>), the word <code>and</code> appears at index position <code>0</code> and is represented by the frequency of the word (which is 2) within that particular sentence.</p> <p>The values in these feature vectors are also called the raw term frequencies: $tf(t,d)$ which is the number of times a term $t$, appears in a document $d$. </p> <pre><code>from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n\ntfidf.fit_transform(vectorizer.fit_transform(docs)).toarray()\n</code></pre> <pre>\n<code>array([[0.        , 0.37632116, 0.        , 0.56855566, 0.56855566,\n        0.        , 0.46029481, 0.        , 0.        ],\n       [0.        , 0.37632116, 0.        , 0.        , 0.        ,\n        0.56855566, 0.46029481, 0.        , 0.56855566],\n       [0.        , 0.4574528 , 0.        , 0.3455657 , 0.3455657 ,\n        0.3455657 , 0.55953044, 0.        , 0.3455657 ],\n       [0.65680405, 0.1713738 , 0.65680405, 0.        , 0.        ,\n        0.        , 0.        , 0.32840203, 0.        ]])</code>\n</pre> <p>The word \"is\" appears in all 4 documents. We can see that the results of the tfid have downweighted its importance. This is evident in the 4th document where it has relatively low importance (0.171).</p> <p>The scikit-learn implementation is slightly different from the one above due to the <code>smooth_idf=True</code> argument which assigns zero weight to terms that appear in all documents.</p> <p><code>TfidfTransformer</code> also normalises the tf-idfs directly bu applying L2-Normalisation, which returns a vector of length 1. The purpose for doing this is that the feature values become proportionate to each other.</p> <p>This can be verified like so...</p> <pre><code>v = tfidf.fit_transform(vectorizer.fit_transform(docs)).toarray()\nnp.linalg.norm(v[0])\n</code></pre> <pre>\n<code>1.0</code>\n</pre> <pre><code># source: this code comes straight from the book!\n# https://sebastianraschka.com/books/\n\nimport re\n\ndef preprocessor(text):\n    text = re.sub('&lt;[^&gt;]*&gt;', '', text)\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n                           text)\n    text = (re.sub('[\\W]+', ' ', text.lower()) +\n            ' '.join(emoticons).replace('-', ''))\n    return text\n</code></pre> <pre><code>s = df.loc[37720, 'review'][:50]\ns\n</code></pre> <pre>\n<code>'WARNING: REVIEW CONTAINS MILD SPOILERS&lt;br /&gt;&lt;br /&gt;'</code>\n</pre> <pre><code>preprocessor(s)\n</code></pre> <pre>\n<code>'warning review contains mild spoilers'</code>\n</pre> <pre><code>def tokeniser(text):\n    return text.split()\n</code></pre> <pre><code>tokeniser('runners like running')\n</code></pre> <pre>\n<code>['runners', 'like', 'running']</code>\n</pre> <pre><code>from nltk.stem import PorterStemmer\n\nstemmer = PorterStemmer()\n\ndef tokeniser_stemmer(text):\n    return [stemmer.stem(word) for word in text.split()]\n</code></pre> <pre><code>tokeniser_stemmer('runners like running')\n</code></pre> <pre>\n<code>['runner', 'like', 'run']</code>\n</pre> <pre><code>import nltk\nnltk.download('stopwords')\n</code></pre> <pre>\n<code>[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/devindearaujo/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n</code>\n</pre> <pre>\n<code>True</code>\n</pre> <pre><code>from nltk.corpus import stopwords\n\nstop = stopwords.words('english')\n\ns = 'a runner likes running and runs a lot'\n\n[w for w in tokeniser_stemmer(s) if w not in stop]\n</code></pre> <pre>\n<code>['runner', 'like', 'run', 'run', 'lot']</code>\n</pre> <pre><code># use grid search to find optimal model params\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\n# combines TfidfTransformer &amp; CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\n</code></pre> <pre><code># train test split\n\nX_train, X_test = df.loc[:25000, 'review'].values, df.loc[25000:, 'review'].values\ny_train, y_test = df.loc[:25000, 'sentiment'].values, df.loc[25000:, 'sentiment'].values\n</code></pre> <p>models parameter available to use with Grid Search... </p> <pre><code>lr = LogisticRegression(solver='liblinear')\nlr.get_params()\n</code></pre> <pre>\n<code>{'C': 1.0,\n 'class_weight': None,\n 'dual': False,\n 'fit_intercept': True,\n 'intercept_scaling': 1,\n 'l1_ratio': None,\n 'max_iter': 100,\n 'multi_class': 'auto',\n 'n_jobs': None,\n 'penalty': 'l2',\n 'random_state': None,\n 'solver': 'liblinear',\n 'tol': 0.0001,\n 'verbose': 0,\n 'warm_start': False}</code>\n</pre> <pre><code>tfidf = TfidfVectorizer(\n    strip_accents=None,\n    lowercase=False,\n    preprocessor=None\n)\n\n# param grid\nparam_grid = [\n    {\n        'vect__ngram_range': [(1,1)],\n        'vect__stop_words': [None],\n        'vect__tokenizer': [tokeniser, tokeniser_stemmer],\n        'clf__penalty': ['l2'],\n        'clf__C': [1., 10.]\n    },\n    {\n        'vect__ngram_range': [(1,1)],\n        'vect__stop_words': [stop, None],\n        'vect__tokenizer': [tokeniser],\n        'vect__use_idf': [False],\n        'vect__norm': [None],\n        'clf__penalty': ['l2'],\n        'clf__C': [1., 10.]   \n    }\n]\n\n# pipeline\nlr_tfidf = Pipeline([\n    ('vect', tfidf),\n    ('clf', LogisticRegression(solver='liblinear'))\n])\n\ngs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='accuracy', cv=5,\n                          verbose=2, n_jobs=-1)\n\ngs_lr_tfidf.fit(X_train, y_train)\n</code></pre> <pre>\n<code>Fitting 5 folds for each of 8 candidates, totalling 40 fits\n</code>\n</pre> <pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('vect',\n                                        TfidfVectorizer(lowercase=False)),\n                                       ('clf',\n                                        LogisticRegression(solver='liblinear'))]),\n             n_jobs=-1,\n             param_grid=[{'clf__C': [1.0, 10.0], 'clf__penalty': ['l2'],\n                          'vect__ngram_range': [(1, 1)],\n                          'vect__stop_words': [None],\n                          'vect__tokenizer': [&lt;function tokeniser at 0x11831fdc0&gt;,\n                                              &lt;function tokeniser_stemmer at 0x118344310&gt;]},\n                         {...\n                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n                                                'our', 'ours', 'ourselves',\n                                                'you', \"you're\", \"you've\",\n                                                \"you'll\", \"you'd\", 'your',\n                                                'yours', 'yourself',\n                                                'yourselves', 'he', 'him',\n                                                'his', 'himself', 'she',\n                                                \"she's\", 'her', 'hers',\n                                                'herself', 'it', \"it's\", 'its',\n                                                'itself', ...],\n                                               None],\n                          'vect__tokenizer': [&lt;function tokeniser at 0x11831fdc0&gt;],\n                          'vect__use_idf': [False]}],\n             scoring='accuracy', verbose=2)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org. <p>GridSearchCV<pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('vect',\n                                        TfidfVectorizer(lowercase=False)),\n                                       ('clf',\n                                        LogisticRegression(solver='liblinear'))]),\n             n_jobs=-1,\n             param_grid=[{'clf__C': [1.0, 10.0], 'clf__penalty': ['l2'],\n                          'vect__ngram_range': [(1, 1)],\n                          'vect__stop_words': [None],\n                          'vect__tokenizer': [&lt;function tokeniser at 0x11831fdc0&gt;,\n                                              &lt;function tokeniser_stemmer at 0x118344310&gt;]},\n                         {...\n                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n                                                'our', 'ours', 'ourselves',\n                                                'you', \"you're\", \"you've\",\n                                                \"you'll\", \"you'd\", 'your',\n                                                'yours', 'yourself',\n                                                'yourselves', 'he', 'him',\n                                                'his', 'himself', 'she',\n                                                \"she's\", 'her', 'hers',\n                                                'herself', 'it', \"it's\", 'its',\n                                                'itself', ...],\n                                               None],\n                          'vect__tokenizer': [&lt;function tokeniser at 0x11831fdc0&gt;],\n                          'vect__use_idf': [False]}],\n             scoring='accuracy', verbose=2)</pre> <p>estimator: Pipeline<pre>Pipeline(steps=[('vect', TfidfVectorizer(lowercase=False)),\n                ('clf', LogisticRegression(solver='liblinear'))])</pre> <p></p> TfidfVectorizer<pre>TfidfVectorizer(lowercase=False)</pre>LogisticRegression<pre>LogisticRegression(solver='liblinear')</pre> <p> </p> <p> </p> <pre><code>gs_lr_tfidf.best_params_\n</code></pre> <pre>\n<code>{'clf__C': 10.0,\n 'clf__penalty': 'l2',\n 'vect__ngram_range': (1, 1),\n 'vect__stop_words': None,\n 'vect__tokenizer': &lt;function __main__.tokeniser(text)&gt;}</code>\n</pre> <pre><code>print(f'Average CV Accuracy: {gs_lr_tfidf.best_score_:.3f}')\n</code></pre> <pre>\n<code>Average CV Accuracy: 0.888\n</code>\n</pre> <p>Using the best estimator, check classification accuracy on the training set.</p> <pre><code>clf = gs_lr_tfidf.best_estimator_\n\nprint(f'Test Accuracy: {clf.score(X_test, y_test):.3f}')\n</code></pre> <pre>\n<code>Test Accuracy: 0.893\n</code>\n</pre>"},{"location":"machine%20learning/01%20Topic%20Modeling/#applying-machine-learning-to-sentiment-analysis-and-topic-modeling","title":"Applying Machine Learning to Sentiment Analysis and Topic Modeling","text":"<p>This notebook will explore two topics from Natural Language Processing. The first, sentiment analysis, where we will use machine learing to classify documents based on their positive or negative sentiment. Followed by topic modeling, where we will extract the main topics from these documents.</p> <p>We will be working with the IMDB movie reviews data set containing 50,000 reviews.</p> <p>topics covered - data cleaning and processing - feature axtraction from text - training a classifyer on positive and negative sentiment - topic modeling with LDA</p> <p>This notebook is based on code and material from the excellent book by S. Raschka Machine Learning with PyTorch and Scikit-Learn</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#1-data-cleaning-and-preprocessing","title":"1. Data Cleaning and Preprocessing","text":"<p>The IMDB data set was produced by Andrew Mass and others (Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).) and contains 50,000 polar movie reviews, labeled either positive or negative. </p> <p>data can be downloaded from here</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#2-the-bag-of-words-model","title":"2. The Bag-of-Words Model","text":"<p>Before text data can be passed onto a machine learning or deep learning model, it needs to be converted into numerical form. The bag-of-words model allows us to do just this by representing text as feature vectors. The model can be summarised as follows...</p> <ol> <li>create a vocabulary of unique tokens (words) from the endire set of documents</li> <li>construct a feature vector for each document that contains the frequency count of words as they appear in each particular document. </li> </ol> <p>These feature vectors are usually very sparse (containing mainly zeros) since the occurrance of unique words represents only a small subset of all words. </p> <pre><code># create inference pipeline &amp;\n# update tfidf and logistic regression params\n\ninf_pl = lr_tfidf.set_params(**gs_lr_tfidf.best_params_)\n\n# refit with best params\ninf_pl.fit(X_train, y_train)\n\n# score on training\ninf_pl.score(X_train, y_train)\n</code></pre> <pre>\n<code>0.9967112810707457</code>\n</pre> <pre><code>print(f\"Test Accuracy: {inf_pl.score(X_test, y_test):.3f}\")\n</code></pre> <pre>\n<code>Test Accuracy: 0.893\n</code>\n</pre> <pre><code># check on some random text\ns = np.array([\"\"\"terminator 2 was a horrible movie. the effects were good, \\n\n              but i just couldn't get onboard with Robert Patrick's character\"\"\"])\n\ninf_pl.predict(s)\n</code></pre> <pre>\n<code>array([0])</code>\n</pre> <pre><code>from sklearn.feature_extraction.text import CountVectorizer\n\nvect = CountVectorizer(\n    stop_words='english',\n    max_df=.1,\n    max_features=5000\n)\n\nX = vect.fit_transform(df['review'].values)\n</code></pre> <pre><code>from sklearn.decomposition import LatentDirichletAllocation\n\nlda = LatentDirichletAllocation(\n    n_components=10,\n    random_state=123,\n    learning_method='batch',\n    n_jobs=-1\n)\n\nX_topics = lda.fit_transform(X)\n</code></pre> <pre><code>lda.components_.shape\n</code></pre> <pre>\n<code>(10, 5000)</code>\n</pre> <pre><code>n_top_words = 6\nfeature_names = vect.get_feature_names_out()\n\nfor topic_idx, topic in enumerate(lda.components_):\n    print(f'Topic {(topic_idx + 1)} : ')\n    print(' '.join([feature_names[i] \n                   for i in topic.argsort()\\\n                   [:-n_top_words -1:-1]]))\n</code></pre> <pre>\n<code>Topic 1 : \nworst minutes script awful stupid terrible\nTopic 2 : \nfamily mother father children girl women\nTopic 3 : \nwar american dvd music tv history\nTopic 4 : \nhuman audience cinema art sense feel\nTopic 5 : \npolice guy car dead murder goes\nTopic 6 : \nhorror house sex blood girl woman\nTopic 7 : \nrole performance comedy actor plays performances\nTopic 8 : \nseries episode episodes tv season original\nTopic 9 : \nbook version original read effects fi\nTopic 10 : \naction fight guy guys fun cool\n</code>\n</pre> <p>based on the most important words for each topic we can make a general assumption about the review topics...</p> <ol> <li>generally terrible movie reviews</li> <li>movies about families</li> <li>history/war movies</li> <li>art/arthouse movies</li> <li>crime films</li> <li>horror films</li> <li>comedy films</li> <li>tv series or shows</li> <li>movies based on books</li> <li>action movies</li> </ol> <p>To confirm our assumptions, we can print out sections of reviews from a particular category, say crime films.</p> <pre><code>horror_idx = X_topics[:, 5].argsort()[::-1] # sort descending\n\nfor iter_idx, movie_idx in enumerate(horror_idx[:3]):\n    print(f'\\nHorror movie #{(iter_idx + 1)}:')\n    print(df['review'].iloc[movie_idx][:300], '...')\n</code></pre> <pre>\n<code>\nHorror movie #1:\n&lt;br /&gt;&lt;br /&gt;Horror movie time, Japanese style. Uzumaki/Spiral was a total freakfest from start to finish. A fun freakfest at that, but at times it was a tad too reliant on kitsch rather than the horror. The story is difficult to summarize succinctly: a carefree, normal teenage girl starts coming fac ...\n\nHorror movie #2:\nBefore I talk about the ending of this film I will talk about the plot. Some dude named Gerald breaks his engagement to Kitty and runs off to Craven Castle in Scotland. After several months Kitty and her aunt venture off to Scottland. Arriving at Craven Castle Kitty finds that Gerald has aged and he ...\n\nHorror movie #3:\nThis film marked the end of the \"serious\" Universal Monsters era (Abbott and Costello meet up with the monsters later in \"Abbott and Costello Meet Frankentstein\"). It was a somewhat desparate, yet fun attempt to revive the classic monsters of the Wolf Man, Frankenstein's monster, and Dracula one \"la ...\n</code>\n</pre> <pre><code>comedy_idx = X_topics[:, 6].argsort()[::-1] # sort descending\n\nfor iter_idx, movie_idx in enumerate(comedy_idx[:3]):\n    print(f'\\nComedy movie #{(iter_idx + 1)}:')\n    print(df['review'].iloc[movie_idx][:300], '...')\n</code></pre> <pre>\n<code>\nComedy movie #1:\nFrom producer/writer/Golden Globe nominated director James L. Brooks (Terms of Endearment, As Good as It Gets) this is a really good satirical comedy film showing behind the scenes in the life of a news reporter/anchor/journalist or producer might be like. Basically Jane Craig (Oscar and Golden Glob ...\n\nComedy movie #2:\nTHE SUNSHINE BOYS was the hilarious 1975 screen adaptation of Neil Simon's play about a retired vaudevillian team, played by Walter Matthau and George Burns, who had a very bitter breakup and have been asked to reunite one more time for a television special or something like that. The problem is tha ...\n\nComedy movie #3:\nAs far as I know the real guy that the main actor is playing saw his performance and said it was an outstanding portrayal, I'd agree with him. This is a fantastic film about a quite gifted boy/man with a special body part helping him. Oscar and BAFTA winning, and Golden Globe nominated Daniel Day-Le ...\n</code>\n</pre>"},{"location":"machine%20learning/01%20Topic%20Modeling/#21-from-words-to-feature-vectors","title":"2.1 From Words to Feature Vectors","text":"<p>Scikit-learn has implemented the <code>CountVectorizer</code> class that will take in an array of data (documents or sentences), and constructs the bag-of-words model for us.</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#22-assessing-word-relevancy-via-term-frequency-inverse-document-frequency-tfidf","title":"2.2 Assessing word relevancy via term frequency-inverse document frequency (tfidf)","text":"<p>Often, when analysing text data, the same word will appear across both classes (in context this means, the same word would appear in positive and negative reviews). These words often don't contain useful or discrimatory information. The tfidf technique can be used to downweight frequentlty occuring words. </p> <p>tfidf can be defined as the product of the term frequency and the inverse document frequency $tfidf = tf(t,d) x idf(t,d)$ and is calculated like...</p> <p>$$idf(t,d) = log\\frac{n_d}{1+df(t,f)} $$</p> <p>where $n_d$ is the total document count, $df(t,f)$ is the number of documents $d$ that contain the term $t$. The $log$ is used to ensure that low document frequencies are not given too much weight. </p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#3-cleaning-text-data","title":"3. Cleaning Text Data","text":"<ol> <li>remove punctuation and html markup</li> <li>tokenisation</li> <li>removing stop words</li> </ol> <p>The above steps are pretty typical in NLP pipeline. There are different approaches to these, ie for neural nets I've seen different encoding strategies where things like capitals, html tags, unknown words etc are replaced with tags which allows the model to capture this information which may (or may not) be useful.</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#31-stripping-punctuation-html","title":"3.1 Stripping Punctuation &amp; html","text":""},{"location":"machine%20learning/01%20Topic%20Modeling/#32-tokenisation","title":"3.2 Tokenisation","text":"<p>Tokenisation is the process of splitting a document into individual elements (tokens). There are different strategies for doing this, ie word tokenisation, sentence tokenisation. Ontop of this are other techniques like word stemming - the process of transforming a word into it's root form ie <code>running</code> -&gt; <code>run</code>.</p> <p>The NLTK library is one of many with tools to help with stemming and lemmatisation. </p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#33-stop-word-removal","title":"3.3 Stop word removal","text":"<p>Stop words are considered words that are extremely common and likely bear no useful or discrimatory information. Again, in the world of deep learning this is debateable and you should consider whether the task requires this and ultimately assess model performance to determine whether this is necessary.</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#4-document-classification-via-logistic-regression","title":"4. Document Classification via logistic regression","text":"<p>Classify movie reviews using logistic regressin, employing all of the preprocessing steps discussed above.</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#41-finding-optimal-model-params-via-gridsearchcv","title":"4.1 Finding optimal model params via GridSearchCV","text":""},{"location":"machine%20learning/01%20Topic%20Modeling/#42-updating-the-pipeline-with-best-parameters","title":"4.2 Updating the Pipeline with best parameters","text":"<p>The results demonstrate that the logistic regression model can predict whether a movie is positive or negative with 86% accuracy. Using the best parameters, retrain the logistic regression model. The <code>lr_tfidf</code> pipeline can be updated using the <code>set_params</code> method and passing in the <code>best_params_</code> from <code>gs_lr_tfidf</code></p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#5-topic-modeling-with-latent-dirichlet-allocation-lda","title":"5. Topic Modeling with Latent Dirichlet Allocation (LDA)","text":"<p>Broadly speaking, topic modeling describes a method for assigning topics to unlabelled documents. For example, categorising a large text corpus of newspaper articles, or wiki pages. This can also be considdered a clustering task - assigning a label to simmilar sets of items, here, the items are documents.</p> <p>LDA is not to be confused with the matrix decomposition method Linear Discriminant Analysis, also abbreviated... to LDA. </p> <p>Latent Dirichlet Allocation (LDA) is a generative probabilistic model that aims to find groups of words that frequently appear together across a corpus of documents. This works on the assumption that each document is made up of mixtures of different words. The words that appear together often, become topics.</p> <p>The input to an LDA model is a bag-of-words model. Given this, LDA decomposes it into two new matrices.. - a document-to-topic matrix - a word-to-topic matrix</p> <p>The decompostion works in such a way that we are able to reconstruct (with the lowest possible error) the original matrix by multiplying the two latent feature matrices together. The downside to LDA, is that the number of topics is a hyperparameter, that must be specified manually beforehand.</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#51-bag-of-words-on-movie-reviews","title":"5.1 Bag-of-words on Movie Reviews","text":"<p>Fit a bag-of-words model using <code>CountVectorizer</code> on the movie reviews data. We can exclude words that appear too frequently across documents by setting <code>max_df</code> to 10%. The dimensionality of tha dataset can be controlled using the <code>max_features</code> argument, here 5000 is chosen arbitrarily.</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#51-fitting-the-lda-model","title":"5.1 Fitting the LDA model","text":"<p>With a total of 10 topics...</p>"},{"location":"machine%20learning/01%20Topic%20Modeling/#conclusion","title":"Conclusion","text":"<p>In the following notebook we can see how even a vanilla implementation of document classification with logistic regression is able to accurately predict whether a review is positive or negative. Following this, using LDA is an effective method for classifying documents based on topics extracted from the raw text input.</p>"},{"location":"machine%20learning/02%20Regression%20Analysis/","title":"02 Regression Analysis","text":"<pre><code>import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format='retina'\n</code></pre> <pre><code>url = 'http://jse.amstat.org/v19n3/decock/AmesHousing.txt'\n\ncols = ['Overall Qual', 'Overall Cond', 'Gr Liv Area', 'Central Air', 'Total Bsmt SF', 'SalePrice']\n\ndf = pd.read_csv(url, sep='\\t', usecols=cols)\n\n# clean up column labels\ndf.columns = [c.lower().replace(' ', '_') for c in cols]\n\n# encode \"central air\"\n# Y=1, N=0\ndf['central_air'] = df['central_air'].map({'Y':1, 'N':0})\n\n# drop NANs\ndf = df.dropna(axis=0)\n\ndf.to_csv('data/ames_housing_data.csv', index=False)\ndf.head()\n</code></pre> overall_qual overall_cond gr_liv_area central_air total_bsmt_sf saleprice 0 6 5 1080.0 1 1656 215000 1 5 6 882.0 1 896 105000 2 6 6 1329.0 1 1329 172000 3 7 5 2110.0 1 2110 244000 4 5 5 928.0 1 1629 189900 <pre><code>import seaborn as sns\n\ng = sns.PairGrid(df)\ng.map_diag(sns.histplot)\ng.map_offdiag(sns.scatterplot)\ng.add_legend();\n</code></pre> <p>looking at the pairplot, it is easy to see that somewhat linear relationships exist between <code>total_bsmt_sf</code> and <code>salesprice</code>, or between <code>gr_liv_area</code> and <code>salesprice</code>. </p> <p>Looking at the histograms for all three variables, they appear to be skewed by outliers. Linear regression models do not require that variables are normally distributed, unless analysis for certain statistics or hypothesis tests are being conducted.</p> <pre><code>cm = np.corrcoef(df.T)\n\nf, ax = plt.subplots(figsize=(5, 4))\nsns.heatmap(cm, annot=True, linewidths=.5, ax=ax, xticklabels=df.T.index, yticklabels=df.T.index);\n</code></pre> <p>Out of the continuous variables, <code>total_bsmt_sf</code> and <code>gr_liv_area</code> have the stronges correlation with the target variable, <code>saleprice</code>. </p> <pre><code># based on implementation from the excellent book\n# https://sebastianraschka.com/books/\n\nclass LinearRegressionGD():\n    def __init__(self, lr=0.01, n_iter=50, random_state=1):\n        self.lr = lr\n        self.n_iter = n_iter\n        self.random_state = random_state\n\n    def fit(self, X, y):\n        rgen = np.random.RandomState(self.random_state)\n        self.w_ = rgen.normal(loc=0., scale=1., size=X.shape[1])\n        self.b_ = np.array([0.])\n        self.losses_ = []\n\n        for i in range(self.n_iter):\n            out = self.net_input(X)\n            errors = (y - out)\n            self.w_ += self.lr * 2.0 * X.T.dot(errors) / X.shape[0]\n            self.b_ += self.lr * 2.0 * errors.mean()\n            loss = (errors**2).mean()\n            self.losses_.append(loss)\n        return self\n\n    def net_input(self, X):\n        return np.dot(X, self.w_) + self.b_\n\n    def predict(self, X):\n        return self.net_input(X)\n</code></pre> <pre><code>X = df[['total_bsmt_sf']].values\ny = df[['saleprice']].values\n\n# standardise input and target\nfrom sklearn.preprocessing import StandardScaler\n\nsc_x, sc_y = StandardScaler(), StandardScaler()\nX_std, y_std = sc_x.fit_transform(X), sc_y.fit_transform(y).flatten()\n</code></pre> <pre><code>lr = LinearRegressionGD(lr=0.1)\n\nlr.fit(X_std, y_std)\n</code></pre> <pre>\n<code>&lt;__main__.LinearRegressionGD at 0x11d3e4a30&gt;</code>\n</pre> <pre><code>plt.plot(range(1, lr.n_iter+1), lr.losses_)\nplt.ylabel('MSE')\nplt.xlabel('Epoch');\n</code></pre> <pre><code>def regression_plot(X, y, model):\n\"\"\"\n    plot the line of best fit \n    from a linear regression model\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8,6))\n\n    ax.scatter(X,y, alpha=.6)\n    ax.plot(X, model.predict(X), c='red', lw=1)\n</code></pre> <pre><code>regression_plot(X_std, y_std, lr)\nplt.xlabel('Total square feet of basement area')\nplt.ylabel('Sale Price');\n</code></pre> <pre><code># model coefficients\nprint(f'Slope: {lr.w_[0]:.3f}')\nprint(f'Intercept: {lr.b_[0]:.3f}')\n</code></pre> <pre>\n<code>Slope: 0.707\nIntercept: -0.000\n</code>\n</pre> <p>This vanilla implementation demonstrated how an OLS model can be fit using SGD, which iteratively updated the weight and bias paramenters by minimising the squared errod between the predicted and actual values. Sklearn provides additional features to assess model fit and accuracy</p> <pre><code>from sklearn.linear_model import LinearRegression\n\nslr = LinearRegression()\nslr.fit(X_std,y_std)\n\ny_pred = slr.predict(X_std)\n\n# model coefficients\nprint(f'Slope: {slr.coef_[0].item():.3f}')\nprint(f'Intercept: {slr.intercept_:.3f}')\n</code></pre> <pre>\n<code>Slope: 0.707\nIntercept: -0.000\n</code>\n</pre> <pre><code>regression_plot(X_std, y_std, slr)\nplt.xlabel('Total square feet of basement area')\nplt.ylabel('Sale Price');\n</code></pre> <p>The results match the from-scratch implementation. In both models, the presence of outliers has pulled the line away from what looks like could be a better fit (with a slighlty steeper slope). </p> <pre><code>from sklearn.linear_model import RANSACRegressor\n\nransac = RANSACRegressor(\n    LinearRegression(),\n    max_trials=100,\n    min_samples=.95,\n    residual_threshold=None,\n    random_state=123\n)\n\nransac.fit(X,y)\n</code></pre> <pre>RANSACRegressor(estimator=LinearRegression(), min_samples=0.95,\n                random_state=123)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org. <p>RANSACRegressor<pre>RANSACRegressor(estimator=LinearRegression(), min_samples=0.95,\n                random_state=123)</pre> <p>estimator: LinearRegression<pre>LinearRegression()</pre> <p></p> LinearRegression<pre>LinearRegression()</pre> <p> </p> <p> </p> <p>Here,  a linear model was fit with the RANSAC algorithm so that the minimum number of training examples used was 95% of the data (<code>min_samples=.95</code>). The algorithm uses the median absolute deviation by default to select the inliers (<code>residual_threshold=None</code>).</p> <p>As expected, the model coefficients differ from the previous linear model.</p> <pre><code>print(f'Slope: {ransac.estimator_.coef_[0].item():.3f}')\nprint(f'Intercept: {ransac.estimator_.intercept_[0]:.3f}')\n</code></pre> <pre>\n<code>Slope: 106.348\nIntercept: 20190.093\n</code>\n</pre> <p>Visualising the results of the model can be useful for understanding how it all works.</p> <pre><code>inlier_mask = ransac.inlier_mask_\noutlier_mask = np.logical_not(inlier_mask)\n\nline_X = np.arange(3, 10, 1)\nline_y = ransac.predict(line_X[:, np.newaxis])\n\n# plot inliers\nplt.scatter(X[inlier_mask], y[inlier_mask],\n           c='steelblue', edgecolor='white',\n           marker='o', label='Inliers')\n\n# plot outliers\nplt.scatter(X[outlier_mask], y[outlier_mask],\n           c='green', edgecolor='white',\n           marker='s', label='Outliers')\n\n# line of fit\nplt.plot(line_X, line_y, color='red', lw=2)\n\nplt.xlabel('Total Basement Square Footage')\nplt.ylabel('Sales Price in U.S. dollars')\nplt.legend(loc='upper left')\nplt.tight_layout();\n</code></pre> <p>To identify fewer outliers, the <code>residual_threshold</code> can be set &gt; than the median absolute deviation. </p> <p>$${\\displaystyle \\operatorname {MAD} =\\operatorname {median} (|X_{i}-{\\tilde {X}}|)}$$</p> <p>where </p> <p>$$\\tilde {X} = \\operatorname {median}(X)$$ </p> <pre><code>def median_absolute_deviation(data):\n    return np.median(np.abs(data - np.median(data)))\n\nmedian_absolute_deviation(y)\n</code></pre> <pre>\n<code>37000.0</code>\n</pre>"},{"location":"machine%20learning/02%20Regression%20Analysis/#regression-analysis-for-continuous-target-variables","title":"Regression Analysis for Continuous Target Variables","text":"<p>Unlike classification models, regression models are used to predict target variables on a continuous scale and for understanding relationships between variables, analysing trends and even making forecasts which makes them valuable within industry. </p>"},{"location":"machine%20learning/02%20Regression%20Analysis/#univariate-linear-regression","title":"Univariate Linear Regression","text":"<p>Linear regression makes use of single or multiple exogenous or explanatory variables and models their relationship with a continuous target variable. Univariate (or simple) linear regression is the most basic form, and uses only a single explanatory variable as a predictor of the target variable. A univariate model can be described as follows... </p> <p>$$y = w_1x +b$$</p> <p>Where $w_1$, the weight coefficient, represents the slope of the line, the bias unit $b$ represents the y intercept. The goal is to optimise this equation and learn the parameters ($w_1$ and $b$) to produce a line the best describes the relationship between predictor $X$ and target $y$. This optimised equation can then be used to predict new variables that are outside the observed training samples.</p> <p>The best fitting line is called the regression line. </p> <pre><code># train test split\nfrom sklearn.model_selection import train_test_split\n\ntarget = 'saleprice'\nfeatures = df.columns[df.columns != target]\n\nX = df[features].values\ny = df[target].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=123)\n\n# model\nmlr = LinearRegression() \n\n# fit\nmlr.fit(X_train, y_train)\n\n# predict\ny_train_pred = mlr.predict(X_train)\ny_test_pred = mlr.predict(X_test)\n</code></pre> <pre><code># straight from the book!\n# max values for hlines\nx_max = np.max([np.max(y_train_pred), np.max(y_test_pred)])\nx_min = np.min([np.min(y_train_pred), np.min(y_test_pred)])\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3), sharey=True)\n\nax1.scatter(y_test_pred, y_test_pred - y_test,\n            c='green', marker='s', edgecolor='white',\n            label='Test data')\nax2.scatter(y_train_pred, y_train_pred - y_train,\n            c='steelblue', marker='o', edgecolor='white',\n            label='Training data')\nax1.set_ylabel('Residuals')\n\nfor ax in (ax1, ax2):\n    ax.set_xlabel('Predicted values')\n    ax.legend(loc='upper left')\n    ax.hlines(y=0, xmin=x_min, xmax=x_max, color='red', lw=1.5)\n\nplt.tight_layout()\n\nplt.show()\n</code></pre> <p>A perfect prediction would result in the residuals sitting at exactly zero. A good model would also result in the residuals being randomly scattered around 0. When this is not the case (as can be seen above) it means that the model has not captured some explanatory information. This information has leaked into the residuals.  </p> <pre><code>ax = df[['total_bsmt_sf', 'gr_liv_area']].boxplot(figsize=(6,8))\nax.set_title('Example of outliers');\n</code></pre> <pre><code>fig, ax = plt.subplots(figsize=(8,6))\nplt.scatter('overall_qual', 'saleprice', data=df, alpha=.5)\nplt.xlabel('overall quality')\nplt.ylabel('sales price');\n</code></pre> <pre><code># set X, y\nX = df['overall_qual'].values.reshape(-1, 1)\ny = df['saleprice'].values\n</code></pre> <pre><code>from sklearn.preprocessing import PolynomialFeatures\n\n# fit regression model\nlm = LinearRegression()\n\n# feature engineering (quadratic, cubic)\nquadr = PolynomialFeatures(degree=2)\ncubic = PolynomialFeatures(degree=3)\n\nX_quad = quadr.fit_transform(X)\nX_cubic = cubic.fit_transform(X)\n\n# fit linear\nX_fit = np.arange(X.min()-1, X.max()+2, 1)[:,np.newaxis]\n\nregr = lm.fit(X, y)\ny_lin_fit = regr.predict(X_fit)\nlinear_r2 = r2_score(y, regr.predict(X))\n\n# fit quadratic\nregr = lm.fit(X_quad, y)\ny_quad_fit = regr.predict(quadr.fit_transform(X_fit))\nquad_r2 = r2_score(y, regr.predict(X_quad))\n\n# fit cubic\nregr = lm.fit(X_cubic,y)\ny_cubic_fit = regr.predict(cubic.fit_transform(X_fit))\ncubic_r2 = r2_score(y, regr.predict(X_cubic))\n</code></pre> <pre><code>fig, ax = plt.subplots(figsize=(10,8))\n\nplt.scatter(X, y, label='Training points', color='lightgrey', alpha=.6)\n\n# linear regression line\nplt.plot(X_fit, y_lin_fit, \n         label=f'Linear (d=1), $R^2$={linear_r2:.2f}',\n         color='steelblue', lw=2, linestyle=':'\n        );\n\n# cubic regression line\nplt.plot(X_fit, y_cubic_fit, \n         label=f'Cubic (d=2), $R^2$={cubic_r2:.2f}',\n         color='red', lw=2, linestyle='-'\n        );\n\n# quadratic regression line\nplt.plot(X_fit, y_quad_fit, \n         label=f'Quadratic (d=3), $R^2$={quad_r2:.2f}',\n         color='green', lw=2, linestyle='--'\n        );\n\nplt.legend(loc='upper left')\nplt.xlabel('overall quality')\nplt.ylabel('sales price');\n</code></pre>"},{"location":"machine%20learning/02%20Regression%20Analysis/#multiple-linear-regression","title":"Multiple Linear Regression","text":"<p>The linear regression model can be generalised to multiple explanatory variables, where the equation is extended to...</p> <p>$$y = w_1x_1 + ... + w_mx_m + b = \\sum_{i=1}^{m} w_ix_i + b = W^{T}x + b$$</p> <p>To explore linear models further, let's look at some data.</p>"},{"location":"machine%20learning/02%20Regression%20Analysis/#1-data-analysis","title":"1. Data Analysis","text":"<p>The Ames housing dataset has been produced by Dean De Cock in 2011. It contains information about individual residential properties in Ames, Iowa. </p> <p>Documentation for this data can be found here with information on all 80 features. For simplicity, a subset of the variables will be used...</p> <p>Columns</p> <ul> <li><code>Overall Qual</code> (Ordinal): Rates the overall material and finish of the house</li> <li><code>Overall Cond</code> (Ordinal): Rates the overall condition of the house</li> <li><code>Gr Liv Area</code> (Continuous): Above grade (ground) living area square feet</li> <li><code>Central Air</code> (Nominal): Central air conditioning</li> <li><code>Total Bsmt SF</code> (Continuous): Total square feet of basement area</li> <li><code>SalePrice</code> (Continuous): Sale price $$</li> </ul>"},{"location":"machine%20learning/02%20Regression%20Analysis/#11-visual-inspection","title":"1.1 Visual inspection","text":""},{"location":"machine%20learning/02%20Regression%20Analysis/#12-correlation","title":"1.2 Correlation","text":"<p>The correlation matrix is a square matrix that contains the Pearson product-moment correlation coefficients abbreviated to Pearson's r, which is a measure of linear dependence between pairs of features. </p> <p>Coefficients range between -1 (perfect negative correlation), to 0 (no correlation) to 1 (perfect positive). The Pearsons correlation coefficient can be calculated as the covariance between two variables (x and y) divided by their standard deviation. </p> <p>$$\\rho = \\frac{\\text{cov}(X,Y)}{\\sigma_x \\sigma_y}$$</p>"},{"location":"machine%20learning/02%20Regression%20Analysis/#13-fitting-an-ols-linear-model-from-scratch","title":"1.3 Fitting an OLS linear model from scratch","text":"<p>Ordinary least squares (OLS) is a method for estimmating the parameters of the linear regression line that minimises the sum of the squared error between training examples. </p> <p>There is a relationship between linear regression and the Adaptive Linear Neuron (Adaline) mode. The Adeline model uses a linear activation function followed by a threshold function for the task of classification. By dropping the threshold function, we can use Adaline to solve OLS regression. This means gradient descent can be used to minimise the mean squared error loss function defined as... </p> <p>$$L(w,b) = \\frac{1}{2n}\\sum_{i=1}^{n}(y^{(i)} - \\hat{y^{(i)}})^2$$</p> <p>Where $\\hat{y}$ is the predicted value $\\hat{y} = W^Tx + b$. </p>"},{"location":"machine%20learning/02%20Regression%20Analysis/#2-ransac-a-robust-regression-model","title":"2. RANSAC a robust regression model","text":"<p>In linear regression, outliers can have a big effect on the model fit by skewing the estimated model coefficients away from what could otherwise be the \"best fit\". Removing outliers involves both judgement and domain knowledge.</p> <p>There is an alternative to outlier removal: The RANSA (RANdom SAmple Consensus) model deals with outliers by fitting the model to a subset of the data (inliers).</p> <p>The model is first fitted on subset of data (inliers), then, all other samples are are tested against these inliers based on a user-defined tolerance. The model is again fitted on the new subset of data. The error is then estimated and the algorithm is stopped if the performance reaches a user defined threshold or if the fixed number of iterations has been reached.</p>"},{"location":"machine%20learning/02%20Regression%20Analysis/#3-evaluating-the-performance-of-linear-regression-models","title":"3. Evaluating the performance of linear regression models","text":"<p>The goal of this section is to go beyond univariate models by introducing additional exogenous variables. However, in doing so it is not then possible to visualise the regression line (or hyperplane) using a two dimensional plot. </p> <p>Alternatively, residual plots are commonly used to diagnose regression models. They can be used to detect non-linearity and outliers, and to assess whether the errors are randomly distributed.</p>"},{"location":"machine%20learning/02%20Regression%20Analysis/#4-modeling-non-linear-relationships-polynomial-regression","title":"4. Modeling non-linear relationships - polynomial regression","text":"<p>Given the information learned above, try constructing polynomial features and removing outliers to see if a better fit can be achieved. To illustrate, <code>overall_qual</code> will be used as the relationship to <code>saleprice</code> is clearly non-linear.</p>"}]}